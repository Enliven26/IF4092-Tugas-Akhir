{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "load_dotenv(dotenv_path=\".env.test\", verbose=True, override=True)\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autocommit_evaluation.core.enums import EnvironmentKey\n",
    "from autocommit_evaluation.cmg.evaluators import CommitMessageGenerator\n",
    "from autocommit_evaluation.cmg import evaluator\n",
    "from autocommit_evaluation.core import (\n",
    "    openrouter_few_shot_high_level_context_cmg_chain,\n",
    "    openrouter_zero_shot_low_level_context_cmg_chain,\n",
    "    openrouter_few_shot_low_level_context_cmg_chain,\n",
    "    openrouter_zero_shot_high_level_context_cmg_chain,\n",
    "    openrouter_high_level_context_chain,\n",
    "    openai_high_level_context_chain,\n",
    "    openai_zero_shot_low_level_context_cmg_chain,\n",
    "    openai_zero_shot_high_level_context_cmg_chain,\n",
    "    openai_few_shot_high_level_context_cmg_chain\n",
    ")\n",
    "from autocommit.core.models import CommitDataModel\n",
    "from autocommit_evaluation.datapreparation import context_generator, example_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMIT_DATA_JSON_FILE_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"cmg\", \"commits.test.json\")\n",
    "CONTEXT_DATA_PATH = os.path.join(\"autocommit_evaluation\",\"data\", \"context\")\n",
    "\n",
    "DEFAULT_HIGH_LEVEL_CONTEXT_OUTPUT_PATH = os.path.join(\n",
    "    \"out\", \"test\", \"highlevelcontext\"\n",
    ")\n",
    "DEFAULT_CMG_OUTPUT_PATH = os.path.join(\"out\", \"test\", \"cmg\")\n",
    "DEFAULT_DIFF_CLASSIFICATION_OUTPUT_PATH = os.path.join(\n",
    "    \"out\", \"test\", \"diffclassification\"\n",
    ")\n",
    "\n",
    "DIFF_CLASSIFIER_CHAINS = [\n",
    "    openrouter_zero_shot_low_level_context_cmg_chain,\n",
    "    openrouter_zero_shot_high_level_context_cmg_chain,\n",
    "]\n",
    "\n",
    "HIGH_LEVEL_CONTEXT_CHAINS = [\n",
    "    openrouter_high_level_context_chain,\n",
    "    openai_high_level_context_chain\n",
    "]\n",
    "\n",
    "GENERATORS = [\n",
    "    CommitMessageGenerator(\n",
    "        \"OpenRouter Zero-Shot Low-Level Context Generator\", openrouter_zero_shot_low_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"OpenRouter Few-Shot Low-Level Context Generator\", openrouter_few_shot_low_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"OpenRouter Zero-Shot High-Level Context Generator\", openrouter_zero_shot_high_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"OpenRouter Few-Shot High-Level Context Generator\", openrouter_few_shot_high_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"OpenAI Few-Shot Low-Level Context Generator\", openai_zero_shot_low_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"OpenAI Zero-Shot High-Level Context Generator\", openai_zero_shot_high_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"OpenAI Few-Shot High-Level Context Generator\", openai_few_shot_high_level_context_cmg_chain\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIGH_LEVEL_CONTEXT_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.HIGH_LEVEL_CONTEXT_OUTPUT_PATH.value,\n",
    "        DEFAULT_HIGH_LEVEL_CONTEXT_OUTPUT_PATH,\n",
    "    )\n",
    "\n",
    "CMG_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.CMG_OUTPUT_PATH.value, DEFAULT_CMG_OUTPUT_PATH\n",
    "    )\n",
    "\n",
    "DIFF_CLASSIFICATION_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.DIFF_CLASSIFICATION_OUTPUT_PATH.value,\n",
    "        DEFAULT_DIFF_CLASSIFICATION_OUTPUT_PATH,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(path: str) -> list[CommitDataModel]:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            json_string = file.read()\n",
    "\n",
    "        return CommitDataModel.from_json(json_string)\n",
    "\n",
    "COMMITS = get_commits(COMMIT_DATA_JSON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDED_DIFF_CLASSIFIER_CHAIN_INDEXES = [1]\n",
    "\n",
    "# for index in INCLUDED_DIFF_CLASSIFIER_CHAIN_INDEXES:\n",
    "#     evaluator.classify_diffs(DIFF_CLASSIFIER_CHAINS[index], COMMITS, CONTEXT_DATA_PATH, DIFF_CLASSIFICATION_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get High Level Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. Summarize in exactly two concise sentences. \\n\\nAvoid adding any additional comments or annotations to the summary.\\n\\nGit diff:\\ndiff --git a/core/src/main/java/kafka/log/remote/RemoteLogManager.java b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\nindex c1c87d579e..3eacbea475 100644\\n--- a/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n+++ b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n@@ -983,7 +983,9 @@ public class RemoteLogManager implements Closeable {\\n                     }\\n                 }\\n                 if (shouldDeleteSegment) {\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\",\\n                             metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n                 }\\n@@ -1000,7 +1002,9 @@ public class RemoteLogManager implements Closeable {\\n                     remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                     // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                     // are ascending with in an epoch.\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\",\\n                             metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n                 }\\ndiff --git a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\nindex 4c4976f060..3c9b8a48e9 100644\\n--- a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n+++ b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n@@ -2055,6 +2055,75 @@ public class RemoteLogManagerTest {\\n         assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n     }\\n \\n+    @ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n+    @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n+    public void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize,\\n+                                                                   long retentionMs)\\n+            throws RemoteStorageException, ExecutionException, InterruptedException {\\n+        Map<String, Long> logProps = new HashMap<>();\\n+        logProps.put(\"retention.bytes\", retentionSize);\\n+        logProps.put(\"retention.ms\", retentionMs);\\n+        LogConfig mockLogConfig = new LogConfig(logProps);\\n+        when(mockLog.config()).thenReturn(mockLogConfig);\\n+\\n+        List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n+        checkpoint.write(epochEntries);\\n+        LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n+        when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n+\\n+        when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n+        when(mockLog.logEndOffset()).thenReturn(200L);\\n+\\n+        RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024,\\n+                epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED)\\n+                .get(0);\\n+        // overlapping segment\\n+        RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()),\\n+                metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(),\\n+                metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128,\\n+                metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n+\\n+        // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n+        // returns the segments in order of (valid ++ unreferenced) segments:\\n+        // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n+        //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n+        //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n+        // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n+        List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n+        metadataList.add(metadata2);\\n+        metadataList.add(metadata1);\\n+\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition))\\n+                .thenReturn(metadataList.iterator());\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0))\\n+                .thenAnswer(ans -> metadataList.iterator());\\n+        when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class)))\\n+                .thenReturn(CompletableFuture.runAsync(() -> { }));\\n+\\n+        // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+\\n+        RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n+        task.convertToLeader(0);\\n+        task.cleanupExpiredRemoteLogSegments();\\n+\\n+        assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n+\\n+        // Verify the metric for remote delete is updated correctly\\n+        assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        // Verify we did not report any failure for remote deletes\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+    }\\n+\\n     @ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n     @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n     public void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize,\\n\\n\\nSource code:\\ncore/src/main/java/kafka/log/remote/RemoteLogManager.java (Before)\\npublic class RemoteLogManager implements Closeable {\\nclass RLMTask extends CancellableRunnable {\\n\\n    private final TopicIdPartition topicIdPartition;\\n\\n    private final int customMetadataSizeLimit;\\n\\n    private final Logger logger;\\n\\n    private volatile int leaderEpoch = -1;\\n\\n    public RLMTask(TopicIdPartition topicIdPartition, int customMetadataSizeLimit) {\\n        this.topicIdPartition = topicIdPartition;\\n        this.customMetadataSizeLimit = customMetadataSizeLimit;\\n        LogContext logContext = new LogContext(\"[RemoteLogManager=\" + brokerId + \" partition=\" + topicIdPartition + \"] \");\\n        logger = logContext.logger(RLMTask.class);\\n    }\\n\\n    boolean isLeader() {\\n        return leaderEpoch >= 0;\\n    }\\n\\n    // The copied and log-start offset is empty initially for a new leader RLMTask, and needs to be fetched inside\\n    // the task\\'s run() method.\\n    private volatile Optional<OffsetAndEpoch> copiedOffsetOption = Optional.empty();\\n\\n    private volatile boolean isLogStartOffsetUpdatedOnBecomingLeader = false;\\n\\n    private volatile Optional<String> logDirectory = Optional.empty();\\n\\n    public void convertToLeader(int leaderEpochVal) {\\n        if (leaderEpochVal < 0) {\\n            throw new KafkaException(\"leaderEpoch value for topic partition \" + topicIdPartition + \" can not be negative\");\\n        }\\n        if (this.leaderEpoch != leaderEpochVal) {\\n            leaderEpoch = leaderEpochVal;\\n        }\\n        // Reset copied and log-start offset, so that it is set in next run of RLMTask\\n        copiedOffsetOption = Optional.empty();\\n        isLogStartOffsetUpdatedOnBecomingLeader = false;\\n    }\\n\\n    public void convertToFollower() {\\n        leaderEpoch = -1;\\n    }\\n\\n    private void maybeUpdateLogStartOffsetOnBecomingLeader(UnifiedLog log) throws RemoteStorageException {\\n        if (!isLogStartOffsetUpdatedOnBecomingLeader) {\\n            long logStartOffset = findLogStartOffset(topicIdPartition, log);\\n            updateRemoteLogStartOffset.accept(topicIdPartition.topicPartition(), logStartOffset);\\n            isLogStartOffsetUpdatedOnBecomingLeader = true;\\n            logger.info(\"Found the logStartOffset: {} for partition: {} after becoming leader, leaderEpoch: {}\", logStartOffset, topicIdPartition, leaderEpoch);\\n        }\\n    }\\n\\n    private void maybeUpdateCopiedOffset(UnifiedLog log) throws RemoteStorageException {\\n        if (!copiedOffsetOption.isPresent()) {\\n            // This is found by traversing from the latest leader epoch from leader epoch history and find the highest offset\\n            // of a segment with that epoch copied into remote storage. If it can not find an entry then it checks for the\\n            // previous leader epoch till it finds an entry, If there are no entries till the earliest leader epoch in leader\\n            // epoch cache then it starts copying the segments from the earliest epoch entry\\'s offset.\\n            copiedOffsetOption = Optional.of(findHighestRemoteOffset(topicIdPartition, log));\\n            logger.info(\"Found the highest copiedRemoteOffset: {} for partition: {} after becoming leader, \" + \"leaderEpoch: {}\", copiedOffsetOption, topicIdPartition, leaderEpoch);\\n            copiedOffsetOption.ifPresent(offsetAndEpoch -> log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset()));\\n        }\\n    }\\n\\n    /**\\n     *  Segments which match the following criteria are eligible for copying to remote storage:\\n     *  1) Segment is not the active segment and\\n     *  2) Segment end-offset is less than the last-stable-offset as remote storage should contain only\\n     *     committed/acked messages\\n     * @param log The log from which the segments are to be copied\\n     * @param fromOffset The offset from which the segments are to be copied\\n     * @param lastStableOffset The last stable offset of the log\\n     * @return candidate log segments to be copied to remote storage\\n     */\\n    List<EnrichedLogSegment> candidateLogSegments(UnifiedLog log, Long fromOffset, Long lastStableOffset) {\\n        List<EnrichedLogSegment> candidateLogSegments = new ArrayList<>();\\n        List<LogSegment> segments = JavaConverters.seqAsJavaList(log.logSegments(fromOffset, Long.MAX_VALUE).toSeq());\\n        if (!segments.isEmpty()) {\\n            for (int idx = 1; idx < segments.size(); idx++) {\\n                LogSegment previousSeg = segments.get(idx - 1);\\n                LogSegment currentSeg = segments.get(idx);\\n                if (currentSeg.baseOffset() <= lastStableOffset) {\\n                    candidateLogSegments.add(new EnrichedLogSegment(previousSeg, currentSeg.baseOffset()));\\n                }\\n            }\\n            // Discard the last active segment\\n        }\\n        return candidateLogSegments;\\n    }\\n\\n    public void copyLogSegmentsToRemote(UnifiedLog log) throws InterruptedException {\\n        if (isCancelled())\\n            return;\\n        try {\\n            maybeUpdateLogStartOffsetOnBecomingLeader(log);\\n            maybeUpdateCopiedOffset(log);\\n            long copiedOffset = copiedOffsetOption.get().offset();\\n            // LSO indicates the offset below are ready to be consumed (high-watermark or committed)\\n            long lso = log.lastStableOffset();\\n            if (lso < 0) {\\n                logger.warn(\"lastStableOffset for partition {} is {}, which should not be negative.\", topicIdPartition, lso);\\n            } else if (lso > 0 && copiedOffset < lso) {\\n                // log-start-offset can be ahead of the copied-offset, when:\\n                // 1) log-start-offset gets incremented via delete-records API (or)\\n                // 2) enabling the remote log for the first time\\n                long fromOffset = Math.max(copiedOffset + 1, log.logStartOffset());\\n                List<EnrichedLogSegment> candidateLogSegments = candidateLogSegments(log, fromOffset, lso);\\n                logger.debug(\"Candidate log segments, logStartOffset: {}, copiedOffset: {}, fromOffset: {}, lso: {} \" + \"and candidateLogSegments: {}\", log.logStartOffset(), copiedOffset, fromOffset, lso, candidateLogSegments);\\n                if (candidateLogSegments.isEmpty()) {\\n                    logger.debug(\"No segments found to be copied for partition {} with copiedOffset: {} and active segment\\'s base-offset: {}\", topicIdPartition, copiedOffset, log.activeSegment().baseOffset());\\n                } else {\\n                    for (EnrichedLogSegment candidateLogSegment : candidateLogSegments) {\\n                        if (isCancelled() || !isLeader()) {\\n                            logger.info(\"Skipping copying log segments as the current task state is changed, cancelled: {} leader:{}\", isCancelled(), isLeader());\\n                            return;\\n                        }\\n                        copyQuotaManagerLock.lock();\\n                        try {\\n                            while (rlmCopyQuotaManager.isQuotaExceeded()) {\\n                                logger.debug(\"Quota exceeded for copying log segments, waiting for the quota to be available.\");\\n                                // If the thread gets interrupted while waiting, the InterruptedException is thrown\\n                                // back to the caller. It\\'s important to note that the task being executed is already\\n                                // cancelled before the executing thread is interrupted. The caller is responsible\\n                                // for handling the exception gracefully by checking if the task is already cancelled.\\n                                boolean ignored = copyQuotaManagerLockCondition.await(quotaTimeout().toMillis(), TimeUnit.MILLISECONDS);\\n                            }\\n                            rlmCopyQuotaManager.record(candidateLogSegment.logSegment.log().sizeInBytes());\\n                            // Signal waiting threads to check the quota again\\n                            copyQuotaManagerLockCondition.signalAll();\\n                        } finally {\\n                            copyQuotaManagerLock.unlock();\\n                        }\\n                        copyLogSegment(log, candidateLogSegment.logSegment, candidateLogSegment.nextSegmentOffset);\\n                    }\\n                }\\n            } else {\\n                logger.debug(\"Skipping copying segments, current read-offset:{}, and LSO:{}\", copiedOffset, lso);\\n            }\\n        } catch (CustomMetadataSizeLimitExceededException e) {\\n            // Only stop this task. Logging is done where the exception is thrown.\\n            brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n            brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n            this.cancel();\\n        } catch (InterruptedException | RetriableException ex) {\\n            throw ex;\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n                logger.error(\"Error occurred while copying log segments of partition: {}\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    private void copyLogSegment(UnifiedLog log, LogSegment segment, long nextSegmentBaseOffset) throws InterruptedException, ExecutionException, RemoteStorageException, IOException, CustomMetadataSizeLimitExceededException {\\n        File logFile = segment.log().file();\\n        String logFileName = logFile.getName();\\n        logger.info(\"Copying {} to remote storage.\", logFileName);\\n        RemoteLogSegmentId id = RemoteLogSegmentId.generateNew(topicIdPartition);\\n        long endOffset = nextSegmentBaseOffset - 1;\\n        File producerStateSnapshotFile = log.producerStateManager().fetchSnapshot(nextSegmentBaseOffset).orElse(null);\\n        List<EpochEntry> epochEntries = getLeaderEpochEntries(log, segment.baseOffset(), nextSegmentBaseOffset);\\n        Map<Integer, Long> segmentLeaderEpochs = new HashMap<>(epochEntries.size());\\n        epochEntries.forEach(entry -> segmentLeaderEpochs.put(entry.epoch, entry.startOffset));\\n        RemoteLogSegmentMetadata copySegmentStartedRlsm = new RemoteLogSegmentMetadata(id, segment.baseOffset(), endOffset, segment.largestTimestamp(), brokerId, time.milliseconds(), segment.log().sizeInBytes(), segmentLeaderEpochs);\\n        remoteLogMetadataManager.addRemoteLogSegmentMetadata(copySegmentStartedRlsm).get();\\n        ByteBuffer leaderEpochsIndex = epochEntriesAsByteBuffer(getLeaderEpochEntries(log, -1, nextSegmentBaseOffset));\\n        LogSegmentData segmentData = new LogSegmentData(logFile.toPath(), toPathIfExists(segment.offsetIndex().file()), toPathIfExists(segment.timeIndex().file()), Optional.ofNullable(toPathIfExists(segment.txnIndex().file())), producerStateSnapshotFile.toPath(), leaderEpochsIndex);\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyRequestRate().mark();\\n        brokerTopicStats.allTopicsStats().remoteCopyRequestRate().mark();\\n        Optional<CustomMetadata> customMetadata = remoteLogStorageManager.copyLogSegmentData(copySegmentStartedRlsm, segmentData);\\n        RemoteLogSegmentMetadataUpdate copySegmentFinishedRlsm = new RemoteLogSegmentMetadataUpdate(id, time.milliseconds(), customMetadata, RemoteLogSegmentState.COPY_SEGMENT_FINISHED, brokerId);\\n        if (customMetadata.isPresent()) {\\n            long customMetadataSize = customMetadata.get().value().length;\\n            if (customMetadataSize > this.customMetadataSizeLimit) {\\n                CustomMetadataSizeLimitExceededException e = new CustomMetadataSizeLimitExceededException();\\n                logger.error(\"Custom metadata size {} exceeds configured limit {}.\" + \" Copying will be stopped and copied segment will be attempted to clean.\" + \" Original metadata: {}\", customMetadataSize, this.customMetadataSizeLimit, copySegmentStartedRlsm, e);\\n                try {\\n                    // For deletion, we provide back the custom metadata by creating a new metadata object from the update.\\n                    // However, the update itself will not be stored in this case.\\n                    remoteLogStorageManager.deleteLogSegmentData(copySegmentStartedRlsm.createWithUpdates(copySegmentFinishedRlsm));\\n                    logger.info(\"Successfully cleaned segment after custom metadata size exceeded\");\\n                } catch (RemoteStorageException e1) {\\n                    logger.error(\"Error while cleaning segment after custom metadata size exceeded, consider cleaning manually\", e1);\\n                }\\n                throw e;\\n            }\\n        }\\n        remoteLogMetadataManager.updateRemoteLogSegmentMetadata(copySegmentFinishedRlsm).get();\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        brokerTopicStats.allTopicsStats().remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        // `epochEntries` cannot be empty, there is a pre-condition validation in RemoteLogSegmentMetadata\\n        // constructor\\n        int lastEpochInSegment = epochEntries.get(epochEntries.size() - 1).epoch;\\n        copiedOffsetOption = Optional.of(new OffsetAndEpoch(endOffset, lastEpochInSegment));\\n        // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n        // are not deleted before they are copied to remote storage.\\n        log.updateHighestOffsetInRemoteStorage(endOffset);\\n        logger.info(\"Copied {} to remote storage with segment-id: {}\", logFileName, copySegmentFinishedRlsm.remoteLogSegmentId());\\n        long bytesLag = log.onlyLocalLogSegmentsSize() - log.activeSegment().size();\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        long segmentsLag = log.onlyLocalLogSegmentsCount();\\n        brokerTopicStats.recordRemoteCopyLagBytes(topic, partition, bytesLag);\\n        brokerTopicStats.recordRemoteCopyLagSegments(topic, partition, segmentsLag);\\n    }\\n\\n    private Path toPathIfExists(File file) {\\n        return file.exists() ? file.toPath() : null;\\n    }\\n\\n    public void run() {\\n        if (isCancelled())\\n            return;\\n        try {\\n            Optional<UnifiedLog> unifiedLogOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n            if (!unifiedLogOptional.isPresent()) {\\n                return;\\n            }\\n            UnifiedLog log = unifiedLogOptional.get();\\n            // In the first run after completing altering logDir within broker, we should make sure the state is reset. (KAFKA-16711)\\n            if (!log.parentDir().equals(logDirectory.orElse(null))) {\\n                copiedOffsetOption = Optional.empty();\\n                isLogStartOffsetUpdatedOnBecomingLeader = false;\\n                logDirectory = Optional.of(log.parentDir());\\n            }\\n            if (isLeader()) {\\n                // Copy log segments to remote storage\\n                copyLogSegmentsToRemote(log);\\n                // Cleanup/delete expired remote log segments\\n                cleanupExpiredRemoteLogSegments();\\n            } else {\\n                OffsetAndEpoch offsetAndEpoch = findHighestRemoteOffset(topicIdPartition, log);\\n                // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n                // are not deleted before they are copied to remote storage.\\n                log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset());\\n            }\\n        } catch (InterruptedException ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current thread for topic-partition-id {} is interrupted\", topicIdPartition, ex);\\n            }\\n        } catch (RetriableException ex) {\\n            logger.debug(\"Encountered a retryable error while executing current task for topic-partition {}\", topicIdPartition, ex);\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current task for topic-partition {} received error but it will be scheduled\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    public void handleLogStartOffsetUpdate(TopicPartition topicPartition, long remoteLogStartOffset) {\\n        if (isLeader()) {\\n            logger.debug(\"Updating {} with remoteLogStartOffset: {}\", topicPartition, remoteLogStartOffset);\\n            updateRemoteLogStartOffset.accept(topicPartition, remoteLogStartOffset);\\n        }\\n    }\\n\\n    class RemoteLogRetentionHandler {\\n\\n        private final Optional<RetentionSizeData> retentionSizeData;\\n\\n        private final Optional<RetentionTimeData> retentionTimeData;\\n\\n        private long remainingBreachedSize;\\n\\n        private OptionalLong logStartOffset = OptionalLong.empty();\\n\\n        public RemoteLogRetentionHandler(Optional<RetentionSizeData> retentionSizeData, Optional<RetentionTimeData> retentionTimeData) {\\n            this.retentionSizeData = retentionSizeData;\\n            this.retentionTimeData = retentionTimeData;\\n            remainingBreachedSize = retentionSizeData.map(sizeData -> sizeData.remainingBreachedSize).orElse(0L);\\n        }\\n\\n        private boolean isSegmentBreachedByRetentionSize(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionSizeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            // Assumption that segments contain size >= 0\\n            if (remainingBreachedSize > 0) {\\n                long remainingBytes = remainingBreachedSize - metadata.segmentSizeInBytes();\\n                if (remainingBytes >= 0) {\\n                    remainingBreachedSize = remainingBytes;\\n                    shouldDeleteSegment = true;\\n                }\\n            }\\n            if (shouldDeleteSegment) {\\n                logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\", metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        public boolean isSegmentBreachedByRetentionTime(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionTimeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            shouldDeleteSegment = metadata.maxTimestampMs() <= retentionTimeData.get().cleanupUntilMs;\\n            if (shouldDeleteSegment) {\\n                remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                // are ascending with in an epoch.\\n                logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\", metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        private boolean isSegmentBreachByLogStartOffset(RemoteLogSegmentMetadata metadata, long logStartOffset, NavigableMap<Integer, Long> leaderEpochEntries) {\\n            boolean shouldDeleteSegment = false;\\n            if (!leaderEpochEntries.isEmpty()) {\\n                // Note that `logStartOffset` and `leaderEpochEntries.firstEntry().getValue()` should be same\\n                Integer firstEpoch = leaderEpochEntries.firstKey();\\n                shouldDeleteSegment = metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch <= firstEpoch) && metadata.endOffset() < logStartOffset;\\n            }\\n            if (shouldDeleteSegment) {\\n                logger.info(\"About to delete remote log segment {} due to log-start-offset {} breach. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), logStartOffset, leaderEpochEntries.firstEntry(), metadata.endOffset(), metadata.segmentLeaderEpochs());\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        // It removes the segments beyond the current leader\\'s earliest epoch. Those segments are considered as\\n        // unreferenced because they are not part of the current leader epoch lineage.\\n        private boolean deleteLogSegmentsDueToLeaderEpochCacheTruncation(EpochEntry earliestEpochEntry, RemoteLogSegmentMetadata metadata) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            boolean isSegmentDeleted = deleteRemoteLogSegment(metadata, ignored -> metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch < earliestEpochEntry.epoch));\\n            if (isSegmentDeleted) {\\n                logger.info(\"Deleted remote log segment {} due to leader-epoch-cache truncation. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), earliestEpochEntry, metadata.endOffset(), metadata.segmentLeaderEpochs().keySet());\\n            }\\n            // No need to update the log-start-offset as these epochs/offsets are earlier to that value.\\n            return isSegmentDeleted;\\n        }\\n\\n        private boolean deleteRemoteLogSegment(RemoteLogSegmentMetadata segmentMetadata, Predicate<RemoteLogSegmentMetadata> predicate) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            if (predicate.test(segmentMetadata)) {\\n                logger.debug(\"Deleting remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                String topic = segmentMetadata.topicIdPartition().topic();\\n                // Publish delete segment started event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_STARTED, brokerId)).get();\\n                brokerTopicStats.topicStats(topic).remoteDeleteRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().mark();\\n                // Delete the segment in remote storage.\\n                try {\\n                    remoteLogStorageManager.deleteLogSegmentData(segmentMetadata);\\n                } catch (RemoteStorageException e) {\\n                    brokerTopicStats.topicStats(topic).failedRemoteDeleteRequestRate().mark();\\n                    brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().mark();\\n                    throw e;\\n                }\\n                // Publish delete segment finished event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_FINISHED, brokerId)).get();\\n                logger.debug(\"Deleted remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                return true;\\n            }\\n            return false;\\n        }\\n    }\\n\\n    private void updateMetadataCountAndLogSizeWith(int metadataCount, long remoteLogSizeBytes) {\\n        int partition = topicIdPartition.partition();\\n        String topic = topicIdPartition.topic();\\n        brokerTopicStats.recordRemoteLogMetadataCount(topic, partition, metadataCount);\\n        brokerTopicStats.recordRemoteLogSizeBytes(topic, partition, remoteLogSizeBytes);\\n    }\\n\\n    private void updateRemoteDeleteLagWith(int segmentsLeftToDelete, long sizeOfDeletableSegmentsBytes) {\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        brokerTopicStats.recordRemoteDeleteLagSegments(topic, partition, segmentsLeftToDelete);\\n        brokerTopicStats.recordRemoteDeleteLagBytes(topic, partition, sizeOfDeletableSegmentsBytes);\\n    }\\n\\n    void cleanupExpiredRemoteLogSegments() throws RemoteStorageException, ExecutionException, InterruptedException {\\n        if (isCancelled() || !isLeader()) {\\n            logger.info(\"Returning from remote log segments cleanup as the task state is changed\");\\n            return;\\n        }\\n        final Optional<UnifiedLog> logOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n        if (!logOptional.isPresent()) {\\n            logger.debug(\"No UnifiedLog instance available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final UnifiedLog log = logOptional.get();\\n        final Option<LeaderEpochFileCache> leaderEpochCacheOption = log.leaderEpochCache();\\n        if (leaderEpochCacheOption.isEmpty()) {\\n            logger.debug(\"No leader epoch cache available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        // Cleanup remote log segments and update the log start offset if applicable.\\n        final Iterator<RemoteLogSegmentMetadata> segmentMetadataIter = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition);\\n        if (!segmentMetadataIter.hasNext()) {\\n            updateMetadataCountAndLogSizeWith(0, 0);\\n            logger.debug(\"No remote log segments available on remote storage for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final Set<Integer> epochsSet = new HashSet<>();\\n        int metadataCount = 0;\\n        long remoteLogSizeBytes = 0;\\n        // Good to have an API from RLMM to get all the remote leader epochs of all the segments of a partition\\n        // instead of going through all the segments and building it here.\\n        while (segmentMetadataIter.hasNext()) {\\n            RemoteLogSegmentMetadata segmentMetadata = segmentMetadataIter.next();\\n            epochsSet.addAll(segmentMetadata.segmentLeaderEpochs().keySet());\\n            metadataCount++;\\n            remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n        }\\n        updateMetadataCountAndLogSizeWith(metadataCount, remoteLogSizeBytes);\\n        // All the leader epochs in sorted order that exists in remote storage\\n        final List<Integer> remoteLeaderEpochs = new ArrayList<>(epochsSet);\\n        Collections.sort(remoteLeaderEpochs);\\n        LeaderEpochFileCache leaderEpochCache = leaderEpochCacheOption.get();\\n        // Build the leader epoch map by filtering the epochs that do not have any records.\\n        NavigableMap<Integer, Long> epochWithOffsets = buildFilteredLeaderEpochMap(leaderEpochCache.epochWithOffsets());\\n        long logStartOffset = log.logStartOffset();\\n        long logEndOffset = log.logEndOffset();\\n        Optional<RetentionSizeData> retentionSizeData = buildRetentionSizeData(log.config().retentionSize, log.onlyLocalLogSegmentsSize(), logEndOffset, epochWithOffsets);\\n        Optional<RetentionTimeData> retentionTimeData = buildRetentionTimeData(log.config().retentionMs);\\n        RemoteLogRetentionHandler remoteLogRetentionHandler = new RemoteLogRetentionHandler(retentionSizeData, retentionTimeData);\\n        Iterator<Integer> epochIterator = epochWithOffsets.navigableKeySet().iterator();\\n        boolean canProcess = true;\\n        List<RemoteLogSegmentMetadata> segmentsToDelete = new ArrayList<>();\\n        long sizeOfDeletableSegmentsBytes = 0L;\\n        while (canProcess && epochIterator.hasNext()) {\\n            Integer epoch = epochIterator.next();\\n            Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n            while (canProcess && segmentsIterator.hasNext()) {\\n                if (isCancelled() || !isLeader()) {\\n                    logger.info(\"Returning from remote log segments cleanup for the remaining segments as the task state is changed.\");\\n                    return;\\n                }\\n                RemoteLogSegmentMetadata metadata = segmentsIterator.next();\\n                if (RemoteLogSegmentState.DELETE_SEGMENT_FINISHED.equals(metadata.state())) {\\n                    continue;\\n                }\\n                if (segmentsToDelete.contains(metadata)) {\\n                    continue;\\n                }\\n                // When the log-start-offset is moved by the user, the leader-epoch-checkpoint file gets truncated\\n                // as per the log-start-offset. Until the rlm-cleaner-thread runs in the next iteration, those\\n                // remote log segments won\\'t be removed. The `isRemoteSegmentWithinLeaderEpoch` validates whether\\n                // the epochs present in the segment lies in the checkpoint file. It will always return false\\n                // since the checkpoint file was already truncated.\\n                boolean shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachByLogStartOffset(metadata, logStartOffset, epochWithOffsets);\\n                boolean isValidSegment = false;\\n                if (!shouldDeleteSegment) {\\n                    // check whether the segment contains the required epoch range with in the current leader epoch lineage.\\n                    isValidSegment = isRemoteSegmentWithinLeaderEpochs(metadata, logEndOffset, epochWithOffsets);\\n                    if (isValidSegment) {\\n                        shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachedByRetentionTime(metadata) || remoteLogRetentionHandler.isSegmentBreachedByRetentionSize(metadata);\\n                    }\\n                }\\n                if (shouldDeleteSegment) {\\n                    segmentsToDelete.add(metadata);\\n                    sizeOfDeletableSegmentsBytes += metadata.segmentSizeInBytes();\\n                }\\n                canProcess = shouldDeleteSegment || !isValidSegment;\\n            }\\n        }\\n        // Update log start offset with the computed value after retention cleanup is done\\n        remoteLogRetentionHandler.logStartOffset.ifPresent(offset -> handleLogStartOffsetUpdate(topicIdPartition.topicPartition(), offset));\\n        // At this point in time we have updated the log start offsets, but not initiated a deletion.\\n        // Either a follower has picked up the changes to the log start offset, or they have not.\\n        // If the follower HAS picked up the changes, and they become the leader this replica won\\'t successfully complete\\n        // the deletion.\\n        // However, the new leader will correctly pick up all breaching segments as log start offset breaching ones\\n        // and delete them accordingly.\\n        // If the follower HAS NOT picked up the changes, and they become the leader then they will go through this process\\n        // again and delete them with the original deletion reason i.e. size, time or log start offset breach.\\n        int segmentsLeftToDelete = segmentsToDelete.size();\\n        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n        List<String> undeletedSegments = new ArrayList<>();\\n        for (RemoteLogSegmentMetadata segmentMetadata : segmentsToDelete) {\\n            if (!remoteLogRetentionHandler.deleteRemoteLogSegment(segmentMetadata, x -> !isCancelled() && isLeader())) {\\n                undeletedSegments.add(segmentMetadata.remoteLogSegmentId().toString());\\n            } else {\\n                sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                segmentsLeftToDelete--;\\n                updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            }\\n        }\\n        if (!undeletedSegments.isEmpty()) {\\n            logger.info(\"The following remote segments could not be deleted: {}\", String.join(\",\", undeletedSegments));\\n        }\\n        // Remove the remote log segments whose segment-leader-epochs are less than the earliest-epoch known\\n        // to the leader. This will remove the unreferenced segments in the remote storage. This is needed for\\n        // unclean leader election scenarios as the remote storage can have epochs earlier to the current leader\\'s\\n        // earliest leader epoch.\\n        Optional<EpochEntry> earliestEpochEntryOptional = leaderEpochCache.earliestEntry();\\n        if (earliestEpochEntryOptional.isPresent()) {\\n            EpochEntry earliestEpochEntry = earliestEpochEntryOptional.get();\\n            Iterator<Integer> epochsToClean = remoteLeaderEpochs.stream().filter(remoteEpoch -> remoteEpoch < earliestEpochEntry.epoch).iterator();\\n            List<RemoteLogSegmentMetadata> listOfSegmentsToBeCleaned = new ArrayList<>();\\n            while (epochsToClean.hasNext()) {\\n                int epoch = epochsToClean.next();\\n                Iterator<RemoteLogSegmentMetadata> segmentsToBeCleaned = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsToBeCleaned.hasNext()) {\\n                    if (!isCancelled() && isLeader()) {\\n                        RemoteLogSegmentMetadata nextSegmentMetadata = segmentsToBeCleaned.next();\\n                        sizeOfDeletableSegmentsBytes += nextSegmentMetadata.segmentSizeInBytes();\\n                        listOfSegmentsToBeCleaned.add(nextSegmentMetadata);\\n                    }\\n                }\\n            }\\n            segmentsLeftToDelete += listOfSegmentsToBeCleaned.size();\\n            updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            for (RemoteLogSegmentMetadata segmentMetadata : listOfSegmentsToBeCleaned) {\\n                if (!isCancelled() && isLeader()) {\\n                    // No need to update the log-start-offset even though the segment is deleted as these epochs/offsets are earlier to that value.\\n                    if (remoteLogRetentionHandler.deleteLogSegmentsDueToLeaderEpochCacheTruncation(earliestEpochEntry, segmentMetadata)) {\\n                        sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                        segmentsLeftToDelete--;\\n                        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n                    }\\n                }\\n            }\\n        }\\n    }\\n\\n    private Optional<RetentionTimeData> buildRetentionTimeData(long retentionMs) {\\n        return retentionMs > -1 ? Optional.of(new RetentionTimeData(retentionMs, time.milliseconds() - retentionMs)) : Optional.empty();\\n    }\\n\\n    private Optional<RetentionSizeData> buildRetentionSizeData(long retentionSize, long onlyLocalLogSegmentsSize, long logEndOffset, NavigableMap<Integer, Long> epochEntries) throws RemoteStorageException {\\n        if (retentionSize > -1) {\\n            long startTimeMs = time.milliseconds();\\n            long remoteLogSizeBytes = 0L;\\n            Set<RemoteLogSegmentId> visitedSegmentIds = new HashSet<>();\\n            for (Integer epoch : epochEntries.navigableKeySet()) {\\n                // remoteLogSize(topicIdPartition, epochEntry.epoch) may not be completely accurate as the remote\\n                // log size may be computed for all the segments but not for segments with in the current\\n                // partition\\'s leader epoch lineage. Better to revisit this API.\\n                // remoteLogSizeBytes += remoteLogMetadataManager.remoteLogSize(topicIdPartition, epochEntry.epoch);\\n                Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsIterator.hasNext()) {\\n                    RemoteLogSegmentMetadata segmentMetadata = segmentsIterator.next();\\n                    RemoteLogSegmentId segmentId = segmentMetadata.remoteLogSegmentId();\\n                    if (!visitedSegmentIds.contains(segmentId) && isRemoteSegmentWithinLeaderEpochs(segmentMetadata, logEndOffset, epochEntries)) {\\n                        remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n                        visitedSegmentIds.add(segmentId);\\n                    }\\n                }\\n            }\\n            brokerTopicStats.recordRemoteLogSizeComputationTime(topicIdPartition.topic(), topicIdPartition.partition(), time.milliseconds() - startTimeMs);\\n            // This is the total size of segments in local log that have their base-offset > local-log-start-offset\\n            // and size of the segments in remote storage which have their end-offset < local-log-start-offset.\\n            long totalSize = onlyLocalLogSegmentsSize + remoteLogSizeBytes;\\n            if (totalSize > retentionSize) {\\n                long remainingBreachedSize = totalSize - retentionSize;\\n                RetentionSizeData retentionSizeData = new RetentionSizeData(retentionSize, remainingBreachedSize);\\n                return Optional.of(retentionSizeData);\\n            }\\n        }\\n        return Optional.empty();\\n    }\\n\\n    public String toString() {\\n        return this.getClass() + \"[\" + topicIdPartition + \"]\";\\n    }\\n}\\n}\\n\\ncore/src/main/java/kafka/log/remote/RemoteLogManager.java (After)\\npublic class RemoteLogManager implements Closeable {\\nclass RLMTask extends CancellableRunnable {\\n\\n    private final TopicIdPartition topicIdPartition;\\n\\n    private final int customMetadataSizeLimit;\\n\\n    private final Logger logger;\\n\\n    private volatile int leaderEpoch = -1;\\n\\n    public RLMTask(TopicIdPartition topicIdPartition, int customMetadataSizeLimit) {\\n        this.topicIdPartition = topicIdPartition;\\n        this.customMetadataSizeLimit = customMetadataSizeLimit;\\n        LogContext logContext = new LogContext(\"[RemoteLogManager=\" + brokerId + \" partition=\" + topicIdPartition + \"] \");\\n        logger = logContext.logger(RLMTask.class);\\n    }\\n\\n    boolean isLeader() {\\n        return leaderEpoch >= 0;\\n    }\\n\\n    // The copied and log-start offset is empty initially for a new leader RLMTask, and needs to be fetched inside\\n    // the task\\'s run() method.\\n    private volatile Optional<OffsetAndEpoch> copiedOffsetOption = Optional.empty();\\n\\n    private volatile boolean isLogStartOffsetUpdatedOnBecomingLeader = false;\\n\\n    private volatile Optional<String> logDirectory = Optional.empty();\\n\\n    public void convertToLeader(int leaderEpochVal) {\\n        if (leaderEpochVal < 0) {\\n            throw new KafkaException(\"leaderEpoch value for topic partition \" + topicIdPartition + \" can not be negative\");\\n        }\\n        if (this.leaderEpoch != leaderEpochVal) {\\n            leaderEpoch = leaderEpochVal;\\n        }\\n        // Reset copied and log-start offset, so that it is set in next run of RLMTask\\n        copiedOffsetOption = Optional.empty();\\n        isLogStartOffsetUpdatedOnBecomingLeader = false;\\n    }\\n\\n    public void convertToFollower() {\\n        leaderEpoch = -1;\\n    }\\n\\n    private void maybeUpdateLogStartOffsetOnBecomingLeader(UnifiedLog log) throws RemoteStorageException {\\n        if (!isLogStartOffsetUpdatedOnBecomingLeader) {\\n            long logStartOffset = findLogStartOffset(topicIdPartition, log);\\n            updateRemoteLogStartOffset.accept(topicIdPartition.topicPartition(), logStartOffset);\\n            isLogStartOffsetUpdatedOnBecomingLeader = true;\\n            logger.info(\"Found the logStartOffset: {} for partition: {} after becoming leader, leaderEpoch: {}\", logStartOffset, topicIdPartition, leaderEpoch);\\n        }\\n    }\\n\\n    private void maybeUpdateCopiedOffset(UnifiedLog log) throws RemoteStorageException {\\n        if (!copiedOffsetOption.isPresent()) {\\n            // This is found by traversing from the latest leader epoch from leader epoch history and find the highest offset\\n            // of a segment with that epoch copied into remote storage. If it can not find an entry then it checks for the\\n            // previous leader epoch till it finds an entry, If there are no entries till the earliest leader epoch in leader\\n            // epoch cache then it starts copying the segments from the earliest epoch entry\\'s offset.\\n            copiedOffsetOption = Optional.of(findHighestRemoteOffset(topicIdPartition, log));\\n            logger.info(\"Found the highest copiedRemoteOffset: {} for partition: {} after becoming leader, \" + \"leaderEpoch: {}\", copiedOffsetOption, topicIdPartition, leaderEpoch);\\n            copiedOffsetOption.ifPresent(offsetAndEpoch -> log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset()));\\n        }\\n    }\\n\\n    /**\\n     *  Segments which match the following criteria are eligible for copying to remote storage:\\n     *  1) Segment is not the active segment and\\n     *  2) Segment end-offset is less than the last-stable-offset as remote storage should contain only\\n     *     committed/acked messages\\n     * @param log The log from which the segments are to be copied\\n     * @param fromOffset The offset from which the segments are to be copied\\n     * @param lastStableOffset The last stable offset of the log\\n     * @return candidate log segments to be copied to remote storage\\n     */\\n    List<EnrichedLogSegment> candidateLogSegments(UnifiedLog log, Long fromOffset, Long lastStableOffset) {\\n        List<EnrichedLogSegment> candidateLogSegments = new ArrayList<>();\\n        List<LogSegment> segments = JavaConverters.seqAsJavaList(log.logSegments(fromOffset, Long.MAX_VALUE).toSeq());\\n        if (!segments.isEmpty()) {\\n            for (int idx = 1; idx < segments.size(); idx++) {\\n                LogSegment previousSeg = segments.get(idx - 1);\\n                LogSegment currentSeg = segments.get(idx);\\n                if (currentSeg.baseOffset() <= lastStableOffset) {\\n                    candidateLogSegments.add(new EnrichedLogSegment(previousSeg, currentSeg.baseOffset()));\\n                }\\n            }\\n            // Discard the last active segment\\n        }\\n        return candidateLogSegments;\\n    }\\n\\n    public void copyLogSegmentsToRemote(UnifiedLog log) throws InterruptedException {\\n        if (isCancelled())\\n            return;\\n        try {\\n            maybeUpdateLogStartOffsetOnBecomingLeader(log);\\n            maybeUpdateCopiedOffset(log);\\n            long copiedOffset = copiedOffsetOption.get().offset();\\n            // LSO indicates the offset below are ready to be consumed (high-watermark or committed)\\n            long lso = log.lastStableOffset();\\n            if (lso < 0) {\\n                logger.warn(\"lastStableOffset for partition {} is {}, which should not be negative.\", topicIdPartition, lso);\\n            } else if (lso > 0 && copiedOffset < lso) {\\n                // log-start-offset can be ahead of the copied-offset, when:\\n                // 1) log-start-offset gets incremented via delete-records API (or)\\n                // 2) enabling the remote log for the first time\\n                long fromOffset = Math.max(copiedOffset + 1, log.logStartOffset());\\n                List<EnrichedLogSegment> candidateLogSegments = candidateLogSegments(log, fromOffset, lso);\\n                logger.debug(\"Candidate log segments, logStartOffset: {}, copiedOffset: {}, fromOffset: {}, lso: {} \" + \"and candidateLogSegments: {}\", log.logStartOffset(), copiedOffset, fromOffset, lso, candidateLogSegments);\\n                if (candidateLogSegments.isEmpty()) {\\n                    logger.debug(\"No segments found to be copied for partition {} with copiedOffset: {} and active segment\\'s base-offset: {}\", topicIdPartition, copiedOffset, log.activeSegment().baseOffset());\\n                } else {\\n                    for (EnrichedLogSegment candidateLogSegment : candidateLogSegments) {\\n                        if (isCancelled() || !isLeader()) {\\n                            logger.info(\"Skipping copying log segments as the current task state is changed, cancelled: {} leader:{}\", isCancelled(), isLeader());\\n                            return;\\n                        }\\n                        copyQuotaManagerLock.lock();\\n                        try {\\n                            while (rlmCopyQuotaManager.isQuotaExceeded()) {\\n                                logger.debug(\"Quota exceeded for copying log segments, waiting for the quota to be available.\");\\n                                // If the thread gets interrupted while waiting, the InterruptedException is thrown\\n                                // back to the caller. It\\'s important to note that the task being executed is already\\n                                // cancelled before the executing thread is interrupted. The caller is responsible\\n                                // for handling the exception gracefully by checking if the task is already cancelled.\\n                                boolean ignored = copyQuotaManagerLockCondition.await(quotaTimeout().toMillis(), TimeUnit.MILLISECONDS);\\n                            }\\n                            rlmCopyQuotaManager.record(candidateLogSegment.logSegment.log().sizeInBytes());\\n                            // Signal waiting threads to check the quota again\\n                            copyQuotaManagerLockCondition.signalAll();\\n                        } finally {\\n                            copyQuotaManagerLock.unlock();\\n                        }\\n                        copyLogSegment(log, candidateLogSegment.logSegment, candidateLogSegment.nextSegmentOffset);\\n                    }\\n                }\\n            } else {\\n                logger.debug(\"Skipping copying segments, current read-offset:{}, and LSO:{}\", copiedOffset, lso);\\n            }\\n        } catch (CustomMetadataSizeLimitExceededException e) {\\n            // Only stop this task. Logging is done where the exception is thrown.\\n            brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n            brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n            this.cancel();\\n        } catch (InterruptedException | RetriableException ex) {\\n            throw ex;\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n                logger.error(\"Error occurred while copying log segments of partition: {}\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    private void copyLogSegment(UnifiedLog log, LogSegment segment, long nextSegmentBaseOffset) throws InterruptedException, ExecutionException, RemoteStorageException, IOException, CustomMetadataSizeLimitExceededException {\\n        File logFile = segment.log().file();\\n        String logFileName = logFile.getName();\\n        logger.info(\"Copying {} to remote storage.\", logFileName);\\n        RemoteLogSegmentId id = RemoteLogSegmentId.generateNew(topicIdPartition);\\n        long endOffset = nextSegmentBaseOffset - 1;\\n        File producerStateSnapshotFile = log.producerStateManager().fetchSnapshot(nextSegmentBaseOffset).orElse(null);\\n        List<EpochEntry> epochEntries = getLeaderEpochEntries(log, segment.baseOffset(), nextSegmentBaseOffset);\\n        Map<Integer, Long> segmentLeaderEpochs = new HashMap<>(epochEntries.size());\\n        epochEntries.forEach(entry -> segmentLeaderEpochs.put(entry.epoch, entry.startOffset));\\n        RemoteLogSegmentMetadata copySegmentStartedRlsm = new RemoteLogSegmentMetadata(id, segment.baseOffset(), endOffset, segment.largestTimestamp(), brokerId, time.milliseconds(), segment.log().sizeInBytes(), segmentLeaderEpochs);\\n        remoteLogMetadataManager.addRemoteLogSegmentMetadata(copySegmentStartedRlsm).get();\\n        ByteBuffer leaderEpochsIndex = epochEntriesAsByteBuffer(getLeaderEpochEntries(log, -1, nextSegmentBaseOffset));\\n        LogSegmentData segmentData = new LogSegmentData(logFile.toPath(), toPathIfExists(segment.offsetIndex().file()), toPathIfExists(segment.timeIndex().file()), Optional.ofNullable(toPathIfExists(segment.txnIndex().file())), producerStateSnapshotFile.toPath(), leaderEpochsIndex);\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyRequestRate().mark();\\n        brokerTopicStats.allTopicsStats().remoteCopyRequestRate().mark();\\n        Optional<CustomMetadata> customMetadata = remoteLogStorageManager.copyLogSegmentData(copySegmentStartedRlsm, segmentData);\\n        RemoteLogSegmentMetadataUpdate copySegmentFinishedRlsm = new RemoteLogSegmentMetadataUpdate(id, time.milliseconds(), customMetadata, RemoteLogSegmentState.COPY_SEGMENT_FINISHED, brokerId);\\n        if (customMetadata.isPresent()) {\\n            long customMetadataSize = customMetadata.get().value().length;\\n            if (customMetadataSize > this.customMetadataSizeLimit) {\\n                CustomMetadataSizeLimitExceededException e = new CustomMetadataSizeLimitExceededException();\\n                logger.error(\"Custom metadata size {} exceeds configured limit {}.\" + \" Copying will be stopped and copied segment will be attempted to clean.\" + \" Original metadata: {}\", customMetadataSize, this.customMetadataSizeLimit, copySegmentStartedRlsm, e);\\n                try {\\n                    // For deletion, we provide back the custom metadata by creating a new metadata object from the update.\\n                    // However, the update itself will not be stored in this case.\\n                    remoteLogStorageManager.deleteLogSegmentData(copySegmentStartedRlsm.createWithUpdates(copySegmentFinishedRlsm));\\n                    logger.info(\"Successfully cleaned segment after custom metadata size exceeded\");\\n                } catch (RemoteStorageException e1) {\\n                    logger.error(\"Error while cleaning segment after custom metadata size exceeded, consider cleaning manually\", e1);\\n                }\\n                throw e;\\n            }\\n        }\\n        remoteLogMetadataManager.updateRemoteLogSegmentMetadata(copySegmentFinishedRlsm).get();\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        brokerTopicStats.allTopicsStats().remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        // `epochEntries` cannot be empty, there is a pre-condition validation in RemoteLogSegmentMetadata\\n        // constructor\\n        int lastEpochInSegment = epochEntries.get(epochEntries.size() - 1).epoch;\\n        copiedOffsetOption = Optional.of(new OffsetAndEpoch(endOffset, lastEpochInSegment));\\n        // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n        // are not deleted before they are copied to remote storage.\\n        log.updateHighestOffsetInRemoteStorage(endOffset);\\n        logger.info(\"Copied {} to remote storage with segment-id: {}\", logFileName, copySegmentFinishedRlsm.remoteLogSegmentId());\\n        long bytesLag = log.onlyLocalLogSegmentsSize() - log.activeSegment().size();\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        long segmentsLag = log.onlyLocalLogSegmentsCount();\\n        brokerTopicStats.recordRemoteCopyLagBytes(topic, partition, bytesLag);\\n        brokerTopicStats.recordRemoteCopyLagSegments(topic, partition, segmentsLag);\\n    }\\n\\n    private Path toPathIfExists(File file) {\\n        return file.exists() ? file.toPath() : null;\\n    }\\n\\n    public void run() {\\n        if (isCancelled())\\n            return;\\n        try {\\n            Optional<UnifiedLog> unifiedLogOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n            if (!unifiedLogOptional.isPresent()) {\\n                return;\\n            }\\n            UnifiedLog log = unifiedLogOptional.get();\\n            // In the first run after completing altering logDir within broker, we should make sure the state is reset. (KAFKA-16711)\\n            if (!log.parentDir().equals(logDirectory.orElse(null))) {\\n                copiedOffsetOption = Optional.empty();\\n                isLogStartOffsetUpdatedOnBecomingLeader = false;\\n                logDirectory = Optional.of(log.parentDir());\\n            }\\n            if (isLeader()) {\\n                // Copy log segments to remote storage\\n                copyLogSegmentsToRemote(log);\\n                // Cleanup/delete expired remote log segments\\n                cleanupExpiredRemoteLogSegments();\\n            } else {\\n                OffsetAndEpoch offsetAndEpoch = findHighestRemoteOffset(topicIdPartition, log);\\n                // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n                // are not deleted before they are copied to remote storage.\\n                log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset());\\n            }\\n        } catch (InterruptedException ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current thread for topic-partition-id {} is interrupted\", topicIdPartition, ex);\\n            }\\n        } catch (RetriableException ex) {\\n            logger.debug(\"Encountered a retryable error while executing current task for topic-partition {}\", topicIdPartition, ex);\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current task for topic-partition {} received error but it will be scheduled\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    public void handleLogStartOffsetUpdate(TopicPartition topicPartition, long remoteLogStartOffset) {\\n        if (isLeader()) {\\n            logger.debug(\"Updating {} with remoteLogStartOffset: {}\", topicPartition, remoteLogStartOffset);\\n            updateRemoteLogStartOffset.accept(topicPartition, remoteLogStartOffset);\\n        }\\n    }\\n\\n    class RemoteLogRetentionHandler {\\n\\n        private final Optional<RetentionSizeData> retentionSizeData;\\n\\n        private final Optional<RetentionTimeData> retentionTimeData;\\n\\n        private long remainingBreachedSize;\\n\\n        private OptionalLong logStartOffset = OptionalLong.empty();\\n\\n        public RemoteLogRetentionHandler(Optional<RetentionSizeData> retentionSizeData, Optional<RetentionTimeData> retentionTimeData) {\\n            this.retentionSizeData = retentionSizeData;\\n            this.retentionTimeData = retentionTimeData;\\n            remainingBreachedSize = retentionSizeData.map(sizeData -> sizeData.remainingBreachedSize).orElse(0L);\\n        }\\n\\n        private boolean isSegmentBreachedByRetentionSize(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionSizeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            // Assumption that segments contain size >= 0\\n            if (remainingBreachedSize > 0) {\\n                long remainingBytes = remainingBreachedSize - metadata.segmentSizeInBytes();\\n                if (remainingBytes >= 0) {\\n                    remainingBreachedSize = remainingBytes;\\n                    shouldDeleteSegment = true;\\n                }\\n            }\\n            if (shouldDeleteSegment) {\\n                if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                }\\n                logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\", metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        public boolean isSegmentBreachedByRetentionTime(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionTimeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            shouldDeleteSegment = metadata.maxTimestampMs() <= retentionTimeData.get().cleanupUntilMs;\\n            if (shouldDeleteSegment) {\\n                remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                // are ascending with in an epoch.\\n                if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                }\\n                logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\", metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        private boolean isSegmentBreachByLogStartOffset(RemoteLogSegmentMetadata metadata, long logStartOffset, NavigableMap<Integer, Long> leaderEpochEntries) {\\n            boolean shouldDeleteSegment = false;\\n            if (!leaderEpochEntries.isEmpty()) {\\n                // Note that `logStartOffset` and `leaderEpochEntries.firstEntry().getValue()` should be same\\n                Integer firstEpoch = leaderEpochEntries.firstKey();\\n                shouldDeleteSegment = metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch <= firstEpoch) && metadata.endOffset() < logStartOffset;\\n            }\\n            if (shouldDeleteSegment) {\\n                logger.info(\"About to delete remote log segment {} due to log-start-offset {} breach. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), logStartOffset, leaderEpochEntries.firstEntry(), metadata.endOffset(), metadata.segmentLeaderEpochs());\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        // It removes the segments beyond the current leader\\'s earliest epoch. Those segments are considered as\\n        // unreferenced because they are not part of the current leader epoch lineage.\\n        private boolean deleteLogSegmentsDueToLeaderEpochCacheTruncation(EpochEntry earliestEpochEntry, RemoteLogSegmentMetadata metadata) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            boolean isSegmentDeleted = deleteRemoteLogSegment(metadata, ignored -> metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch < earliestEpochEntry.epoch));\\n            if (isSegmentDeleted) {\\n                logger.info(\"Deleted remote log segment {} due to leader-epoch-cache truncation. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), earliestEpochEntry, metadata.endOffset(), metadata.segmentLeaderEpochs().keySet());\\n            }\\n            // No need to update the log-start-offset as these epochs/offsets are earlier to that value.\\n            return isSegmentDeleted;\\n        }\\n\\n        private boolean deleteRemoteLogSegment(RemoteLogSegmentMetadata segmentMetadata, Predicate<RemoteLogSegmentMetadata> predicate) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            if (predicate.test(segmentMetadata)) {\\n                logger.debug(\"Deleting remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                String topic = segmentMetadata.topicIdPartition().topic();\\n                // Publish delete segment started event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_STARTED, brokerId)).get();\\n                brokerTopicStats.topicStats(topic).remoteDeleteRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().mark();\\n                // Delete the segment in remote storage.\\n                try {\\n                    remoteLogStorageManager.deleteLogSegmentData(segmentMetadata);\\n                } catch (RemoteStorageException e) {\\n                    brokerTopicStats.topicStats(topic).failedRemoteDeleteRequestRate().mark();\\n                    brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().mark();\\n                    throw e;\\n                }\\n                // Publish delete segment finished event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_FINISHED, brokerId)).get();\\n                logger.debug(\"Deleted remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                return true;\\n            }\\n            return false;\\n        }\\n    }\\n\\n    private void updateMetadataCountAndLogSizeWith(int metadataCount, long remoteLogSizeBytes) {\\n        int partition = topicIdPartition.partition();\\n        String topic = topicIdPartition.topic();\\n        brokerTopicStats.recordRemoteLogMetadataCount(topic, partition, metadataCount);\\n        brokerTopicStats.recordRemoteLogSizeBytes(topic, partition, remoteLogSizeBytes);\\n    }\\n\\n    private void updateRemoteDeleteLagWith(int segmentsLeftToDelete, long sizeOfDeletableSegmentsBytes) {\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        brokerTopicStats.recordRemoteDeleteLagSegments(topic, partition, segmentsLeftToDelete);\\n        brokerTopicStats.recordRemoteDeleteLagBytes(topic, partition, sizeOfDeletableSegmentsBytes);\\n    }\\n\\n    void cleanupExpiredRemoteLogSegments() throws RemoteStorageException, ExecutionException, InterruptedException {\\n        if (isCancelled() || !isLeader()) {\\n            logger.info(\"Returning from remote log segments cleanup as the task state is changed\");\\n            return;\\n        }\\n        final Optional<UnifiedLog> logOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n        if (!logOptional.isPresent()) {\\n            logger.debug(\"No UnifiedLog instance available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final UnifiedLog log = logOptional.get();\\n        final Option<LeaderEpochFileCache> leaderEpochCacheOption = log.leaderEpochCache();\\n        if (leaderEpochCacheOption.isEmpty()) {\\n            logger.debug(\"No leader epoch cache available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        // Cleanup remote log segments and update the log start offset if applicable.\\n        final Iterator<RemoteLogSegmentMetadata> segmentMetadataIter = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition);\\n        if (!segmentMetadataIter.hasNext()) {\\n            updateMetadataCountAndLogSizeWith(0, 0);\\n            logger.debug(\"No remote log segments available on remote storage for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final Set<Integer> epochsSet = new HashSet<>();\\n        int metadataCount = 0;\\n        long remoteLogSizeBytes = 0;\\n        // Good to have an API from RLMM to get all the remote leader epochs of all the segments of a partition\\n        // instead of going through all the segments and building it here.\\n        while (segmentMetadataIter.hasNext()) {\\n            RemoteLogSegmentMetadata segmentMetadata = segmentMetadataIter.next();\\n            epochsSet.addAll(segmentMetadata.segmentLeaderEpochs().keySet());\\n            metadataCount++;\\n            remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n        }\\n        updateMetadataCountAndLogSizeWith(metadataCount, remoteLogSizeBytes);\\n        // All the leader epochs in sorted order that exists in remote storage\\n        final List<Integer> remoteLeaderEpochs = new ArrayList<>(epochsSet);\\n        Collections.sort(remoteLeaderEpochs);\\n        LeaderEpochFileCache leaderEpochCache = leaderEpochCacheOption.get();\\n        // Build the leader epoch map by filtering the epochs that do not have any records.\\n        NavigableMap<Integer, Long> epochWithOffsets = buildFilteredLeaderEpochMap(leaderEpochCache.epochWithOffsets());\\n        long logStartOffset = log.logStartOffset();\\n        long logEndOffset = log.logEndOffset();\\n        Optional<RetentionSizeData> retentionSizeData = buildRetentionSizeData(log.config().retentionSize, log.onlyLocalLogSegmentsSize(), logEndOffset, epochWithOffsets);\\n        Optional<RetentionTimeData> retentionTimeData = buildRetentionTimeData(log.config().retentionMs);\\n        RemoteLogRetentionHandler remoteLogRetentionHandler = new RemoteLogRetentionHandler(retentionSizeData, retentionTimeData);\\n        Iterator<Integer> epochIterator = epochWithOffsets.navigableKeySet().iterator();\\n        boolean canProcess = true;\\n        List<RemoteLogSegmentMetadata> segmentsToDelete = new ArrayList<>();\\n        long sizeOfDeletableSegmentsBytes = 0L;\\n        while (canProcess && epochIterator.hasNext()) {\\n            Integer epoch = epochIterator.next();\\n            Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n            while (canProcess && segmentsIterator.hasNext()) {\\n                if (isCancelled() || !isLeader()) {\\n                    logger.info(\"Returning from remote log segments cleanup for the remaining segments as the task state is changed.\");\\n                    return;\\n                }\\n                RemoteLogSegmentMetadata metadata = segmentsIterator.next();\\n                if (RemoteLogSegmentState.DELETE_SEGMENT_FINISHED.equals(metadata.state())) {\\n                    continue;\\n                }\\n                if (segmentsToDelete.contains(metadata)) {\\n                    continue;\\n                }\\n                // When the log-start-offset is moved by the user, the leader-epoch-checkpoint file gets truncated\\n                // as per the log-start-offset. Until the rlm-cleaner-thread runs in the next iteration, those\\n                // remote log segments won\\'t be removed. The `isRemoteSegmentWithinLeaderEpoch` validates whether\\n                // the epochs present in the segment lies in the checkpoint file. It will always return false\\n                // since the checkpoint file was already truncated.\\n                boolean shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachByLogStartOffset(metadata, logStartOffset, epochWithOffsets);\\n                boolean isValidSegment = false;\\n                if (!shouldDeleteSegment) {\\n                    // check whether the segment contains the required epoch range with in the current leader epoch lineage.\\n                    isValidSegment = isRemoteSegmentWithinLeaderEpochs(metadata, logEndOffset, epochWithOffsets);\\n                    if (isValidSegment) {\\n                        shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachedByRetentionTime(metadata) || remoteLogRetentionHandler.isSegmentBreachedByRetentionSize(metadata);\\n                    }\\n                }\\n                if (shouldDeleteSegment) {\\n                    segmentsToDelete.add(metadata);\\n                    sizeOfDeletableSegmentsBytes += metadata.segmentSizeInBytes();\\n                }\\n                canProcess = shouldDeleteSegment || !isValidSegment;\\n            }\\n        }\\n        // Update log start offset with the computed value after retention cleanup is done\\n        remoteLogRetentionHandler.logStartOffset.ifPresent(offset -> handleLogStartOffsetUpdate(topicIdPartition.topicPartition(), offset));\\n        // At this point in time we have updated the log start offsets, but not initiated a deletion.\\n        // Either a follower has picked up the changes to the log start offset, or they have not.\\n        // If the follower HAS picked up the changes, and they become the leader this replica won\\'t successfully complete\\n        // the deletion.\\n        // However, the new leader will correctly pick up all breaching segments as log start offset breaching ones\\n        // and delete them accordingly.\\n        // If the follower HAS NOT picked up the changes, and they become the leader then they will go through this process\\n        // again and delete them with the original deletion reason i.e. size, time or log start offset breach.\\n        int segmentsLeftToDelete = segmentsToDelete.size();\\n        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n        List<String> undeletedSegments = new ArrayList<>();\\n        for (RemoteLogSegmentMetadata segmentMetadata : segmentsToDelete) {\\n            if (!remoteLogRetentionHandler.deleteRemoteLogSegment(segmentMetadata, x -> !isCancelled() && isLeader())) {\\n                undeletedSegments.add(segmentMetadata.remoteLogSegmentId().toString());\\n            } else {\\n                sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                segmentsLeftToDelete--;\\n                updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            }\\n        }\\n        if (!undeletedSegments.isEmpty()) {\\n            logger.info(\"The following remote segments could not be deleted: {}\", String.join(\",\", undeletedSegments));\\n        }\\n        // Remove the remote log segments whose segment-leader-epochs are less than the earliest-epoch known\\n        // to the leader. This will remove the unreferenced segments in the remote storage. This is needed for\\n        // unclean leader election scenarios as the remote storage can have epochs earlier to the current leader\\'s\\n        // earliest leader epoch.\\n        Optional<EpochEntry> earliestEpochEntryOptional = leaderEpochCache.earliestEntry();\\n        if (earliestEpochEntryOptional.isPresent()) {\\n            EpochEntry earliestEpochEntry = earliestEpochEntryOptional.get();\\n            Iterator<Integer> epochsToClean = remoteLeaderEpochs.stream().filter(remoteEpoch -> remoteEpoch < earliestEpochEntry.epoch).iterator();\\n            List<RemoteLogSegmentMetadata> listOfSegmentsToBeCleaned = new ArrayList<>();\\n            while (epochsToClean.hasNext()) {\\n                int epoch = epochsToClean.next();\\n                Iterator<RemoteLogSegmentMetadata> segmentsToBeCleaned = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsToBeCleaned.hasNext()) {\\n                    if (!isCancelled() && isLeader()) {\\n                        RemoteLogSegmentMetadata nextSegmentMetadata = segmentsToBeCleaned.next();\\n                        sizeOfDeletableSegmentsBytes += nextSegmentMetadata.segmentSizeInBytes();\\n                        listOfSegmentsToBeCleaned.add(nextSegmentMetadata);\\n                    }\\n                }\\n            }\\n            segmentsLeftToDelete += listOfSegmentsToBeCleaned.size();\\n            updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            for (RemoteLogSegmentMetadata segmentMetadata : listOfSegmentsToBeCleaned) {\\n                if (!isCancelled() && isLeader()) {\\n                    // No need to update the log-start-offset even though the segment is deleted as these epochs/offsets are earlier to that value.\\n                    if (remoteLogRetentionHandler.deleteLogSegmentsDueToLeaderEpochCacheTruncation(earliestEpochEntry, segmentMetadata)) {\\n                        sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                        segmentsLeftToDelete--;\\n                        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n                    }\\n                }\\n            }\\n        }\\n    }\\n\\n    private Optional<RetentionTimeData> buildRetentionTimeData(long retentionMs) {\\n        return retentionMs > -1 ? Optional.of(new RetentionTimeData(retentionMs, time.milliseconds() - retentionMs)) : Optional.empty();\\n    }\\n\\n    private Optional<RetentionSizeData> buildRetentionSizeData(long retentionSize, long onlyLocalLogSegmentsSize, long logEndOffset, NavigableMap<Integer, Long> epochEntries) throws RemoteStorageException {\\n        if (retentionSize > -1) {\\n            long startTimeMs = time.milliseconds();\\n            long remoteLogSizeBytes = 0L;\\n            Set<RemoteLogSegmentId> visitedSegmentIds = new HashSet<>();\\n            for (Integer epoch : epochEntries.navigableKeySet()) {\\n                // remoteLogSize(topicIdPartition, epochEntry.epoch) may not be completely accurate as the remote\\n                // log size may be computed for all the segments but not for segments with in the current\\n                // partition\\'s leader epoch lineage. Better to revisit this API.\\n                // remoteLogSizeBytes += remoteLogMetadataManager.remoteLogSize(topicIdPartition, epochEntry.epoch);\\n                Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsIterator.hasNext()) {\\n                    RemoteLogSegmentMetadata segmentMetadata = segmentsIterator.next();\\n                    RemoteLogSegmentId segmentId = segmentMetadata.remoteLogSegmentId();\\n                    if (!visitedSegmentIds.contains(segmentId) && isRemoteSegmentWithinLeaderEpochs(segmentMetadata, logEndOffset, epochEntries)) {\\n                        remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n                        visitedSegmentIds.add(segmentId);\\n                    }\\n                }\\n            }\\n            brokerTopicStats.recordRemoteLogSizeComputationTime(topicIdPartition.topic(), topicIdPartition.partition(), time.milliseconds() - startTimeMs);\\n            // This is the total size of segments in local log that have their base-offset > local-log-start-offset\\n            // and size of the segments in remote storage which have their end-offset < local-log-start-offset.\\n            long totalSize = onlyLocalLogSegmentsSize + remoteLogSizeBytes;\\n            if (totalSize > retentionSize) {\\n                long remainingBreachedSize = totalSize - retentionSize;\\n                RetentionSizeData retentionSizeData = new RetentionSizeData(retentionSize, remainingBreachedSize);\\n                return Optional.of(retentionSizeData);\\n            }\\n        }\\n        return Optional.empty();\\n    }\\n\\n    public String toString() {\\n        return this.getClass() + \"[\" + topicIdPartition + \"]\";\\n    }\\n}\\n}\\n\\ncore/src/test/java/kafka/log/remote/RemoteLogManagerTest.java (Before)\\npublic class RemoteLogManagerTest {\\n@ParameterizedTest(name = \"testDeletionOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    doAnswer(ans -> {\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic)));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments\"), String.format(\"Expected to find 2 for RemoteDeleteLagSegments metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments\")));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 2 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).doAnswer(ans -> {\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).when(remoteStorageManager).deleteLogSegmentData(any(RemoteLogSegmentMetadata.class));\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagBytes\"));\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagSegments\"));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic));\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n}\\n}\\n\\ncore/src/test/java/kafka/log/remote/RemoteLogManagerTest.java (After)\\npublic class RemoteLogManagerTest {\\n@ParameterizedTest(name = \"testDeletionOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED).get(0);\\n    // overlapping segment\\n    RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()), metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(), metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128, metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n    // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n    // returns the segments in order of (valid ++ unreferenced) segments:\\n    // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n    //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n    //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n    // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n    List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n    metadataList.add(metadata2);\\n    metadataList.add(metadata1);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    doAnswer(ans -> {\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic)));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments\"), String.format(\"Expected to find 2 for RemoteDeleteLagSegments metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments\")));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 2 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).doAnswer(ans -> {\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).when(remoteStorageManager).deleteLogSegmentData(any(RemoteLogSegmentMetadata.class));\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagBytes\"));\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagSegments\"));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic));\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n}\\n}\\n\\n\\nSummary:', 'role': 'user'}], 'model': 'deepseek/deepseek-r1-distill-qwen-32b', 'max_tokens': 4096, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /info HTTP/11\" 200 672\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 34\n",
      "DEBUG:httpcore.connection:connect_tcp.failed exception=ConnectError(gaierror(11001, 'getaddrinfo failed'))\n",
      "DEBUG:openai._base_client:Encountered Exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"C:\\Users\\johan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 996, in _request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 916, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 944, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 981, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 1016, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\johan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 11001] getaddrinfo failed\n",
      "DEBUG:openai._base_client:2 retries left\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.395627 seconds\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. Summarize in exactly two concise sentences. \\n\\nAvoid adding any additional comments or annotations to the summary.\\n\\nGit diff:\\ndiff --git a/core/src/main/java/kafka/log/remote/RemoteLogManager.java b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\nindex c1c87d579e..3eacbea475 100644\\n--- a/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n+++ b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n@@ -983,7 +983,9 @@ public class RemoteLogManager implements Closeable {\\n                     }\\n                 }\\n                 if (shouldDeleteSegment) {\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\",\\n                             metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n                 }\\n@@ -1000,7 +1002,9 @@ public class RemoteLogManager implements Closeable {\\n                     remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                     // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                     // are ascending with in an epoch.\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\",\\n                             metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n                 }\\ndiff --git a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\nindex 4c4976f060..3c9b8a48e9 100644\\n--- a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n+++ b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n@@ -2055,6 +2055,75 @@ public class RemoteLogManagerTest {\\n         assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n     }\\n \\n+    @ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n+    @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n+    public void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize,\\n+                                                                   long retentionMs)\\n+            throws RemoteStorageException, ExecutionException, InterruptedException {\\n+        Map<String, Long> logProps = new HashMap<>();\\n+        logProps.put(\"retention.bytes\", retentionSize);\\n+        logProps.put(\"retention.ms\", retentionMs);\\n+        LogConfig mockLogConfig = new LogConfig(logProps);\\n+        when(mockLog.config()).thenReturn(mockLogConfig);\\n+\\n+        List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n+        checkpoint.write(epochEntries);\\n+        LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n+        when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n+\\n+        when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n+        when(mockLog.logEndOffset()).thenReturn(200L);\\n+\\n+        RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024,\\n+                epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED)\\n+                .get(0);\\n+        // overlapping segment\\n+        RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()),\\n+                metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(),\\n+                metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128,\\n+                metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n+\\n+        // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n+        // returns the segments in order of (valid ++ unreferenced) segments:\\n+        // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n+        //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n+        //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n+        // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n+        List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n+        metadataList.add(metadata2);\\n+        metadataList.add(metadata1);\\n+\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition))\\n+                .thenReturn(metadataList.iterator());\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0))\\n+                .thenAnswer(ans -> metadataList.iterator());\\n+        when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class)))\\n+                .thenReturn(CompletableFuture.runAsync(() -> { }));\\n+\\n+        // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+\\n+        RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n+        task.convertToLeader(0);\\n+        task.cleanupExpiredRemoteLogSegments();\\n+\\n+        assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n+\\n+        // Verify the metric for remote delete is updated correctly\\n+        assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        // Verify we did not report any failure for remote deletes\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+    }\\n+\\n     @ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n     @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n     public void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize,\\n\\n\\nSource code:\\ncore/src/main/java/kafka/log/remote/RemoteLogManager.java (Before)\\npublic class RemoteLogManager implements Closeable {\\nclass RLMTask extends CancellableRunnable {\\n\\n    private final TopicIdPartition topicIdPartition;\\n\\n    private final int customMetadataSizeLimit;\\n\\n    private final Logger logger;\\n\\n    private volatile int leaderEpoch = -1;\\n\\n    public RLMTask(TopicIdPartition topicIdPartition, int customMetadataSizeLimit) {\\n        this.topicIdPartition = topicIdPartition;\\n        this.customMetadataSizeLimit = customMetadataSizeLimit;\\n        LogContext logContext = new LogContext(\"[RemoteLogManager=\" + brokerId + \" partition=\" + topicIdPartition + \"] \");\\n        logger = logContext.logger(RLMTask.class);\\n    }\\n\\n    boolean isLeader() {\\n        return leaderEpoch >= 0;\\n    }\\n\\n    // The copied and log-start offset is empty initially for a new leader RLMTask, and needs to be fetched inside\\n    // the task\\'s run() method.\\n    private volatile Optional<OffsetAndEpoch> copiedOffsetOption = Optional.empty();\\n\\n    private volatile boolean isLogStartOffsetUpdatedOnBecomingLeader = false;\\n\\n    private volatile Optional<String> logDirectory = Optional.empty();\\n\\n    public void convertToLeader(int leaderEpochVal) {\\n        if (leaderEpochVal < 0) {\\n            throw new KafkaException(\"leaderEpoch value for topic partition \" + topicIdPartition + \" can not be negative\");\\n        }\\n        if (this.leaderEpoch != leaderEpochVal) {\\n            leaderEpoch = leaderEpochVal;\\n        }\\n        // Reset copied and log-start offset, so that it is set in next run of RLMTask\\n        copiedOffsetOption = Optional.empty();\\n        isLogStartOffsetUpdatedOnBecomingLeader = false;\\n    }\\n\\n    public void convertToFollower() {\\n        leaderEpoch = -1;\\n    }\\n\\n    private void maybeUpdateLogStartOffsetOnBecomingLeader(UnifiedLog log) throws RemoteStorageException {\\n        if (!isLogStartOffsetUpdatedOnBecomingLeader) {\\n            long logStartOffset = findLogStartOffset(topicIdPartition, log);\\n            updateRemoteLogStartOffset.accept(topicIdPartition.topicPartition(), logStartOffset);\\n            isLogStartOffsetUpdatedOnBecomingLeader = true;\\n            logger.info(\"Found the logStartOffset: {} for partition: {} after becoming leader, leaderEpoch: {}\", logStartOffset, topicIdPartition, leaderEpoch);\\n        }\\n    }\\n\\n    private void maybeUpdateCopiedOffset(UnifiedLog log) throws RemoteStorageException {\\n        if (!copiedOffsetOption.isPresent()) {\\n            // This is found by traversing from the latest leader epoch from leader epoch history and find the highest offset\\n            // of a segment with that epoch copied into remote storage. If it can not find an entry then it checks for the\\n            // previous leader epoch till it finds an entry, If there are no entries till the earliest leader epoch in leader\\n            // epoch cache then it starts copying the segments from the earliest epoch entry\\'s offset.\\n            copiedOffsetOption = Optional.of(findHighestRemoteOffset(topicIdPartition, log));\\n            logger.info(\"Found the highest copiedRemoteOffset: {} for partition: {} after becoming leader, \" + \"leaderEpoch: {}\", copiedOffsetOption, topicIdPartition, leaderEpoch);\\n            copiedOffsetOption.ifPresent(offsetAndEpoch -> log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset()));\\n        }\\n    }\\n\\n    /**\\n     *  Segments which match the following criteria are eligible for copying to remote storage:\\n     *  1) Segment is not the active segment and\\n     *  2) Segment end-offset is less than the last-stable-offset as remote storage should contain only\\n     *     committed/acked messages\\n     * @param log The log from which the segments are to be copied\\n     * @param fromOffset The offset from which the segments are to be copied\\n     * @param lastStableOffset The last stable offset of the log\\n     * @return candidate log segments to be copied to remote storage\\n     */\\n    List<EnrichedLogSegment> candidateLogSegments(UnifiedLog log, Long fromOffset, Long lastStableOffset) {\\n        List<EnrichedLogSegment> candidateLogSegments = new ArrayList<>();\\n        List<LogSegment> segments = JavaConverters.seqAsJavaList(log.logSegments(fromOffset, Long.MAX_VALUE).toSeq());\\n        if (!segments.isEmpty()) {\\n            for (int idx = 1; idx < segments.size(); idx++) {\\n                LogSegment previousSeg = segments.get(idx - 1);\\n                LogSegment currentSeg = segments.get(idx);\\n                if (currentSeg.baseOffset() <= lastStableOffset) {\\n                    candidateLogSegments.add(new EnrichedLogSegment(previousSeg, currentSeg.baseOffset()));\\n                }\\n            }\\n            // Discard the last active segment\\n        }\\n        return candidateLogSegments;\\n    }\\n\\n    public void copyLogSegmentsToRemote(UnifiedLog log) throws InterruptedException {\\n        if (isCancelled())\\n            return;\\n        try {\\n            maybeUpdateLogStartOffsetOnBecomingLeader(log);\\n            maybeUpdateCopiedOffset(log);\\n            long copiedOffset = copiedOffsetOption.get().offset();\\n            // LSO indicates the offset below are ready to be consumed (high-watermark or committed)\\n            long lso = log.lastStableOffset();\\n            if (lso < 0) {\\n                logger.warn(\"lastStableOffset for partition {} is {}, which should not be negative.\", topicIdPartition, lso);\\n            } else if (lso > 0 && copiedOffset < lso) {\\n                // log-start-offset can be ahead of the copied-offset, when:\\n                // 1) log-start-offset gets incremented via delete-records API (or)\\n                // 2) enabling the remote log for the first time\\n                long fromOffset = Math.max(copiedOffset + 1, log.logStartOffset());\\n                List<EnrichedLogSegment> candidateLogSegments = candidateLogSegments(log, fromOffset, lso);\\n                logger.debug(\"Candidate log segments, logStartOffset: {}, copiedOffset: {}, fromOffset: {}, lso: {} \" + \"and candidateLogSegments: {}\", log.logStartOffset(), copiedOffset, fromOffset, lso, candidateLogSegments);\\n                if (candidateLogSegments.isEmpty()) {\\n                    logger.debug(\"No segments found to be copied for partition {} with copiedOffset: {} and active segment\\'s base-offset: {}\", topicIdPartition, copiedOffset, log.activeSegment().baseOffset());\\n                } else {\\n                    for (EnrichedLogSegment candidateLogSegment : candidateLogSegments) {\\n                        if (isCancelled() || !isLeader()) {\\n                            logger.info(\"Skipping copying log segments as the current task state is changed, cancelled: {} leader:{}\", isCancelled(), isLeader());\\n                            return;\\n                        }\\n                        copyQuotaManagerLock.lock();\\n                        try {\\n                            while (rlmCopyQuotaManager.isQuotaExceeded()) {\\n                                logger.debug(\"Quota exceeded for copying log segments, waiting for the quota to be available.\");\\n                                // If the thread gets interrupted while waiting, the InterruptedException is thrown\\n                                // back to the caller. It\\'s important to note that the task being executed is already\\n                                // cancelled before the executing thread is interrupted. The caller is responsible\\n                                // for handling the exception gracefully by checking if the task is already cancelled.\\n                                boolean ignored = copyQuotaManagerLockCondition.await(quotaTimeout().toMillis(), TimeUnit.MILLISECONDS);\\n                            }\\n                            rlmCopyQuotaManager.record(candidateLogSegment.logSegment.log().sizeInBytes());\\n                            // Signal waiting threads to check the quota again\\n                            copyQuotaManagerLockCondition.signalAll();\\n                        } finally {\\n                            copyQuotaManagerLock.unlock();\\n                        }\\n                        copyLogSegment(log, candidateLogSegment.logSegment, candidateLogSegment.nextSegmentOffset);\\n                    }\\n                }\\n            } else {\\n                logger.debug(\"Skipping copying segments, current read-offset:{}, and LSO:{}\", copiedOffset, lso);\\n            }\\n        } catch (CustomMetadataSizeLimitExceededException e) {\\n            // Only stop this task. Logging is done where the exception is thrown.\\n            brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n            brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n            this.cancel();\\n        } catch (InterruptedException | RetriableException ex) {\\n            throw ex;\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n                logger.error(\"Error occurred while copying log segments of partition: {}\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    private void copyLogSegment(UnifiedLog log, LogSegment segment, long nextSegmentBaseOffset) throws InterruptedException, ExecutionException, RemoteStorageException, IOException, CustomMetadataSizeLimitExceededException {\\n        File logFile = segment.log().file();\\n        String logFileName = logFile.getName();\\n        logger.info(\"Copying {} to remote storage.\", logFileName);\\n        RemoteLogSegmentId id = RemoteLogSegmentId.generateNew(topicIdPartition);\\n        long endOffset = nextSegmentBaseOffset - 1;\\n        File producerStateSnapshotFile = log.producerStateManager().fetchSnapshot(nextSegmentBaseOffset).orElse(null);\\n        List<EpochEntry> epochEntries = getLeaderEpochEntries(log, segment.baseOffset(), nextSegmentBaseOffset);\\n        Map<Integer, Long> segmentLeaderEpochs = new HashMap<>(epochEntries.size());\\n        epochEntries.forEach(entry -> segmentLeaderEpochs.put(entry.epoch, entry.startOffset));\\n        RemoteLogSegmentMetadata copySegmentStartedRlsm = new RemoteLogSegmentMetadata(id, segment.baseOffset(), endOffset, segment.largestTimestamp(), brokerId, time.milliseconds(), segment.log().sizeInBytes(), segmentLeaderEpochs);\\n        remoteLogMetadataManager.addRemoteLogSegmentMetadata(copySegmentStartedRlsm).get();\\n        ByteBuffer leaderEpochsIndex = epochEntriesAsByteBuffer(getLeaderEpochEntries(log, -1, nextSegmentBaseOffset));\\n        LogSegmentData segmentData = new LogSegmentData(logFile.toPath(), toPathIfExists(segment.offsetIndex().file()), toPathIfExists(segment.timeIndex().file()), Optional.ofNullable(toPathIfExists(segment.txnIndex().file())), producerStateSnapshotFile.toPath(), leaderEpochsIndex);\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyRequestRate().mark();\\n        brokerTopicStats.allTopicsStats().remoteCopyRequestRate().mark();\\n        Optional<CustomMetadata> customMetadata = remoteLogStorageManager.copyLogSegmentData(copySegmentStartedRlsm, segmentData);\\n        RemoteLogSegmentMetadataUpdate copySegmentFinishedRlsm = new RemoteLogSegmentMetadataUpdate(id, time.milliseconds(), customMetadata, RemoteLogSegmentState.COPY_SEGMENT_FINISHED, brokerId);\\n        if (customMetadata.isPresent()) {\\n            long customMetadataSize = customMetadata.get().value().length;\\n            if (customMetadataSize > this.customMetadataSizeLimit) {\\n                CustomMetadataSizeLimitExceededException e = new CustomMetadataSizeLimitExceededException();\\n                logger.error(\"Custom metadata size {} exceeds configured limit {}.\" + \" Copying will be stopped and copied segment will be attempted to clean.\" + \" Original metadata: {}\", customMetadataSize, this.customMetadataSizeLimit, copySegmentStartedRlsm, e);\\n                try {\\n                    // For deletion, we provide back the custom metadata by creating a new metadata object from the update.\\n                    // However, the update itself will not be stored in this case.\\n                    remoteLogStorageManager.deleteLogSegmentData(copySegmentStartedRlsm.createWithUpdates(copySegmentFinishedRlsm));\\n                    logger.info(\"Successfully cleaned segment after custom metadata size exceeded\");\\n                } catch (RemoteStorageException e1) {\\n                    logger.error(\"Error while cleaning segment after custom metadata size exceeded, consider cleaning manually\", e1);\\n                }\\n                throw e;\\n            }\\n        }\\n        remoteLogMetadataManager.updateRemoteLogSegmentMetadata(copySegmentFinishedRlsm).get();\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        brokerTopicStats.allTopicsStats().remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        // `epochEntries` cannot be empty, there is a pre-condition validation in RemoteLogSegmentMetadata\\n        // constructor\\n        int lastEpochInSegment = epochEntries.get(epochEntries.size() - 1).epoch;\\n        copiedOffsetOption = Optional.of(new OffsetAndEpoch(endOffset, lastEpochInSegment));\\n        // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n        // are not deleted before they are copied to remote storage.\\n        log.updateHighestOffsetInRemoteStorage(endOffset);\\n        logger.info(\"Copied {} to remote storage with segment-id: {}\", logFileName, copySegmentFinishedRlsm.remoteLogSegmentId());\\n        long bytesLag = log.onlyLocalLogSegmentsSize() - log.activeSegment().size();\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        long segmentsLag = log.onlyLocalLogSegmentsCount();\\n        brokerTopicStats.recordRemoteCopyLagBytes(topic, partition, bytesLag);\\n        brokerTopicStats.recordRemoteCopyLagSegments(topic, partition, segmentsLag);\\n    }\\n\\n    private Path toPathIfExists(File file) {\\n        return file.exists() ? file.toPath() : null;\\n    }\\n\\n    public void run() {\\n        if (isCancelled())\\n            return;\\n        try {\\n            Optional<UnifiedLog> unifiedLogOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n            if (!unifiedLogOptional.isPresent()) {\\n                return;\\n            }\\n            UnifiedLog log = unifiedLogOptional.get();\\n            // In the first run after completing altering logDir within broker, we should make sure the state is reset. (KAFKA-16711)\\n            if (!log.parentDir().equals(logDirectory.orElse(null))) {\\n                copiedOffsetOption = Optional.empty();\\n                isLogStartOffsetUpdatedOnBecomingLeader = false;\\n                logDirectory = Optional.of(log.parentDir());\\n            }\\n            if (isLeader()) {\\n                // Copy log segments to remote storage\\n                copyLogSegmentsToRemote(log);\\n                // Cleanup/delete expired remote log segments\\n                cleanupExpiredRemoteLogSegments();\\n            } else {\\n                OffsetAndEpoch offsetAndEpoch = findHighestRemoteOffset(topicIdPartition, log);\\n                // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n                // are not deleted before they are copied to remote storage.\\n                log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset());\\n            }\\n        } catch (InterruptedException ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current thread for topic-partition-id {} is interrupted\", topicIdPartition, ex);\\n            }\\n        } catch (RetriableException ex) {\\n            logger.debug(\"Encountered a retryable error while executing current task for topic-partition {}\", topicIdPartition, ex);\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current task for topic-partition {} received error but it will be scheduled\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    public void handleLogStartOffsetUpdate(TopicPartition topicPartition, long remoteLogStartOffset) {\\n        if (isLeader()) {\\n            logger.debug(\"Updating {} with remoteLogStartOffset: {}\", topicPartition, remoteLogStartOffset);\\n            updateRemoteLogStartOffset.accept(topicPartition, remoteLogStartOffset);\\n        }\\n    }\\n\\n    class RemoteLogRetentionHandler {\\n\\n        private final Optional<RetentionSizeData> retentionSizeData;\\n\\n        private final Optional<RetentionTimeData> retentionTimeData;\\n\\n        private long remainingBreachedSize;\\n\\n        private OptionalLong logStartOffset = OptionalLong.empty();\\n\\n        public RemoteLogRetentionHandler(Optional<RetentionSizeData> retentionSizeData, Optional<RetentionTimeData> retentionTimeData) {\\n            this.retentionSizeData = retentionSizeData;\\n            this.retentionTimeData = retentionTimeData;\\n            remainingBreachedSize = retentionSizeData.map(sizeData -> sizeData.remainingBreachedSize).orElse(0L);\\n        }\\n\\n        private boolean isSegmentBreachedByRetentionSize(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionSizeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            // Assumption that segments contain size >= 0\\n            if (remainingBreachedSize > 0) {\\n                long remainingBytes = remainingBreachedSize - metadata.segmentSizeInBytes();\\n                if (remainingBytes >= 0) {\\n                    remainingBreachedSize = remainingBytes;\\n                    shouldDeleteSegment = true;\\n                }\\n            }\\n            if (shouldDeleteSegment) {\\n                logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\", metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        public boolean isSegmentBreachedByRetentionTime(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionTimeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            shouldDeleteSegment = metadata.maxTimestampMs() <= retentionTimeData.get().cleanupUntilMs;\\n            if (shouldDeleteSegment) {\\n                remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                // are ascending with in an epoch.\\n                logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\", metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        private boolean isSegmentBreachByLogStartOffset(RemoteLogSegmentMetadata metadata, long logStartOffset, NavigableMap<Integer, Long> leaderEpochEntries) {\\n            boolean shouldDeleteSegment = false;\\n            if (!leaderEpochEntries.isEmpty()) {\\n                // Note that `logStartOffset` and `leaderEpochEntries.firstEntry().getValue()` should be same\\n                Integer firstEpoch = leaderEpochEntries.firstKey();\\n                shouldDeleteSegment = metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch <= firstEpoch) && metadata.endOffset() < logStartOffset;\\n            }\\n            if (shouldDeleteSegment) {\\n                logger.info(\"About to delete remote log segment {} due to log-start-offset {} breach. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), logStartOffset, leaderEpochEntries.firstEntry(), metadata.endOffset(), metadata.segmentLeaderEpochs());\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        // It removes the segments beyond the current leader\\'s earliest epoch. Those segments are considered as\\n        // unreferenced because they are not part of the current leader epoch lineage.\\n        private boolean deleteLogSegmentsDueToLeaderEpochCacheTruncation(EpochEntry earliestEpochEntry, RemoteLogSegmentMetadata metadata) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            boolean isSegmentDeleted = deleteRemoteLogSegment(metadata, ignored -> metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch < earliestEpochEntry.epoch));\\n            if (isSegmentDeleted) {\\n                logger.info(\"Deleted remote log segment {} due to leader-epoch-cache truncation. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), earliestEpochEntry, metadata.endOffset(), metadata.segmentLeaderEpochs().keySet());\\n            }\\n            // No need to update the log-start-offset as these epochs/offsets are earlier to that value.\\n            return isSegmentDeleted;\\n        }\\n\\n        private boolean deleteRemoteLogSegment(RemoteLogSegmentMetadata segmentMetadata, Predicate<RemoteLogSegmentMetadata> predicate) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            if (predicate.test(segmentMetadata)) {\\n                logger.debug(\"Deleting remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                String topic = segmentMetadata.topicIdPartition().topic();\\n                // Publish delete segment started event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_STARTED, brokerId)).get();\\n                brokerTopicStats.topicStats(topic).remoteDeleteRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().mark();\\n                // Delete the segment in remote storage.\\n                try {\\n                    remoteLogStorageManager.deleteLogSegmentData(segmentMetadata);\\n                } catch (RemoteStorageException e) {\\n                    brokerTopicStats.topicStats(topic).failedRemoteDeleteRequestRate().mark();\\n                    brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().mark();\\n                    throw e;\\n                }\\n                // Publish delete segment finished event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_FINISHED, brokerId)).get();\\n                logger.debug(\"Deleted remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                return true;\\n            }\\n            return false;\\n        }\\n    }\\n\\n    private void updateMetadataCountAndLogSizeWith(int metadataCount, long remoteLogSizeBytes) {\\n        int partition = topicIdPartition.partition();\\n        String topic = topicIdPartition.topic();\\n        brokerTopicStats.recordRemoteLogMetadataCount(topic, partition, metadataCount);\\n        brokerTopicStats.recordRemoteLogSizeBytes(topic, partition, remoteLogSizeBytes);\\n    }\\n\\n    private void updateRemoteDeleteLagWith(int segmentsLeftToDelete, long sizeOfDeletableSegmentsBytes) {\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        brokerTopicStats.recordRemoteDeleteLagSegments(topic, partition, segmentsLeftToDelete);\\n        brokerTopicStats.recordRemoteDeleteLagBytes(topic, partition, sizeOfDeletableSegmentsBytes);\\n    }\\n\\n    void cleanupExpiredRemoteLogSegments() throws RemoteStorageException, ExecutionException, InterruptedException {\\n        if (isCancelled() || !isLeader()) {\\n            logger.info(\"Returning from remote log segments cleanup as the task state is changed\");\\n            return;\\n        }\\n        final Optional<UnifiedLog> logOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n        if (!logOptional.isPresent()) {\\n            logger.debug(\"No UnifiedLog instance available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final UnifiedLog log = logOptional.get();\\n        final Option<LeaderEpochFileCache> leaderEpochCacheOption = log.leaderEpochCache();\\n        if (leaderEpochCacheOption.isEmpty()) {\\n            logger.debug(\"No leader epoch cache available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        // Cleanup remote log segments and update the log start offset if applicable.\\n        final Iterator<RemoteLogSegmentMetadata> segmentMetadataIter = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition);\\n        if (!segmentMetadataIter.hasNext()) {\\n            updateMetadataCountAndLogSizeWith(0, 0);\\n            logger.debug(\"No remote log segments available on remote storage for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final Set<Integer> epochsSet = new HashSet<>();\\n        int metadataCount = 0;\\n        long remoteLogSizeBytes = 0;\\n        // Good to have an API from RLMM to get all the remote leader epochs of all the segments of a partition\\n        // instead of going through all the segments and building it here.\\n        while (segmentMetadataIter.hasNext()) {\\n            RemoteLogSegmentMetadata segmentMetadata = segmentMetadataIter.next();\\n            epochsSet.addAll(segmentMetadata.segmentLeaderEpochs().keySet());\\n            metadataCount++;\\n            remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n        }\\n        updateMetadataCountAndLogSizeWith(metadataCount, remoteLogSizeBytes);\\n        // All the leader epochs in sorted order that exists in remote storage\\n        final List<Integer> remoteLeaderEpochs = new ArrayList<>(epochsSet);\\n        Collections.sort(remoteLeaderEpochs);\\n        LeaderEpochFileCache leaderEpochCache = leaderEpochCacheOption.get();\\n        // Build the leader epoch map by filtering the epochs that do not have any records.\\n        NavigableMap<Integer, Long> epochWithOffsets = buildFilteredLeaderEpochMap(leaderEpochCache.epochWithOffsets());\\n        long logStartOffset = log.logStartOffset();\\n        long logEndOffset = log.logEndOffset();\\n        Optional<RetentionSizeData> retentionSizeData = buildRetentionSizeData(log.config().retentionSize, log.onlyLocalLogSegmentsSize(), logEndOffset, epochWithOffsets);\\n        Optional<RetentionTimeData> retentionTimeData = buildRetentionTimeData(log.config().retentionMs);\\n        RemoteLogRetentionHandler remoteLogRetentionHandler = new RemoteLogRetentionHandler(retentionSizeData, retentionTimeData);\\n        Iterator<Integer> epochIterator = epochWithOffsets.navigableKeySet().iterator();\\n        boolean canProcess = true;\\n        List<RemoteLogSegmentMetadata> segmentsToDelete = new ArrayList<>();\\n        long sizeOfDeletableSegmentsBytes = 0L;\\n        while (canProcess && epochIterator.hasNext()) {\\n            Integer epoch = epochIterator.next();\\n            Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n            while (canProcess && segmentsIterator.hasNext()) {\\n                if (isCancelled() || !isLeader()) {\\n                    logger.info(\"Returning from remote log segments cleanup for the remaining segments as the task state is changed.\");\\n                    return;\\n                }\\n                RemoteLogSegmentMetadata metadata = segmentsIterator.next();\\n                if (RemoteLogSegmentState.DELETE_SEGMENT_FINISHED.equals(metadata.state())) {\\n                    continue;\\n                }\\n                if (segmentsToDelete.contains(metadata)) {\\n                    continue;\\n                }\\n                // When the log-start-offset is moved by the user, the leader-epoch-checkpoint file gets truncated\\n                // as per the log-start-offset. Until the rlm-cleaner-thread runs in the next iteration, those\\n                // remote log segments won\\'t be removed. The `isRemoteSegmentWithinLeaderEpoch` validates whether\\n                // the epochs present in the segment lies in the checkpoint file. It will always return false\\n                // since the checkpoint file was already truncated.\\n                boolean shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachByLogStartOffset(metadata, logStartOffset, epochWithOffsets);\\n                boolean isValidSegment = false;\\n                if (!shouldDeleteSegment) {\\n                    // check whether the segment contains the required epoch range with in the current leader epoch lineage.\\n                    isValidSegment = isRemoteSegmentWithinLeaderEpochs(metadata, logEndOffset, epochWithOffsets);\\n                    if (isValidSegment) {\\n                        shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachedByRetentionTime(metadata) || remoteLogRetentionHandler.isSegmentBreachedByRetentionSize(metadata);\\n                    }\\n                }\\n                if (shouldDeleteSegment) {\\n                    segmentsToDelete.add(metadata);\\n                    sizeOfDeletableSegmentsBytes += metadata.segmentSizeInBytes();\\n                }\\n                canProcess = shouldDeleteSegment || !isValidSegment;\\n            }\\n        }\\n        // Update log start offset with the computed value after retention cleanup is done\\n        remoteLogRetentionHandler.logStartOffset.ifPresent(offset -> handleLogStartOffsetUpdate(topicIdPartition.topicPartition(), offset));\\n        // At this point in time we have updated the log start offsets, but not initiated a deletion.\\n        // Either a follower has picked up the changes to the log start offset, or they have not.\\n        // If the follower HAS picked up the changes, and they become the leader this replica won\\'t successfully complete\\n        // the deletion.\\n        // However, the new leader will correctly pick up all breaching segments as log start offset breaching ones\\n        // and delete them accordingly.\\n        // If the follower HAS NOT picked up the changes, and they become the leader then they will go through this process\\n        // again and delete them with the original deletion reason i.e. size, time or log start offset breach.\\n        int segmentsLeftToDelete = segmentsToDelete.size();\\n        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n        List<String> undeletedSegments = new ArrayList<>();\\n        for (RemoteLogSegmentMetadata segmentMetadata : segmentsToDelete) {\\n            if (!remoteLogRetentionHandler.deleteRemoteLogSegment(segmentMetadata, x -> !isCancelled() && isLeader())) {\\n                undeletedSegments.add(segmentMetadata.remoteLogSegmentId().toString());\\n            } else {\\n                sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                segmentsLeftToDelete--;\\n                updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            }\\n        }\\n        if (!undeletedSegments.isEmpty()) {\\n            logger.info(\"The following remote segments could not be deleted: {}\", String.join(\",\", undeletedSegments));\\n        }\\n        // Remove the remote log segments whose segment-leader-epochs are less than the earliest-epoch known\\n        // to the leader. This will remove the unreferenced segments in the remote storage. This is needed for\\n        // unclean leader election scenarios as the remote storage can have epochs earlier to the current leader\\'s\\n        // earliest leader epoch.\\n        Optional<EpochEntry> earliestEpochEntryOptional = leaderEpochCache.earliestEntry();\\n        if (earliestEpochEntryOptional.isPresent()) {\\n            EpochEntry earliestEpochEntry = earliestEpochEntryOptional.get();\\n            Iterator<Integer> epochsToClean = remoteLeaderEpochs.stream().filter(remoteEpoch -> remoteEpoch < earliestEpochEntry.epoch).iterator();\\n            List<RemoteLogSegmentMetadata> listOfSegmentsToBeCleaned = new ArrayList<>();\\n            while (epochsToClean.hasNext()) {\\n                int epoch = epochsToClean.next();\\n                Iterator<RemoteLogSegmentMetadata> segmentsToBeCleaned = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsToBeCleaned.hasNext()) {\\n                    if (!isCancelled() && isLeader()) {\\n                        RemoteLogSegmentMetadata nextSegmentMetadata = segmentsToBeCleaned.next();\\n                        sizeOfDeletableSegmentsBytes += nextSegmentMetadata.segmentSizeInBytes();\\n                        listOfSegmentsToBeCleaned.add(nextSegmentMetadata);\\n                    }\\n                }\\n            }\\n            segmentsLeftToDelete += listOfSegmentsToBeCleaned.size();\\n            updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            for (RemoteLogSegmentMetadata segmentMetadata : listOfSegmentsToBeCleaned) {\\n                if (!isCancelled() && isLeader()) {\\n                    // No need to update the log-start-offset even though the segment is deleted as these epochs/offsets are earlier to that value.\\n                    if (remoteLogRetentionHandler.deleteLogSegmentsDueToLeaderEpochCacheTruncation(earliestEpochEntry, segmentMetadata)) {\\n                        sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                        segmentsLeftToDelete--;\\n                        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n                    }\\n                }\\n            }\\n        }\\n    }\\n\\n    private Optional<RetentionTimeData> buildRetentionTimeData(long retentionMs) {\\n        return retentionMs > -1 ? Optional.of(new RetentionTimeData(retentionMs, time.milliseconds() - retentionMs)) : Optional.empty();\\n    }\\n\\n    private Optional<RetentionSizeData> buildRetentionSizeData(long retentionSize, long onlyLocalLogSegmentsSize, long logEndOffset, NavigableMap<Integer, Long> epochEntries) throws RemoteStorageException {\\n        if (retentionSize > -1) {\\n            long startTimeMs = time.milliseconds();\\n            long remoteLogSizeBytes = 0L;\\n            Set<RemoteLogSegmentId> visitedSegmentIds = new HashSet<>();\\n            for (Integer epoch : epochEntries.navigableKeySet()) {\\n                // remoteLogSize(topicIdPartition, epochEntry.epoch) may not be completely accurate as the remote\\n                // log size may be computed for all the segments but not for segments with in the current\\n                // partition\\'s leader epoch lineage. Better to revisit this API.\\n                // remoteLogSizeBytes += remoteLogMetadataManager.remoteLogSize(topicIdPartition, epochEntry.epoch);\\n                Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsIterator.hasNext()) {\\n                    RemoteLogSegmentMetadata segmentMetadata = segmentsIterator.next();\\n                    RemoteLogSegmentId segmentId = segmentMetadata.remoteLogSegmentId();\\n                    if (!visitedSegmentIds.contains(segmentId) && isRemoteSegmentWithinLeaderEpochs(segmentMetadata, logEndOffset, epochEntries)) {\\n                        remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n                        visitedSegmentIds.add(segmentId);\\n                    }\\n                }\\n            }\\n            brokerTopicStats.recordRemoteLogSizeComputationTime(topicIdPartition.topic(), topicIdPartition.partition(), time.milliseconds() - startTimeMs);\\n            // This is the total size of segments in local log that have their base-offset > local-log-start-offset\\n            // and size of the segments in remote storage which have their end-offset < local-log-start-offset.\\n            long totalSize = onlyLocalLogSegmentsSize + remoteLogSizeBytes;\\n            if (totalSize > retentionSize) {\\n                long remainingBreachedSize = totalSize - retentionSize;\\n                RetentionSizeData retentionSizeData = new RetentionSizeData(retentionSize, remainingBreachedSize);\\n                return Optional.of(retentionSizeData);\\n            }\\n        }\\n        return Optional.empty();\\n    }\\n\\n    public String toString() {\\n        return this.getClass() + \"[\" + topicIdPartition + \"]\";\\n    }\\n}\\n}\\n\\ncore/src/main/java/kafka/log/remote/RemoteLogManager.java (After)\\npublic class RemoteLogManager implements Closeable {\\nclass RLMTask extends CancellableRunnable {\\n\\n    private final TopicIdPartition topicIdPartition;\\n\\n    private final int customMetadataSizeLimit;\\n\\n    private final Logger logger;\\n\\n    private volatile int leaderEpoch = -1;\\n\\n    public RLMTask(TopicIdPartition topicIdPartition, int customMetadataSizeLimit) {\\n        this.topicIdPartition = topicIdPartition;\\n        this.customMetadataSizeLimit = customMetadataSizeLimit;\\n        LogContext logContext = new LogContext(\"[RemoteLogManager=\" + brokerId + \" partition=\" + topicIdPartition + \"] \");\\n        logger = logContext.logger(RLMTask.class);\\n    }\\n\\n    boolean isLeader() {\\n        return leaderEpoch >= 0;\\n    }\\n\\n    // The copied and log-start offset is empty initially for a new leader RLMTask, and needs to be fetched inside\\n    // the task\\'s run() method.\\n    private volatile Optional<OffsetAndEpoch> copiedOffsetOption = Optional.empty();\\n\\n    private volatile boolean isLogStartOffsetUpdatedOnBecomingLeader = false;\\n\\n    private volatile Optional<String> logDirectory = Optional.empty();\\n\\n    public void convertToLeader(int leaderEpochVal) {\\n        if (leaderEpochVal < 0) {\\n            throw new KafkaException(\"leaderEpoch value for topic partition \" + topicIdPartition + \" can not be negative\");\\n        }\\n        if (this.leaderEpoch != leaderEpochVal) {\\n            leaderEpoch = leaderEpochVal;\\n        }\\n        // Reset copied and log-start offset, so that it is set in next run of RLMTask\\n        copiedOffsetOption = Optional.empty();\\n        isLogStartOffsetUpdatedOnBecomingLeader = false;\\n    }\\n\\n    public void convertToFollower() {\\n        leaderEpoch = -1;\\n    }\\n\\n    private void maybeUpdateLogStartOffsetOnBecomingLeader(UnifiedLog log) throws RemoteStorageException {\\n        if (!isLogStartOffsetUpdatedOnBecomingLeader) {\\n            long logStartOffset = findLogStartOffset(topicIdPartition, log);\\n            updateRemoteLogStartOffset.accept(topicIdPartition.topicPartition(), logStartOffset);\\n            isLogStartOffsetUpdatedOnBecomingLeader = true;\\n            logger.info(\"Found the logStartOffset: {} for partition: {} after becoming leader, leaderEpoch: {}\", logStartOffset, topicIdPartition, leaderEpoch);\\n        }\\n    }\\n\\n    private void maybeUpdateCopiedOffset(UnifiedLog log) throws RemoteStorageException {\\n        if (!copiedOffsetOption.isPresent()) {\\n            // This is found by traversing from the latest leader epoch from leader epoch history and find the highest offset\\n            // of a segment with that epoch copied into remote storage. If it can not find an entry then it checks for the\\n            // previous leader epoch till it finds an entry, If there are no entries till the earliest leader epoch in leader\\n            // epoch cache then it starts copying the segments from the earliest epoch entry\\'s offset.\\n            copiedOffsetOption = Optional.of(findHighestRemoteOffset(topicIdPartition, log));\\n            logger.info(\"Found the highest copiedRemoteOffset: {} for partition: {} after becoming leader, \" + \"leaderEpoch: {}\", copiedOffsetOption, topicIdPartition, leaderEpoch);\\n            copiedOffsetOption.ifPresent(offsetAndEpoch -> log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset()));\\n        }\\n    }\\n\\n    /**\\n     *  Segments which match the following criteria are eligible for copying to remote storage:\\n     *  1) Segment is not the active segment and\\n     *  2) Segment end-offset is less than the last-stable-offset as remote storage should contain only\\n     *     committed/acked messages\\n     * @param log The log from which the segments are to be copied\\n     * @param fromOffset The offset from which the segments are to be copied\\n     * @param lastStableOffset The last stable offset of the log\\n     * @return candidate log segments to be copied to remote storage\\n     */\\n    List<EnrichedLogSegment> candidateLogSegments(UnifiedLog log, Long fromOffset, Long lastStableOffset) {\\n        List<EnrichedLogSegment> candidateLogSegments = new ArrayList<>();\\n        List<LogSegment> segments = JavaConverters.seqAsJavaList(log.logSegments(fromOffset, Long.MAX_VALUE).toSeq());\\n        if (!segments.isEmpty()) {\\n            for (int idx = 1; idx < segments.size(); idx++) {\\n                LogSegment previousSeg = segments.get(idx - 1);\\n                LogSegment currentSeg = segments.get(idx);\\n                if (currentSeg.baseOffset() <= lastStableOffset) {\\n                    candidateLogSegments.add(new EnrichedLogSegment(previousSeg, currentSeg.baseOffset()));\\n                }\\n            }\\n            // Discard the last active segment\\n        }\\n        return candidateLogSegments;\\n    }\\n\\n    public void copyLogSegmentsToRemote(UnifiedLog log) throws InterruptedException {\\n        if (isCancelled())\\n            return;\\n        try {\\n            maybeUpdateLogStartOffsetOnBecomingLeader(log);\\n            maybeUpdateCopiedOffset(log);\\n            long copiedOffset = copiedOffsetOption.get().offset();\\n            // LSO indicates the offset below are ready to be consumed (high-watermark or committed)\\n            long lso = log.lastStableOffset();\\n            if (lso < 0) {\\n                logger.warn(\"lastStableOffset for partition {} is {}, which should not be negative.\", topicIdPartition, lso);\\n            } else if (lso > 0 && copiedOffset < lso) {\\n                // log-start-offset can be ahead of the copied-offset, when:\\n                // 1) log-start-offset gets incremented via delete-records API (or)\\n                // 2) enabling the remote log for the first time\\n                long fromOffset = Math.max(copiedOffset + 1, log.logStartOffset());\\n                List<EnrichedLogSegment> candidateLogSegments = candidateLogSegments(log, fromOffset, lso);\\n                logger.debug(\"Candidate log segments, logStartOffset: {}, copiedOffset: {}, fromOffset: {}, lso: {} \" + \"and candidateLogSegments: {}\", log.logStartOffset(), copiedOffset, fromOffset, lso, candidateLogSegments);\\n                if (candidateLogSegments.isEmpty()) {\\n                    logger.debug(\"No segments found to be copied for partition {} with copiedOffset: {} and active segment\\'s base-offset: {}\", topicIdPartition, copiedOffset, log.activeSegment().baseOffset());\\n                } else {\\n                    for (EnrichedLogSegment candidateLogSegment : candidateLogSegments) {\\n                        if (isCancelled() || !isLeader()) {\\n                            logger.info(\"Skipping copying log segments as the current task state is changed, cancelled: {} leader:{}\", isCancelled(), isLeader());\\n                            return;\\n                        }\\n                        copyQuotaManagerLock.lock();\\n                        try {\\n                            while (rlmCopyQuotaManager.isQuotaExceeded()) {\\n                                logger.debug(\"Quota exceeded for copying log segments, waiting for the quota to be available.\");\\n                                // If the thread gets interrupted while waiting, the InterruptedException is thrown\\n                                // back to the caller. It\\'s important to note that the task being executed is already\\n                                // cancelled before the executing thread is interrupted. The caller is responsible\\n                                // for handling the exception gracefully by checking if the task is already cancelled.\\n                                boolean ignored = copyQuotaManagerLockCondition.await(quotaTimeout().toMillis(), TimeUnit.MILLISECONDS);\\n                            }\\n                            rlmCopyQuotaManager.record(candidateLogSegment.logSegment.log().sizeInBytes());\\n                            // Signal waiting threads to check the quota again\\n                            copyQuotaManagerLockCondition.signalAll();\\n                        } finally {\\n                            copyQuotaManagerLock.unlock();\\n                        }\\n                        copyLogSegment(log, candidateLogSegment.logSegment, candidateLogSegment.nextSegmentOffset);\\n                    }\\n                }\\n            } else {\\n                logger.debug(\"Skipping copying segments, current read-offset:{}, and LSO:{}\", copiedOffset, lso);\\n            }\\n        } catch (CustomMetadataSizeLimitExceededException e) {\\n            // Only stop this task. Logging is done where the exception is thrown.\\n            brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n            brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n            this.cancel();\\n        } catch (InterruptedException | RetriableException ex) {\\n            throw ex;\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n                logger.error(\"Error occurred while copying log segments of partition: {}\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    private void copyLogSegment(UnifiedLog log, LogSegment segment, long nextSegmentBaseOffset) throws InterruptedException, ExecutionException, RemoteStorageException, IOException, CustomMetadataSizeLimitExceededException {\\n        File logFile = segment.log().file();\\n        String logFileName = logFile.getName();\\n        logger.info(\"Copying {} to remote storage.\", logFileName);\\n        RemoteLogSegmentId id = RemoteLogSegmentId.generateNew(topicIdPartition);\\n        long endOffset = nextSegmentBaseOffset - 1;\\n        File producerStateSnapshotFile = log.producerStateManager().fetchSnapshot(nextSegmentBaseOffset).orElse(null);\\n        List<EpochEntry> epochEntries = getLeaderEpochEntries(log, segment.baseOffset(), nextSegmentBaseOffset);\\n        Map<Integer, Long> segmentLeaderEpochs = new HashMap<>(epochEntries.size());\\n        epochEntries.forEach(entry -> segmentLeaderEpochs.put(entry.epoch, entry.startOffset));\\n        RemoteLogSegmentMetadata copySegmentStartedRlsm = new RemoteLogSegmentMetadata(id, segment.baseOffset(), endOffset, segment.largestTimestamp(), brokerId, time.milliseconds(), segment.log().sizeInBytes(), segmentLeaderEpochs);\\n        remoteLogMetadataManager.addRemoteLogSegmentMetadata(copySegmentStartedRlsm).get();\\n        ByteBuffer leaderEpochsIndex = epochEntriesAsByteBuffer(getLeaderEpochEntries(log, -1, nextSegmentBaseOffset));\\n        LogSegmentData segmentData = new LogSegmentData(logFile.toPath(), toPathIfExists(segment.offsetIndex().file()), toPathIfExists(segment.timeIndex().file()), Optional.ofNullable(toPathIfExists(segment.txnIndex().file())), producerStateSnapshotFile.toPath(), leaderEpochsIndex);\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyRequestRate().mark();\\n        brokerTopicStats.allTopicsStats().remoteCopyRequestRate().mark();\\n        Optional<CustomMetadata> customMetadata = remoteLogStorageManager.copyLogSegmentData(copySegmentStartedRlsm, segmentData);\\n        RemoteLogSegmentMetadataUpdate copySegmentFinishedRlsm = new RemoteLogSegmentMetadataUpdate(id, time.milliseconds(), customMetadata, RemoteLogSegmentState.COPY_SEGMENT_FINISHED, brokerId);\\n        if (customMetadata.isPresent()) {\\n            long customMetadataSize = customMetadata.get().value().length;\\n            if (customMetadataSize > this.customMetadataSizeLimit) {\\n                CustomMetadataSizeLimitExceededException e = new CustomMetadataSizeLimitExceededException();\\n                logger.error(\"Custom metadata size {} exceeds configured limit {}.\" + \" Copying will be stopped and copied segment will be attempted to clean.\" + \" Original metadata: {}\", customMetadataSize, this.customMetadataSizeLimit, copySegmentStartedRlsm, e);\\n                try {\\n                    // For deletion, we provide back the custom metadata by creating a new metadata object from the update.\\n                    // However, the update itself will not be stored in this case.\\n                    remoteLogStorageManager.deleteLogSegmentData(copySegmentStartedRlsm.createWithUpdates(copySegmentFinishedRlsm));\\n                    logger.info(\"Successfully cleaned segment after custom metadata size exceeded\");\\n                } catch (RemoteStorageException e1) {\\n                    logger.error(\"Error while cleaning segment after custom metadata size exceeded, consider cleaning manually\", e1);\\n                }\\n                throw e;\\n            }\\n        }\\n        remoteLogMetadataManager.updateRemoteLogSegmentMetadata(copySegmentFinishedRlsm).get();\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        brokerTopicStats.allTopicsStats().remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        // `epochEntries` cannot be empty, there is a pre-condition validation in RemoteLogSegmentMetadata\\n        // constructor\\n        int lastEpochInSegment = epochEntries.get(epochEntries.size() - 1).epoch;\\n        copiedOffsetOption = Optional.of(new OffsetAndEpoch(endOffset, lastEpochInSegment));\\n        // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n        // are not deleted before they are copied to remote storage.\\n        log.updateHighestOffsetInRemoteStorage(endOffset);\\n        logger.info(\"Copied {} to remote storage with segment-id: {}\", logFileName, copySegmentFinishedRlsm.remoteLogSegmentId());\\n        long bytesLag = log.onlyLocalLogSegmentsSize() - log.activeSegment().size();\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        long segmentsLag = log.onlyLocalLogSegmentsCount();\\n        brokerTopicStats.recordRemoteCopyLagBytes(topic, partition, bytesLag);\\n        brokerTopicStats.recordRemoteCopyLagSegments(topic, partition, segmentsLag);\\n    }\\n\\n    private Path toPathIfExists(File file) {\\n        return file.exists() ? file.toPath() : null;\\n    }\\n\\n    public void run() {\\n        if (isCancelled())\\n            return;\\n        try {\\n            Optional<UnifiedLog> unifiedLogOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n            if (!unifiedLogOptional.isPresent()) {\\n                return;\\n            }\\n            UnifiedLog log = unifiedLogOptional.get();\\n            // In the first run after completing altering logDir within broker, we should make sure the state is reset. (KAFKA-16711)\\n            if (!log.parentDir().equals(logDirectory.orElse(null))) {\\n                copiedOffsetOption = Optional.empty();\\n                isLogStartOffsetUpdatedOnBecomingLeader = false;\\n                logDirectory = Optional.of(log.parentDir());\\n            }\\n            if (isLeader()) {\\n                // Copy log segments to remote storage\\n                copyLogSegmentsToRemote(log);\\n                // Cleanup/delete expired remote log segments\\n                cleanupExpiredRemoteLogSegments();\\n            } else {\\n                OffsetAndEpoch offsetAndEpoch = findHighestRemoteOffset(topicIdPartition, log);\\n                // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n                // are not deleted before they are copied to remote storage.\\n                log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset());\\n            }\\n        } catch (InterruptedException ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current thread for topic-partition-id {} is interrupted\", topicIdPartition, ex);\\n            }\\n        } catch (RetriableException ex) {\\n            logger.debug(\"Encountered a retryable error while executing current task for topic-partition {}\", topicIdPartition, ex);\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current task for topic-partition {} received error but it will be scheduled\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    public void handleLogStartOffsetUpdate(TopicPartition topicPartition, long remoteLogStartOffset) {\\n        if (isLeader()) {\\n            logger.debug(\"Updating {} with remoteLogStartOffset: {}\", topicPartition, remoteLogStartOffset);\\n            updateRemoteLogStartOffset.accept(topicPartition, remoteLogStartOffset);\\n        }\\n    }\\n\\n    class RemoteLogRetentionHandler {\\n\\n        private final Optional<RetentionSizeData> retentionSizeData;\\n\\n        private final Optional<RetentionTimeData> retentionTimeData;\\n\\n        private long remainingBreachedSize;\\n\\n        private OptionalLong logStartOffset = OptionalLong.empty();\\n\\n        public RemoteLogRetentionHandler(Optional<RetentionSizeData> retentionSizeData, Optional<RetentionTimeData> retentionTimeData) {\\n            this.retentionSizeData = retentionSizeData;\\n            this.retentionTimeData = retentionTimeData;\\n            remainingBreachedSize = retentionSizeData.map(sizeData -> sizeData.remainingBreachedSize).orElse(0L);\\n        }\\n\\n        private boolean isSegmentBreachedByRetentionSize(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionSizeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            // Assumption that segments contain size >= 0\\n            if (remainingBreachedSize > 0) {\\n                long remainingBytes = remainingBreachedSize - metadata.segmentSizeInBytes();\\n                if (remainingBytes >= 0) {\\n                    remainingBreachedSize = remainingBytes;\\n                    shouldDeleteSegment = true;\\n                }\\n            }\\n            if (shouldDeleteSegment) {\\n                if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                }\\n                logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\", metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        public boolean isSegmentBreachedByRetentionTime(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionTimeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            shouldDeleteSegment = metadata.maxTimestampMs() <= retentionTimeData.get().cleanupUntilMs;\\n            if (shouldDeleteSegment) {\\n                remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                // are ascending with in an epoch.\\n                if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                }\\n                logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\", metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        private boolean isSegmentBreachByLogStartOffset(RemoteLogSegmentMetadata metadata, long logStartOffset, NavigableMap<Integer, Long> leaderEpochEntries) {\\n            boolean shouldDeleteSegment = false;\\n            if (!leaderEpochEntries.isEmpty()) {\\n                // Note that `logStartOffset` and `leaderEpochEntries.firstEntry().getValue()` should be same\\n                Integer firstEpoch = leaderEpochEntries.firstKey();\\n                shouldDeleteSegment = metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch <= firstEpoch) && metadata.endOffset() < logStartOffset;\\n            }\\n            if (shouldDeleteSegment) {\\n                logger.info(\"About to delete remote log segment {} due to log-start-offset {} breach. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), logStartOffset, leaderEpochEntries.firstEntry(), metadata.endOffset(), metadata.segmentLeaderEpochs());\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        // It removes the segments beyond the current leader\\'s earliest epoch. Those segments are considered as\\n        // unreferenced because they are not part of the current leader epoch lineage.\\n        private boolean deleteLogSegmentsDueToLeaderEpochCacheTruncation(EpochEntry earliestEpochEntry, RemoteLogSegmentMetadata metadata) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            boolean isSegmentDeleted = deleteRemoteLogSegment(metadata, ignored -> metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch < earliestEpochEntry.epoch));\\n            if (isSegmentDeleted) {\\n                logger.info(\"Deleted remote log segment {} due to leader-epoch-cache truncation. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), earliestEpochEntry, metadata.endOffset(), metadata.segmentLeaderEpochs().keySet());\\n            }\\n            // No need to update the log-start-offset as these epochs/offsets are earlier to that value.\\n            return isSegmentDeleted;\\n        }\\n\\n        private boolean deleteRemoteLogSegment(RemoteLogSegmentMetadata segmentMetadata, Predicate<RemoteLogSegmentMetadata> predicate) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            if (predicate.test(segmentMetadata)) {\\n                logger.debug(\"Deleting remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                String topic = segmentMetadata.topicIdPartition().topic();\\n                // Publish delete segment started event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_STARTED, brokerId)).get();\\n                brokerTopicStats.topicStats(topic).remoteDeleteRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().mark();\\n                // Delete the segment in remote storage.\\n                try {\\n                    remoteLogStorageManager.deleteLogSegmentData(segmentMetadata);\\n                } catch (RemoteStorageException e) {\\n                    brokerTopicStats.topicStats(topic).failedRemoteDeleteRequestRate().mark();\\n                    brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().mark();\\n                    throw e;\\n                }\\n                // Publish delete segment finished event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_FINISHED, brokerId)).get();\\n                logger.debug(\"Deleted remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                return true;\\n            }\\n            return false;\\n        }\\n    }\\n\\n    private void updateMetadataCountAndLogSizeWith(int metadataCount, long remoteLogSizeBytes) {\\n        int partition = topicIdPartition.partition();\\n        String topic = topicIdPartition.topic();\\n        brokerTopicStats.recordRemoteLogMetadataCount(topic, partition, metadataCount);\\n        brokerTopicStats.recordRemoteLogSizeBytes(topic, partition, remoteLogSizeBytes);\\n    }\\n\\n    private void updateRemoteDeleteLagWith(int segmentsLeftToDelete, long sizeOfDeletableSegmentsBytes) {\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        brokerTopicStats.recordRemoteDeleteLagSegments(topic, partition, segmentsLeftToDelete);\\n        brokerTopicStats.recordRemoteDeleteLagBytes(topic, partition, sizeOfDeletableSegmentsBytes);\\n    }\\n\\n    void cleanupExpiredRemoteLogSegments() throws RemoteStorageException, ExecutionException, InterruptedException {\\n        if (isCancelled() || !isLeader()) {\\n            logger.info(\"Returning from remote log segments cleanup as the task state is changed\");\\n            return;\\n        }\\n        final Optional<UnifiedLog> logOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n        if (!logOptional.isPresent()) {\\n            logger.debug(\"No UnifiedLog instance available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final UnifiedLog log = logOptional.get();\\n        final Option<LeaderEpochFileCache> leaderEpochCacheOption = log.leaderEpochCache();\\n        if (leaderEpochCacheOption.isEmpty()) {\\n            logger.debug(\"No leader epoch cache available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        // Cleanup remote log segments and update the log start offset if applicable.\\n        final Iterator<RemoteLogSegmentMetadata> segmentMetadataIter = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition);\\n        if (!segmentMetadataIter.hasNext()) {\\n            updateMetadataCountAndLogSizeWith(0, 0);\\n            logger.debug(\"No remote log segments available on remote storage for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final Set<Integer> epochsSet = new HashSet<>();\\n        int metadataCount = 0;\\n        long remoteLogSizeBytes = 0;\\n        // Good to have an API from RLMM to get all the remote leader epochs of all the segments of a partition\\n        // instead of going through all the segments and building it here.\\n        while (segmentMetadataIter.hasNext()) {\\n            RemoteLogSegmentMetadata segmentMetadata = segmentMetadataIter.next();\\n            epochsSet.addAll(segmentMetadata.segmentLeaderEpochs().keySet());\\n            metadataCount++;\\n            remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n        }\\n        updateMetadataCountAndLogSizeWith(metadataCount, remoteLogSizeBytes);\\n        // All the leader epochs in sorted order that exists in remote storage\\n        final List<Integer> remoteLeaderEpochs = new ArrayList<>(epochsSet);\\n        Collections.sort(remoteLeaderEpochs);\\n        LeaderEpochFileCache leaderEpochCache = leaderEpochCacheOption.get();\\n        // Build the leader epoch map by filtering the epochs that do not have any records.\\n        NavigableMap<Integer, Long> epochWithOffsets = buildFilteredLeaderEpochMap(leaderEpochCache.epochWithOffsets());\\n        long logStartOffset = log.logStartOffset();\\n        long logEndOffset = log.logEndOffset();\\n        Optional<RetentionSizeData> retentionSizeData = buildRetentionSizeData(log.config().retentionSize, log.onlyLocalLogSegmentsSize(), logEndOffset, epochWithOffsets);\\n        Optional<RetentionTimeData> retentionTimeData = buildRetentionTimeData(log.config().retentionMs);\\n        RemoteLogRetentionHandler remoteLogRetentionHandler = new RemoteLogRetentionHandler(retentionSizeData, retentionTimeData);\\n        Iterator<Integer> epochIterator = epochWithOffsets.navigableKeySet().iterator();\\n        boolean canProcess = true;\\n        List<RemoteLogSegmentMetadata> segmentsToDelete = new ArrayList<>();\\n        long sizeOfDeletableSegmentsBytes = 0L;\\n        while (canProcess && epochIterator.hasNext()) {\\n            Integer epoch = epochIterator.next();\\n            Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n            while (canProcess && segmentsIterator.hasNext()) {\\n                if (isCancelled() || !isLeader()) {\\n                    logger.info(\"Returning from remote log segments cleanup for the remaining segments as the task state is changed.\");\\n                    return;\\n                }\\n                RemoteLogSegmentMetadata metadata = segmentsIterator.next();\\n                if (RemoteLogSegmentState.DELETE_SEGMENT_FINISHED.equals(metadata.state())) {\\n                    continue;\\n                }\\n                if (segmentsToDelete.contains(metadata)) {\\n                    continue;\\n                }\\n                // When the log-start-offset is moved by the user, the leader-epoch-checkpoint file gets truncated\\n                // as per the log-start-offset. Until the rlm-cleaner-thread runs in the next iteration, those\\n                // remote log segments won\\'t be removed. The `isRemoteSegmentWithinLeaderEpoch` validates whether\\n                // the epochs present in the segment lies in the checkpoint file. It will always return false\\n                // since the checkpoint file was already truncated.\\n                boolean shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachByLogStartOffset(metadata, logStartOffset, epochWithOffsets);\\n                boolean isValidSegment = false;\\n                if (!shouldDeleteSegment) {\\n                    // check whether the segment contains the required epoch range with in the current leader epoch lineage.\\n                    isValidSegment = isRemoteSegmentWithinLeaderEpochs(metadata, logEndOffset, epochWithOffsets);\\n                    if (isValidSegment) {\\n                        shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachedByRetentionTime(metadata) || remoteLogRetentionHandler.isSegmentBreachedByRetentionSize(metadata);\\n                    }\\n                }\\n                if (shouldDeleteSegment) {\\n                    segmentsToDelete.add(metadata);\\n                    sizeOfDeletableSegmentsBytes += metadata.segmentSizeInBytes();\\n                }\\n                canProcess = shouldDeleteSegment || !isValidSegment;\\n            }\\n        }\\n        // Update log start offset with the computed value after retention cleanup is done\\n        remoteLogRetentionHandler.logStartOffset.ifPresent(offset -> handleLogStartOffsetUpdate(topicIdPartition.topicPartition(), offset));\\n        // At this point in time we have updated the log start offsets, but not initiated a deletion.\\n        // Either a follower has picked up the changes to the log start offset, or they have not.\\n        // If the follower HAS picked up the changes, and they become the leader this replica won\\'t successfully complete\\n        // the deletion.\\n        // However, the new leader will correctly pick up all breaching segments as log start offset breaching ones\\n        // and delete them accordingly.\\n        // If the follower HAS NOT picked up the changes, and they become the leader then they will go through this process\\n        // again and delete them with the original deletion reason i.e. size, time or log start offset breach.\\n        int segmentsLeftToDelete = segmentsToDelete.size();\\n        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n        List<String> undeletedSegments = new ArrayList<>();\\n        for (RemoteLogSegmentMetadata segmentMetadata : segmentsToDelete) {\\n            if (!remoteLogRetentionHandler.deleteRemoteLogSegment(segmentMetadata, x -> !isCancelled() && isLeader())) {\\n                undeletedSegments.add(segmentMetadata.remoteLogSegmentId().toString());\\n            } else {\\n                sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                segmentsLeftToDelete--;\\n                updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            }\\n        }\\n        if (!undeletedSegments.isEmpty()) {\\n            logger.info(\"The following remote segments could not be deleted: {}\", String.join(\",\", undeletedSegments));\\n        }\\n        // Remove the remote log segments whose segment-leader-epochs are less than the earliest-epoch known\\n        // to the leader. This will remove the unreferenced segments in the remote storage. This is needed for\\n        // unclean leader election scenarios as the remote storage can have epochs earlier to the current leader\\'s\\n        // earliest leader epoch.\\n        Optional<EpochEntry> earliestEpochEntryOptional = leaderEpochCache.earliestEntry();\\n        if (earliestEpochEntryOptional.isPresent()) {\\n            EpochEntry earliestEpochEntry = earliestEpochEntryOptional.get();\\n            Iterator<Integer> epochsToClean = remoteLeaderEpochs.stream().filter(remoteEpoch -> remoteEpoch < earliestEpochEntry.epoch).iterator();\\n            List<RemoteLogSegmentMetadata> listOfSegmentsToBeCleaned = new ArrayList<>();\\n            while (epochsToClean.hasNext()) {\\n                int epoch = epochsToClean.next();\\n                Iterator<RemoteLogSegmentMetadata> segmentsToBeCleaned = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsToBeCleaned.hasNext()) {\\n                    if (!isCancelled() && isLeader()) {\\n                        RemoteLogSegmentMetadata nextSegmentMetadata = segmentsToBeCleaned.next();\\n                        sizeOfDeletableSegmentsBytes += nextSegmentMetadata.segmentSizeInBytes();\\n                        listOfSegmentsToBeCleaned.add(nextSegmentMetadata);\\n                    }\\n                }\\n            }\\n            segmentsLeftToDelete += listOfSegmentsToBeCleaned.size();\\n            updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            for (RemoteLogSegmentMetadata segmentMetadata : listOfSegmentsToBeCleaned) {\\n                if (!isCancelled() && isLeader()) {\\n                    // No need to update the log-start-offset even though the segment is deleted as these epochs/offsets are earlier to that value.\\n                    if (remoteLogRetentionHandler.deleteLogSegmentsDueToLeaderEpochCacheTruncation(earliestEpochEntry, segmentMetadata)) {\\n                        sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                        segmentsLeftToDelete--;\\n                        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n                    }\\n                }\\n            }\\n        }\\n    }\\n\\n    private Optional<RetentionTimeData> buildRetentionTimeData(long retentionMs) {\\n        return retentionMs > -1 ? Optional.of(new RetentionTimeData(retentionMs, time.milliseconds() - retentionMs)) : Optional.empty();\\n    }\\n\\n    private Optional<RetentionSizeData> buildRetentionSizeData(long retentionSize, long onlyLocalLogSegmentsSize, long logEndOffset, NavigableMap<Integer, Long> epochEntries) throws RemoteStorageException {\\n        if (retentionSize > -1) {\\n            long startTimeMs = time.milliseconds();\\n            long remoteLogSizeBytes = 0L;\\n            Set<RemoteLogSegmentId> visitedSegmentIds = new HashSet<>();\\n            for (Integer epoch : epochEntries.navigableKeySet()) {\\n                // remoteLogSize(topicIdPartition, epochEntry.epoch) may not be completely accurate as the remote\\n                // log size may be computed for all the segments but not for segments with in the current\\n                // partition\\'s leader epoch lineage. Better to revisit this API.\\n                // remoteLogSizeBytes += remoteLogMetadataManager.remoteLogSize(topicIdPartition, epochEntry.epoch);\\n                Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsIterator.hasNext()) {\\n                    RemoteLogSegmentMetadata segmentMetadata = segmentsIterator.next();\\n                    RemoteLogSegmentId segmentId = segmentMetadata.remoteLogSegmentId();\\n                    if (!visitedSegmentIds.contains(segmentId) && isRemoteSegmentWithinLeaderEpochs(segmentMetadata, logEndOffset, epochEntries)) {\\n                        remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n                        visitedSegmentIds.add(segmentId);\\n                    }\\n                }\\n            }\\n            brokerTopicStats.recordRemoteLogSizeComputationTime(topicIdPartition.topic(), topicIdPartition.partition(), time.milliseconds() - startTimeMs);\\n            // This is the total size of segments in local log that have their base-offset > local-log-start-offset\\n            // and size of the segments in remote storage which have their end-offset < local-log-start-offset.\\n            long totalSize = onlyLocalLogSegmentsSize + remoteLogSizeBytes;\\n            if (totalSize > retentionSize) {\\n                long remainingBreachedSize = totalSize - retentionSize;\\n                RetentionSizeData retentionSizeData = new RetentionSizeData(retentionSize, remainingBreachedSize);\\n                return Optional.of(retentionSizeData);\\n            }\\n        }\\n        return Optional.empty();\\n    }\\n\\n    public String toString() {\\n        return this.getClass() + \"[\" + topicIdPartition + \"]\";\\n    }\\n}\\n}\\n\\ncore/src/test/java/kafka/log/remote/RemoteLogManagerTest.java (Before)\\npublic class RemoteLogManagerTest {\\n@ParameterizedTest(name = \"testDeletionOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    doAnswer(ans -> {\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic)));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments\"), String.format(\"Expected to find 2 for RemoteDeleteLagSegments metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments\")));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 2 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).doAnswer(ans -> {\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).when(remoteStorageManager).deleteLogSegmentData(any(RemoteLogSegmentMetadata.class));\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagBytes\"));\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagSegments\"));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic));\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n}\\n}\\n\\ncore/src/test/java/kafka/log/remote/RemoteLogManagerTest.java (After)\\npublic class RemoteLogManagerTest {\\n@ParameterizedTest(name = \"testDeletionOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED).get(0);\\n    // overlapping segment\\n    RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()), metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(), metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128, metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n    // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n    // returns the segments in order of (valid ++ unreferenced) segments:\\n    // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n    //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n    //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n    // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n    List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n    metadataList.add(metadata2);\\n    metadataList.add(metadata1);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    doAnswer(ans -> {\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic)));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments\"), String.format(\"Expected to find 2 for RemoteDeleteLagSegments metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments\")));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 2 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).doAnswer(ans -> {\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).when(remoteStorageManager).deleteLogSegmentData(any(RemoteLogSegmentMetadata.class));\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagBytes\"));\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagSegments\"));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic));\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n}\\n}\\n\\n\\nSummary:', 'role': 'user'}], 'model': 'deepseek/deepseek-r1-distill-qwen-32b', 'max_tokens': 4096, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.failed exception=ConnectError(gaierror(11001, 'getaddrinfo failed'))\n",
      "DEBUG:openai._base_client:Encountered Exception\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 250, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "        pool_request.request\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"C:\\Users\\johan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 996, in _request\n",
      "    response = self._client.send(\n",
      "        request,\n",
      "        stream=stream or self._should_stream_response_body(request=request),\n",
      "        **kwargs,\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 916, in send\n",
      "    response = self._send_handling_auth(\n",
      "        request,\n",
      "    ...<2 lines>...\n",
      "        history=[],\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 944, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "        request,\n",
      "        follow_redirects=follow_redirects,\n",
      "        history=history,\n",
      "    )\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 981, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_client.py\", line 1016, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 249, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\johan\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\johan\\source\\IF4092-Tugas-Akhir\\src\\venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 11001] getaddrinfo failed\n",
      "DEBUG:openai._base_client:1 retry left\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.811112 seconds\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. Summarize in exactly two concise sentences. \\n\\nAvoid adding any additional comments or annotations to the summary.\\n\\nGit diff:\\ndiff --git a/core/src/main/java/kafka/log/remote/RemoteLogManager.java b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\nindex c1c87d579e..3eacbea475 100644\\n--- a/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n+++ b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n@@ -983,7 +983,9 @@ public class RemoteLogManager implements Closeable {\\n                     }\\n                 }\\n                 if (shouldDeleteSegment) {\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\",\\n                             metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n                 }\\n@@ -1000,7 +1002,9 @@ public class RemoteLogManager implements Closeable {\\n                     remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                     // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                     // are ascending with in an epoch.\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\",\\n                             metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n                 }\\ndiff --git a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\nindex 4c4976f060..3c9b8a48e9 100644\\n--- a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n+++ b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n@@ -2055,6 +2055,75 @@ public class RemoteLogManagerTest {\\n         assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n     }\\n \\n+    @ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n+    @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n+    public void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize,\\n+                                                                   long retentionMs)\\n+            throws RemoteStorageException, ExecutionException, InterruptedException {\\n+        Map<String, Long> logProps = new HashMap<>();\\n+        logProps.put(\"retention.bytes\", retentionSize);\\n+        logProps.put(\"retention.ms\", retentionMs);\\n+        LogConfig mockLogConfig = new LogConfig(logProps);\\n+        when(mockLog.config()).thenReturn(mockLogConfig);\\n+\\n+        List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n+        checkpoint.write(epochEntries);\\n+        LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n+        when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n+\\n+        when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n+        when(mockLog.logEndOffset()).thenReturn(200L);\\n+\\n+        RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024,\\n+                epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED)\\n+                .get(0);\\n+        // overlapping segment\\n+        RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()),\\n+                metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(),\\n+                metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128,\\n+                metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n+\\n+        // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n+        // returns the segments in order of (valid ++ unreferenced) segments:\\n+        // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n+        //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n+        //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n+        // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n+        List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n+        metadataList.add(metadata2);\\n+        metadataList.add(metadata1);\\n+\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition))\\n+                .thenReturn(metadataList.iterator());\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0))\\n+                .thenAnswer(ans -> metadataList.iterator());\\n+        when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class)))\\n+                .thenReturn(CompletableFuture.runAsync(() -> { }));\\n+\\n+        // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+\\n+        RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n+        task.convertToLeader(0);\\n+        task.cleanupExpiredRemoteLogSegments();\\n+\\n+        assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n+\\n+        // Verify the metric for remote delete is updated correctly\\n+        assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        // Verify we did not report any failure for remote deletes\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+    }\\n+\\n     @ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n     @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n     public void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize,\\n\\n\\nSource code:\\ncore/src/main/java/kafka/log/remote/RemoteLogManager.java (Before)\\npublic class RemoteLogManager implements Closeable {\\nclass RLMTask extends CancellableRunnable {\\n\\n    private final TopicIdPartition topicIdPartition;\\n\\n    private final int customMetadataSizeLimit;\\n\\n    private final Logger logger;\\n\\n    private volatile int leaderEpoch = -1;\\n\\n    public RLMTask(TopicIdPartition topicIdPartition, int customMetadataSizeLimit) {\\n        this.topicIdPartition = topicIdPartition;\\n        this.customMetadataSizeLimit = customMetadataSizeLimit;\\n        LogContext logContext = new LogContext(\"[RemoteLogManager=\" + brokerId + \" partition=\" + topicIdPartition + \"] \");\\n        logger = logContext.logger(RLMTask.class);\\n    }\\n\\n    boolean isLeader() {\\n        return leaderEpoch >= 0;\\n    }\\n\\n    // The copied and log-start offset is empty initially for a new leader RLMTask, and needs to be fetched inside\\n    // the task\\'s run() method.\\n    private volatile Optional<OffsetAndEpoch> copiedOffsetOption = Optional.empty();\\n\\n    private volatile boolean isLogStartOffsetUpdatedOnBecomingLeader = false;\\n\\n    private volatile Optional<String> logDirectory = Optional.empty();\\n\\n    public void convertToLeader(int leaderEpochVal) {\\n        if (leaderEpochVal < 0) {\\n            throw new KafkaException(\"leaderEpoch value for topic partition \" + topicIdPartition + \" can not be negative\");\\n        }\\n        if (this.leaderEpoch != leaderEpochVal) {\\n            leaderEpoch = leaderEpochVal;\\n        }\\n        // Reset copied and log-start offset, so that it is set in next run of RLMTask\\n        copiedOffsetOption = Optional.empty();\\n        isLogStartOffsetUpdatedOnBecomingLeader = false;\\n    }\\n\\n    public void convertToFollower() {\\n        leaderEpoch = -1;\\n    }\\n\\n    private void maybeUpdateLogStartOffsetOnBecomingLeader(UnifiedLog log) throws RemoteStorageException {\\n        if (!isLogStartOffsetUpdatedOnBecomingLeader) {\\n            long logStartOffset = findLogStartOffset(topicIdPartition, log);\\n            updateRemoteLogStartOffset.accept(topicIdPartition.topicPartition(), logStartOffset);\\n            isLogStartOffsetUpdatedOnBecomingLeader = true;\\n            logger.info(\"Found the logStartOffset: {} for partition: {} after becoming leader, leaderEpoch: {}\", logStartOffset, topicIdPartition, leaderEpoch);\\n        }\\n    }\\n\\n    private void maybeUpdateCopiedOffset(UnifiedLog log) throws RemoteStorageException {\\n        if (!copiedOffsetOption.isPresent()) {\\n            // This is found by traversing from the latest leader epoch from leader epoch history and find the highest offset\\n            // of a segment with that epoch copied into remote storage. If it can not find an entry then it checks for the\\n            // previous leader epoch till it finds an entry, If there are no entries till the earliest leader epoch in leader\\n            // epoch cache then it starts copying the segments from the earliest epoch entry\\'s offset.\\n            copiedOffsetOption = Optional.of(findHighestRemoteOffset(topicIdPartition, log));\\n            logger.info(\"Found the highest copiedRemoteOffset: {} for partition: {} after becoming leader, \" + \"leaderEpoch: {}\", copiedOffsetOption, topicIdPartition, leaderEpoch);\\n            copiedOffsetOption.ifPresent(offsetAndEpoch -> log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset()));\\n        }\\n    }\\n\\n    /**\\n     *  Segments which match the following criteria are eligible for copying to remote storage:\\n     *  1) Segment is not the active segment and\\n     *  2) Segment end-offset is less than the last-stable-offset as remote storage should contain only\\n     *     committed/acked messages\\n     * @param log The log from which the segments are to be copied\\n     * @param fromOffset The offset from which the segments are to be copied\\n     * @param lastStableOffset The last stable offset of the log\\n     * @return candidate log segments to be copied to remote storage\\n     */\\n    List<EnrichedLogSegment> candidateLogSegments(UnifiedLog log, Long fromOffset, Long lastStableOffset) {\\n        List<EnrichedLogSegment> candidateLogSegments = new ArrayList<>();\\n        List<LogSegment> segments = JavaConverters.seqAsJavaList(log.logSegments(fromOffset, Long.MAX_VALUE).toSeq());\\n        if (!segments.isEmpty()) {\\n            for (int idx = 1; idx < segments.size(); idx++) {\\n                LogSegment previousSeg = segments.get(idx - 1);\\n                LogSegment currentSeg = segments.get(idx);\\n                if (currentSeg.baseOffset() <= lastStableOffset) {\\n                    candidateLogSegments.add(new EnrichedLogSegment(previousSeg, currentSeg.baseOffset()));\\n                }\\n            }\\n            // Discard the last active segment\\n        }\\n        return candidateLogSegments;\\n    }\\n\\n    public void copyLogSegmentsToRemote(UnifiedLog log) throws InterruptedException {\\n        if (isCancelled())\\n            return;\\n        try {\\n            maybeUpdateLogStartOffsetOnBecomingLeader(log);\\n            maybeUpdateCopiedOffset(log);\\n            long copiedOffset = copiedOffsetOption.get().offset();\\n            // LSO indicates the offset below are ready to be consumed (high-watermark or committed)\\n            long lso = log.lastStableOffset();\\n            if (lso < 0) {\\n                logger.warn(\"lastStableOffset for partition {} is {}, which should not be negative.\", topicIdPartition, lso);\\n            } else if (lso > 0 && copiedOffset < lso) {\\n                // log-start-offset can be ahead of the copied-offset, when:\\n                // 1) log-start-offset gets incremented via delete-records API (or)\\n                // 2) enabling the remote log for the first time\\n                long fromOffset = Math.max(copiedOffset + 1, log.logStartOffset());\\n                List<EnrichedLogSegment> candidateLogSegments = candidateLogSegments(log, fromOffset, lso);\\n                logger.debug(\"Candidate log segments, logStartOffset: {}, copiedOffset: {}, fromOffset: {}, lso: {} \" + \"and candidateLogSegments: {}\", log.logStartOffset(), copiedOffset, fromOffset, lso, candidateLogSegments);\\n                if (candidateLogSegments.isEmpty()) {\\n                    logger.debug(\"No segments found to be copied for partition {} with copiedOffset: {} and active segment\\'s base-offset: {}\", topicIdPartition, copiedOffset, log.activeSegment().baseOffset());\\n                } else {\\n                    for (EnrichedLogSegment candidateLogSegment : candidateLogSegments) {\\n                        if (isCancelled() || !isLeader()) {\\n                            logger.info(\"Skipping copying log segments as the current task state is changed, cancelled: {} leader:{}\", isCancelled(), isLeader());\\n                            return;\\n                        }\\n                        copyQuotaManagerLock.lock();\\n                        try {\\n                            while (rlmCopyQuotaManager.isQuotaExceeded()) {\\n                                logger.debug(\"Quota exceeded for copying log segments, waiting for the quota to be available.\");\\n                                // If the thread gets interrupted while waiting, the InterruptedException is thrown\\n                                // back to the caller. It\\'s important to note that the task being executed is already\\n                                // cancelled before the executing thread is interrupted. The caller is responsible\\n                                // for handling the exception gracefully by checking if the task is already cancelled.\\n                                boolean ignored = copyQuotaManagerLockCondition.await(quotaTimeout().toMillis(), TimeUnit.MILLISECONDS);\\n                            }\\n                            rlmCopyQuotaManager.record(candidateLogSegment.logSegment.log().sizeInBytes());\\n                            // Signal waiting threads to check the quota again\\n                            copyQuotaManagerLockCondition.signalAll();\\n                        } finally {\\n                            copyQuotaManagerLock.unlock();\\n                        }\\n                        copyLogSegment(log, candidateLogSegment.logSegment, candidateLogSegment.nextSegmentOffset);\\n                    }\\n                }\\n            } else {\\n                logger.debug(\"Skipping copying segments, current read-offset:{}, and LSO:{}\", copiedOffset, lso);\\n            }\\n        } catch (CustomMetadataSizeLimitExceededException e) {\\n            // Only stop this task. Logging is done where the exception is thrown.\\n            brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n            brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n            this.cancel();\\n        } catch (InterruptedException | RetriableException ex) {\\n            throw ex;\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n                logger.error(\"Error occurred while copying log segments of partition: {}\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    private void copyLogSegment(UnifiedLog log, LogSegment segment, long nextSegmentBaseOffset) throws InterruptedException, ExecutionException, RemoteStorageException, IOException, CustomMetadataSizeLimitExceededException {\\n        File logFile = segment.log().file();\\n        String logFileName = logFile.getName();\\n        logger.info(\"Copying {} to remote storage.\", logFileName);\\n        RemoteLogSegmentId id = RemoteLogSegmentId.generateNew(topicIdPartition);\\n        long endOffset = nextSegmentBaseOffset - 1;\\n        File producerStateSnapshotFile = log.producerStateManager().fetchSnapshot(nextSegmentBaseOffset).orElse(null);\\n        List<EpochEntry> epochEntries = getLeaderEpochEntries(log, segment.baseOffset(), nextSegmentBaseOffset);\\n        Map<Integer, Long> segmentLeaderEpochs = new HashMap<>(epochEntries.size());\\n        epochEntries.forEach(entry -> segmentLeaderEpochs.put(entry.epoch, entry.startOffset));\\n        RemoteLogSegmentMetadata copySegmentStartedRlsm = new RemoteLogSegmentMetadata(id, segment.baseOffset(), endOffset, segment.largestTimestamp(), brokerId, time.milliseconds(), segment.log().sizeInBytes(), segmentLeaderEpochs);\\n        remoteLogMetadataManager.addRemoteLogSegmentMetadata(copySegmentStartedRlsm).get();\\n        ByteBuffer leaderEpochsIndex = epochEntriesAsByteBuffer(getLeaderEpochEntries(log, -1, nextSegmentBaseOffset));\\n        LogSegmentData segmentData = new LogSegmentData(logFile.toPath(), toPathIfExists(segment.offsetIndex().file()), toPathIfExists(segment.timeIndex().file()), Optional.ofNullable(toPathIfExists(segment.txnIndex().file())), producerStateSnapshotFile.toPath(), leaderEpochsIndex);\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyRequestRate().mark();\\n        brokerTopicStats.allTopicsStats().remoteCopyRequestRate().mark();\\n        Optional<CustomMetadata> customMetadata = remoteLogStorageManager.copyLogSegmentData(copySegmentStartedRlsm, segmentData);\\n        RemoteLogSegmentMetadataUpdate copySegmentFinishedRlsm = new RemoteLogSegmentMetadataUpdate(id, time.milliseconds(), customMetadata, RemoteLogSegmentState.COPY_SEGMENT_FINISHED, brokerId);\\n        if (customMetadata.isPresent()) {\\n            long customMetadataSize = customMetadata.get().value().length;\\n            if (customMetadataSize > this.customMetadataSizeLimit) {\\n                CustomMetadataSizeLimitExceededException e = new CustomMetadataSizeLimitExceededException();\\n                logger.error(\"Custom metadata size {} exceeds configured limit {}.\" + \" Copying will be stopped and copied segment will be attempted to clean.\" + \" Original metadata: {}\", customMetadataSize, this.customMetadataSizeLimit, copySegmentStartedRlsm, e);\\n                try {\\n                    // For deletion, we provide back the custom metadata by creating a new metadata object from the update.\\n                    // However, the update itself will not be stored in this case.\\n                    remoteLogStorageManager.deleteLogSegmentData(copySegmentStartedRlsm.createWithUpdates(copySegmentFinishedRlsm));\\n                    logger.info(\"Successfully cleaned segment after custom metadata size exceeded\");\\n                } catch (RemoteStorageException e1) {\\n                    logger.error(\"Error while cleaning segment after custom metadata size exceeded, consider cleaning manually\", e1);\\n                }\\n                throw e;\\n            }\\n        }\\n        remoteLogMetadataManager.updateRemoteLogSegmentMetadata(copySegmentFinishedRlsm).get();\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        brokerTopicStats.allTopicsStats().remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        // `epochEntries` cannot be empty, there is a pre-condition validation in RemoteLogSegmentMetadata\\n        // constructor\\n        int lastEpochInSegment = epochEntries.get(epochEntries.size() - 1).epoch;\\n        copiedOffsetOption = Optional.of(new OffsetAndEpoch(endOffset, lastEpochInSegment));\\n        // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n        // are not deleted before they are copied to remote storage.\\n        log.updateHighestOffsetInRemoteStorage(endOffset);\\n        logger.info(\"Copied {} to remote storage with segment-id: {}\", logFileName, copySegmentFinishedRlsm.remoteLogSegmentId());\\n        long bytesLag = log.onlyLocalLogSegmentsSize() - log.activeSegment().size();\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        long segmentsLag = log.onlyLocalLogSegmentsCount();\\n        brokerTopicStats.recordRemoteCopyLagBytes(topic, partition, bytesLag);\\n        brokerTopicStats.recordRemoteCopyLagSegments(topic, partition, segmentsLag);\\n    }\\n\\n    private Path toPathIfExists(File file) {\\n        return file.exists() ? file.toPath() : null;\\n    }\\n\\n    public void run() {\\n        if (isCancelled())\\n            return;\\n        try {\\n            Optional<UnifiedLog> unifiedLogOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n            if (!unifiedLogOptional.isPresent()) {\\n                return;\\n            }\\n            UnifiedLog log = unifiedLogOptional.get();\\n            // In the first run after completing altering logDir within broker, we should make sure the state is reset. (KAFKA-16711)\\n            if (!log.parentDir().equals(logDirectory.orElse(null))) {\\n                copiedOffsetOption = Optional.empty();\\n                isLogStartOffsetUpdatedOnBecomingLeader = false;\\n                logDirectory = Optional.of(log.parentDir());\\n            }\\n            if (isLeader()) {\\n                // Copy log segments to remote storage\\n                copyLogSegmentsToRemote(log);\\n                // Cleanup/delete expired remote log segments\\n                cleanupExpiredRemoteLogSegments();\\n            } else {\\n                OffsetAndEpoch offsetAndEpoch = findHighestRemoteOffset(topicIdPartition, log);\\n                // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n                // are not deleted before they are copied to remote storage.\\n                log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset());\\n            }\\n        } catch (InterruptedException ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current thread for topic-partition-id {} is interrupted\", topicIdPartition, ex);\\n            }\\n        } catch (RetriableException ex) {\\n            logger.debug(\"Encountered a retryable error while executing current task for topic-partition {}\", topicIdPartition, ex);\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current task for topic-partition {} received error but it will be scheduled\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    public void handleLogStartOffsetUpdate(TopicPartition topicPartition, long remoteLogStartOffset) {\\n        if (isLeader()) {\\n            logger.debug(\"Updating {} with remoteLogStartOffset: {}\", topicPartition, remoteLogStartOffset);\\n            updateRemoteLogStartOffset.accept(topicPartition, remoteLogStartOffset);\\n        }\\n    }\\n\\n    class RemoteLogRetentionHandler {\\n\\n        private final Optional<RetentionSizeData> retentionSizeData;\\n\\n        private final Optional<RetentionTimeData> retentionTimeData;\\n\\n        private long remainingBreachedSize;\\n\\n        private OptionalLong logStartOffset = OptionalLong.empty();\\n\\n        public RemoteLogRetentionHandler(Optional<RetentionSizeData> retentionSizeData, Optional<RetentionTimeData> retentionTimeData) {\\n            this.retentionSizeData = retentionSizeData;\\n            this.retentionTimeData = retentionTimeData;\\n            remainingBreachedSize = retentionSizeData.map(sizeData -> sizeData.remainingBreachedSize).orElse(0L);\\n        }\\n\\n        private boolean isSegmentBreachedByRetentionSize(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionSizeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            // Assumption that segments contain size >= 0\\n            if (remainingBreachedSize > 0) {\\n                long remainingBytes = remainingBreachedSize - metadata.segmentSizeInBytes();\\n                if (remainingBytes >= 0) {\\n                    remainingBreachedSize = remainingBytes;\\n                    shouldDeleteSegment = true;\\n                }\\n            }\\n            if (shouldDeleteSegment) {\\n                logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\", metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        public boolean isSegmentBreachedByRetentionTime(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionTimeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            shouldDeleteSegment = metadata.maxTimestampMs() <= retentionTimeData.get().cleanupUntilMs;\\n            if (shouldDeleteSegment) {\\n                remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                // are ascending with in an epoch.\\n                logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\", metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        private boolean isSegmentBreachByLogStartOffset(RemoteLogSegmentMetadata metadata, long logStartOffset, NavigableMap<Integer, Long> leaderEpochEntries) {\\n            boolean shouldDeleteSegment = false;\\n            if (!leaderEpochEntries.isEmpty()) {\\n                // Note that `logStartOffset` and `leaderEpochEntries.firstEntry().getValue()` should be same\\n                Integer firstEpoch = leaderEpochEntries.firstKey();\\n                shouldDeleteSegment = metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch <= firstEpoch) && metadata.endOffset() < logStartOffset;\\n            }\\n            if (shouldDeleteSegment) {\\n                logger.info(\"About to delete remote log segment {} due to log-start-offset {} breach. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), logStartOffset, leaderEpochEntries.firstEntry(), metadata.endOffset(), metadata.segmentLeaderEpochs());\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        // It removes the segments beyond the current leader\\'s earliest epoch. Those segments are considered as\\n        // unreferenced because they are not part of the current leader epoch lineage.\\n        private boolean deleteLogSegmentsDueToLeaderEpochCacheTruncation(EpochEntry earliestEpochEntry, RemoteLogSegmentMetadata metadata) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            boolean isSegmentDeleted = deleteRemoteLogSegment(metadata, ignored -> metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch < earliestEpochEntry.epoch));\\n            if (isSegmentDeleted) {\\n                logger.info(\"Deleted remote log segment {} due to leader-epoch-cache truncation. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), earliestEpochEntry, metadata.endOffset(), metadata.segmentLeaderEpochs().keySet());\\n            }\\n            // No need to update the log-start-offset as these epochs/offsets are earlier to that value.\\n            return isSegmentDeleted;\\n        }\\n\\n        private boolean deleteRemoteLogSegment(RemoteLogSegmentMetadata segmentMetadata, Predicate<RemoteLogSegmentMetadata> predicate) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            if (predicate.test(segmentMetadata)) {\\n                logger.debug(\"Deleting remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                String topic = segmentMetadata.topicIdPartition().topic();\\n                // Publish delete segment started event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_STARTED, brokerId)).get();\\n                brokerTopicStats.topicStats(topic).remoteDeleteRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().mark();\\n                // Delete the segment in remote storage.\\n                try {\\n                    remoteLogStorageManager.deleteLogSegmentData(segmentMetadata);\\n                } catch (RemoteStorageException e) {\\n                    brokerTopicStats.topicStats(topic).failedRemoteDeleteRequestRate().mark();\\n                    brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().mark();\\n                    throw e;\\n                }\\n                // Publish delete segment finished event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_FINISHED, brokerId)).get();\\n                logger.debug(\"Deleted remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                return true;\\n            }\\n            return false;\\n        }\\n    }\\n\\n    private void updateMetadataCountAndLogSizeWith(int metadataCount, long remoteLogSizeBytes) {\\n        int partition = topicIdPartition.partition();\\n        String topic = topicIdPartition.topic();\\n        brokerTopicStats.recordRemoteLogMetadataCount(topic, partition, metadataCount);\\n        brokerTopicStats.recordRemoteLogSizeBytes(topic, partition, remoteLogSizeBytes);\\n    }\\n\\n    private void updateRemoteDeleteLagWith(int segmentsLeftToDelete, long sizeOfDeletableSegmentsBytes) {\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        brokerTopicStats.recordRemoteDeleteLagSegments(topic, partition, segmentsLeftToDelete);\\n        brokerTopicStats.recordRemoteDeleteLagBytes(topic, partition, sizeOfDeletableSegmentsBytes);\\n    }\\n\\n    void cleanupExpiredRemoteLogSegments() throws RemoteStorageException, ExecutionException, InterruptedException {\\n        if (isCancelled() || !isLeader()) {\\n            logger.info(\"Returning from remote log segments cleanup as the task state is changed\");\\n            return;\\n        }\\n        final Optional<UnifiedLog> logOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n        if (!logOptional.isPresent()) {\\n            logger.debug(\"No UnifiedLog instance available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final UnifiedLog log = logOptional.get();\\n        final Option<LeaderEpochFileCache> leaderEpochCacheOption = log.leaderEpochCache();\\n        if (leaderEpochCacheOption.isEmpty()) {\\n            logger.debug(\"No leader epoch cache available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        // Cleanup remote log segments and update the log start offset if applicable.\\n        final Iterator<RemoteLogSegmentMetadata> segmentMetadataIter = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition);\\n        if (!segmentMetadataIter.hasNext()) {\\n            updateMetadataCountAndLogSizeWith(0, 0);\\n            logger.debug(\"No remote log segments available on remote storage for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final Set<Integer> epochsSet = new HashSet<>();\\n        int metadataCount = 0;\\n        long remoteLogSizeBytes = 0;\\n        // Good to have an API from RLMM to get all the remote leader epochs of all the segments of a partition\\n        // instead of going through all the segments and building it here.\\n        while (segmentMetadataIter.hasNext()) {\\n            RemoteLogSegmentMetadata segmentMetadata = segmentMetadataIter.next();\\n            epochsSet.addAll(segmentMetadata.segmentLeaderEpochs().keySet());\\n            metadataCount++;\\n            remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n        }\\n        updateMetadataCountAndLogSizeWith(metadataCount, remoteLogSizeBytes);\\n        // All the leader epochs in sorted order that exists in remote storage\\n        final List<Integer> remoteLeaderEpochs = new ArrayList<>(epochsSet);\\n        Collections.sort(remoteLeaderEpochs);\\n        LeaderEpochFileCache leaderEpochCache = leaderEpochCacheOption.get();\\n        // Build the leader epoch map by filtering the epochs that do not have any records.\\n        NavigableMap<Integer, Long> epochWithOffsets = buildFilteredLeaderEpochMap(leaderEpochCache.epochWithOffsets());\\n        long logStartOffset = log.logStartOffset();\\n        long logEndOffset = log.logEndOffset();\\n        Optional<RetentionSizeData> retentionSizeData = buildRetentionSizeData(log.config().retentionSize, log.onlyLocalLogSegmentsSize(), logEndOffset, epochWithOffsets);\\n        Optional<RetentionTimeData> retentionTimeData = buildRetentionTimeData(log.config().retentionMs);\\n        RemoteLogRetentionHandler remoteLogRetentionHandler = new RemoteLogRetentionHandler(retentionSizeData, retentionTimeData);\\n        Iterator<Integer> epochIterator = epochWithOffsets.navigableKeySet().iterator();\\n        boolean canProcess = true;\\n        List<RemoteLogSegmentMetadata> segmentsToDelete = new ArrayList<>();\\n        long sizeOfDeletableSegmentsBytes = 0L;\\n        while (canProcess && epochIterator.hasNext()) {\\n            Integer epoch = epochIterator.next();\\n            Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n            while (canProcess && segmentsIterator.hasNext()) {\\n                if (isCancelled() || !isLeader()) {\\n                    logger.info(\"Returning from remote log segments cleanup for the remaining segments as the task state is changed.\");\\n                    return;\\n                }\\n                RemoteLogSegmentMetadata metadata = segmentsIterator.next();\\n                if (RemoteLogSegmentState.DELETE_SEGMENT_FINISHED.equals(metadata.state())) {\\n                    continue;\\n                }\\n                if (segmentsToDelete.contains(metadata)) {\\n                    continue;\\n                }\\n                // When the log-start-offset is moved by the user, the leader-epoch-checkpoint file gets truncated\\n                // as per the log-start-offset. Until the rlm-cleaner-thread runs in the next iteration, those\\n                // remote log segments won\\'t be removed. The `isRemoteSegmentWithinLeaderEpoch` validates whether\\n                // the epochs present in the segment lies in the checkpoint file. It will always return false\\n                // since the checkpoint file was already truncated.\\n                boolean shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachByLogStartOffset(metadata, logStartOffset, epochWithOffsets);\\n                boolean isValidSegment = false;\\n                if (!shouldDeleteSegment) {\\n                    // check whether the segment contains the required epoch range with in the current leader epoch lineage.\\n                    isValidSegment = isRemoteSegmentWithinLeaderEpochs(metadata, logEndOffset, epochWithOffsets);\\n                    if (isValidSegment) {\\n                        shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachedByRetentionTime(metadata) || remoteLogRetentionHandler.isSegmentBreachedByRetentionSize(metadata);\\n                    }\\n                }\\n                if (shouldDeleteSegment) {\\n                    segmentsToDelete.add(metadata);\\n                    sizeOfDeletableSegmentsBytes += metadata.segmentSizeInBytes();\\n                }\\n                canProcess = shouldDeleteSegment || !isValidSegment;\\n            }\\n        }\\n        // Update log start offset with the computed value after retention cleanup is done\\n        remoteLogRetentionHandler.logStartOffset.ifPresent(offset -> handleLogStartOffsetUpdate(topicIdPartition.topicPartition(), offset));\\n        // At this point in time we have updated the log start offsets, but not initiated a deletion.\\n        // Either a follower has picked up the changes to the log start offset, or they have not.\\n        // If the follower HAS picked up the changes, and they become the leader this replica won\\'t successfully complete\\n        // the deletion.\\n        // However, the new leader will correctly pick up all breaching segments as log start offset breaching ones\\n        // and delete them accordingly.\\n        // If the follower HAS NOT picked up the changes, and they become the leader then they will go through this process\\n        // again and delete them with the original deletion reason i.e. size, time or log start offset breach.\\n        int segmentsLeftToDelete = segmentsToDelete.size();\\n        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n        List<String> undeletedSegments = new ArrayList<>();\\n        for (RemoteLogSegmentMetadata segmentMetadata : segmentsToDelete) {\\n            if (!remoteLogRetentionHandler.deleteRemoteLogSegment(segmentMetadata, x -> !isCancelled() && isLeader())) {\\n                undeletedSegments.add(segmentMetadata.remoteLogSegmentId().toString());\\n            } else {\\n                sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                segmentsLeftToDelete--;\\n                updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            }\\n        }\\n        if (!undeletedSegments.isEmpty()) {\\n            logger.info(\"The following remote segments could not be deleted: {}\", String.join(\",\", undeletedSegments));\\n        }\\n        // Remove the remote log segments whose segment-leader-epochs are less than the earliest-epoch known\\n        // to the leader. This will remove the unreferenced segments in the remote storage. This is needed for\\n        // unclean leader election scenarios as the remote storage can have epochs earlier to the current leader\\'s\\n        // earliest leader epoch.\\n        Optional<EpochEntry> earliestEpochEntryOptional = leaderEpochCache.earliestEntry();\\n        if (earliestEpochEntryOptional.isPresent()) {\\n            EpochEntry earliestEpochEntry = earliestEpochEntryOptional.get();\\n            Iterator<Integer> epochsToClean = remoteLeaderEpochs.stream().filter(remoteEpoch -> remoteEpoch < earliestEpochEntry.epoch).iterator();\\n            List<RemoteLogSegmentMetadata> listOfSegmentsToBeCleaned = new ArrayList<>();\\n            while (epochsToClean.hasNext()) {\\n                int epoch = epochsToClean.next();\\n                Iterator<RemoteLogSegmentMetadata> segmentsToBeCleaned = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsToBeCleaned.hasNext()) {\\n                    if (!isCancelled() && isLeader()) {\\n                        RemoteLogSegmentMetadata nextSegmentMetadata = segmentsToBeCleaned.next();\\n                        sizeOfDeletableSegmentsBytes += nextSegmentMetadata.segmentSizeInBytes();\\n                        listOfSegmentsToBeCleaned.add(nextSegmentMetadata);\\n                    }\\n                }\\n            }\\n            segmentsLeftToDelete += listOfSegmentsToBeCleaned.size();\\n            updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            for (RemoteLogSegmentMetadata segmentMetadata : listOfSegmentsToBeCleaned) {\\n                if (!isCancelled() && isLeader()) {\\n                    // No need to update the log-start-offset even though the segment is deleted as these epochs/offsets are earlier to that value.\\n                    if (remoteLogRetentionHandler.deleteLogSegmentsDueToLeaderEpochCacheTruncation(earliestEpochEntry, segmentMetadata)) {\\n                        sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                        segmentsLeftToDelete--;\\n                        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n                    }\\n                }\\n            }\\n        }\\n    }\\n\\n    private Optional<RetentionTimeData> buildRetentionTimeData(long retentionMs) {\\n        return retentionMs > -1 ? Optional.of(new RetentionTimeData(retentionMs, time.milliseconds() - retentionMs)) : Optional.empty();\\n    }\\n\\n    private Optional<RetentionSizeData> buildRetentionSizeData(long retentionSize, long onlyLocalLogSegmentsSize, long logEndOffset, NavigableMap<Integer, Long> epochEntries) throws RemoteStorageException {\\n        if (retentionSize > -1) {\\n            long startTimeMs = time.milliseconds();\\n            long remoteLogSizeBytes = 0L;\\n            Set<RemoteLogSegmentId> visitedSegmentIds = new HashSet<>();\\n            for (Integer epoch : epochEntries.navigableKeySet()) {\\n                // remoteLogSize(topicIdPartition, epochEntry.epoch) may not be completely accurate as the remote\\n                // log size may be computed for all the segments but not for segments with in the current\\n                // partition\\'s leader epoch lineage. Better to revisit this API.\\n                // remoteLogSizeBytes += remoteLogMetadataManager.remoteLogSize(topicIdPartition, epochEntry.epoch);\\n                Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsIterator.hasNext()) {\\n                    RemoteLogSegmentMetadata segmentMetadata = segmentsIterator.next();\\n                    RemoteLogSegmentId segmentId = segmentMetadata.remoteLogSegmentId();\\n                    if (!visitedSegmentIds.contains(segmentId) && isRemoteSegmentWithinLeaderEpochs(segmentMetadata, logEndOffset, epochEntries)) {\\n                        remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n                        visitedSegmentIds.add(segmentId);\\n                    }\\n                }\\n            }\\n            brokerTopicStats.recordRemoteLogSizeComputationTime(topicIdPartition.topic(), topicIdPartition.partition(), time.milliseconds() - startTimeMs);\\n            // This is the total size of segments in local log that have their base-offset > local-log-start-offset\\n            // and size of the segments in remote storage which have their end-offset < local-log-start-offset.\\n            long totalSize = onlyLocalLogSegmentsSize + remoteLogSizeBytes;\\n            if (totalSize > retentionSize) {\\n                long remainingBreachedSize = totalSize - retentionSize;\\n                RetentionSizeData retentionSizeData = new RetentionSizeData(retentionSize, remainingBreachedSize);\\n                return Optional.of(retentionSizeData);\\n            }\\n        }\\n        return Optional.empty();\\n    }\\n\\n    public String toString() {\\n        return this.getClass() + \"[\" + topicIdPartition + \"]\";\\n    }\\n}\\n}\\n\\ncore/src/main/java/kafka/log/remote/RemoteLogManager.java (After)\\npublic class RemoteLogManager implements Closeable {\\nclass RLMTask extends CancellableRunnable {\\n\\n    private final TopicIdPartition topicIdPartition;\\n\\n    private final int customMetadataSizeLimit;\\n\\n    private final Logger logger;\\n\\n    private volatile int leaderEpoch = -1;\\n\\n    public RLMTask(TopicIdPartition topicIdPartition, int customMetadataSizeLimit) {\\n        this.topicIdPartition = topicIdPartition;\\n        this.customMetadataSizeLimit = customMetadataSizeLimit;\\n        LogContext logContext = new LogContext(\"[RemoteLogManager=\" + brokerId + \" partition=\" + topicIdPartition + \"] \");\\n        logger = logContext.logger(RLMTask.class);\\n    }\\n\\n    boolean isLeader() {\\n        return leaderEpoch >= 0;\\n    }\\n\\n    // The copied and log-start offset is empty initially for a new leader RLMTask, and needs to be fetched inside\\n    // the task\\'s run() method.\\n    private volatile Optional<OffsetAndEpoch> copiedOffsetOption = Optional.empty();\\n\\n    private volatile boolean isLogStartOffsetUpdatedOnBecomingLeader = false;\\n\\n    private volatile Optional<String> logDirectory = Optional.empty();\\n\\n    public void convertToLeader(int leaderEpochVal) {\\n        if (leaderEpochVal < 0) {\\n            throw new KafkaException(\"leaderEpoch value for topic partition \" + topicIdPartition + \" can not be negative\");\\n        }\\n        if (this.leaderEpoch != leaderEpochVal) {\\n            leaderEpoch = leaderEpochVal;\\n        }\\n        // Reset copied and log-start offset, so that it is set in next run of RLMTask\\n        copiedOffsetOption = Optional.empty();\\n        isLogStartOffsetUpdatedOnBecomingLeader = false;\\n    }\\n\\n    public void convertToFollower() {\\n        leaderEpoch = -1;\\n    }\\n\\n    private void maybeUpdateLogStartOffsetOnBecomingLeader(UnifiedLog log) throws RemoteStorageException {\\n        if (!isLogStartOffsetUpdatedOnBecomingLeader) {\\n            long logStartOffset = findLogStartOffset(topicIdPartition, log);\\n            updateRemoteLogStartOffset.accept(topicIdPartition.topicPartition(), logStartOffset);\\n            isLogStartOffsetUpdatedOnBecomingLeader = true;\\n            logger.info(\"Found the logStartOffset: {} for partition: {} after becoming leader, leaderEpoch: {}\", logStartOffset, topicIdPartition, leaderEpoch);\\n        }\\n    }\\n\\n    private void maybeUpdateCopiedOffset(UnifiedLog log) throws RemoteStorageException {\\n        if (!copiedOffsetOption.isPresent()) {\\n            // This is found by traversing from the latest leader epoch from leader epoch history and find the highest offset\\n            // of a segment with that epoch copied into remote storage. If it can not find an entry then it checks for the\\n            // previous leader epoch till it finds an entry, If there are no entries till the earliest leader epoch in leader\\n            // epoch cache then it starts copying the segments from the earliest epoch entry\\'s offset.\\n            copiedOffsetOption = Optional.of(findHighestRemoteOffset(topicIdPartition, log));\\n            logger.info(\"Found the highest copiedRemoteOffset: {} for partition: {} after becoming leader, \" + \"leaderEpoch: {}\", copiedOffsetOption, topicIdPartition, leaderEpoch);\\n            copiedOffsetOption.ifPresent(offsetAndEpoch -> log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset()));\\n        }\\n    }\\n\\n    /**\\n     *  Segments which match the following criteria are eligible for copying to remote storage:\\n     *  1) Segment is not the active segment and\\n     *  2) Segment end-offset is less than the last-stable-offset as remote storage should contain only\\n     *     committed/acked messages\\n     * @param log The log from which the segments are to be copied\\n     * @param fromOffset The offset from which the segments are to be copied\\n     * @param lastStableOffset The last stable offset of the log\\n     * @return candidate log segments to be copied to remote storage\\n     */\\n    List<EnrichedLogSegment> candidateLogSegments(UnifiedLog log, Long fromOffset, Long lastStableOffset) {\\n        List<EnrichedLogSegment> candidateLogSegments = new ArrayList<>();\\n        List<LogSegment> segments = JavaConverters.seqAsJavaList(log.logSegments(fromOffset, Long.MAX_VALUE).toSeq());\\n        if (!segments.isEmpty()) {\\n            for (int idx = 1; idx < segments.size(); idx++) {\\n                LogSegment previousSeg = segments.get(idx - 1);\\n                LogSegment currentSeg = segments.get(idx);\\n                if (currentSeg.baseOffset() <= lastStableOffset) {\\n                    candidateLogSegments.add(new EnrichedLogSegment(previousSeg, currentSeg.baseOffset()));\\n                }\\n            }\\n            // Discard the last active segment\\n        }\\n        return candidateLogSegments;\\n    }\\n\\n    public void copyLogSegmentsToRemote(UnifiedLog log) throws InterruptedException {\\n        if (isCancelled())\\n            return;\\n        try {\\n            maybeUpdateLogStartOffsetOnBecomingLeader(log);\\n            maybeUpdateCopiedOffset(log);\\n            long copiedOffset = copiedOffsetOption.get().offset();\\n            // LSO indicates the offset below are ready to be consumed (high-watermark or committed)\\n            long lso = log.lastStableOffset();\\n            if (lso < 0) {\\n                logger.warn(\"lastStableOffset for partition {} is {}, which should not be negative.\", topicIdPartition, lso);\\n            } else if (lso > 0 && copiedOffset < lso) {\\n                // log-start-offset can be ahead of the copied-offset, when:\\n                // 1) log-start-offset gets incremented via delete-records API (or)\\n                // 2) enabling the remote log for the first time\\n                long fromOffset = Math.max(copiedOffset + 1, log.logStartOffset());\\n                List<EnrichedLogSegment> candidateLogSegments = candidateLogSegments(log, fromOffset, lso);\\n                logger.debug(\"Candidate log segments, logStartOffset: {}, copiedOffset: {}, fromOffset: {}, lso: {} \" + \"and candidateLogSegments: {}\", log.logStartOffset(), copiedOffset, fromOffset, lso, candidateLogSegments);\\n                if (candidateLogSegments.isEmpty()) {\\n                    logger.debug(\"No segments found to be copied for partition {} with copiedOffset: {} and active segment\\'s base-offset: {}\", topicIdPartition, copiedOffset, log.activeSegment().baseOffset());\\n                } else {\\n                    for (EnrichedLogSegment candidateLogSegment : candidateLogSegments) {\\n                        if (isCancelled() || !isLeader()) {\\n                            logger.info(\"Skipping copying log segments as the current task state is changed, cancelled: {} leader:{}\", isCancelled(), isLeader());\\n                            return;\\n                        }\\n                        copyQuotaManagerLock.lock();\\n                        try {\\n                            while (rlmCopyQuotaManager.isQuotaExceeded()) {\\n                                logger.debug(\"Quota exceeded for copying log segments, waiting for the quota to be available.\");\\n                                // If the thread gets interrupted while waiting, the InterruptedException is thrown\\n                                // back to the caller. It\\'s important to note that the task being executed is already\\n                                // cancelled before the executing thread is interrupted. The caller is responsible\\n                                // for handling the exception gracefully by checking if the task is already cancelled.\\n                                boolean ignored = copyQuotaManagerLockCondition.await(quotaTimeout().toMillis(), TimeUnit.MILLISECONDS);\\n                            }\\n                            rlmCopyQuotaManager.record(candidateLogSegment.logSegment.log().sizeInBytes());\\n                            // Signal waiting threads to check the quota again\\n                            copyQuotaManagerLockCondition.signalAll();\\n                        } finally {\\n                            copyQuotaManagerLock.unlock();\\n                        }\\n                        copyLogSegment(log, candidateLogSegment.logSegment, candidateLogSegment.nextSegmentOffset);\\n                    }\\n                }\\n            } else {\\n                logger.debug(\"Skipping copying segments, current read-offset:{}, and LSO:{}\", copiedOffset, lso);\\n            }\\n        } catch (CustomMetadataSizeLimitExceededException e) {\\n            // Only stop this task. Logging is done where the exception is thrown.\\n            brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n            brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n            this.cancel();\\n        } catch (InterruptedException | RetriableException ex) {\\n            throw ex;\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                brokerTopicStats.topicStats(log.topicPartition().topic()).failedRemoteCopyRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().failedRemoteCopyRequestRate().mark();\\n                logger.error(\"Error occurred while copying log segments of partition: {}\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    private void copyLogSegment(UnifiedLog log, LogSegment segment, long nextSegmentBaseOffset) throws InterruptedException, ExecutionException, RemoteStorageException, IOException, CustomMetadataSizeLimitExceededException {\\n        File logFile = segment.log().file();\\n        String logFileName = logFile.getName();\\n        logger.info(\"Copying {} to remote storage.\", logFileName);\\n        RemoteLogSegmentId id = RemoteLogSegmentId.generateNew(topicIdPartition);\\n        long endOffset = nextSegmentBaseOffset - 1;\\n        File producerStateSnapshotFile = log.producerStateManager().fetchSnapshot(nextSegmentBaseOffset).orElse(null);\\n        List<EpochEntry> epochEntries = getLeaderEpochEntries(log, segment.baseOffset(), nextSegmentBaseOffset);\\n        Map<Integer, Long> segmentLeaderEpochs = new HashMap<>(epochEntries.size());\\n        epochEntries.forEach(entry -> segmentLeaderEpochs.put(entry.epoch, entry.startOffset));\\n        RemoteLogSegmentMetadata copySegmentStartedRlsm = new RemoteLogSegmentMetadata(id, segment.baseOffset(), endOffset, segment.largestTimestamp(), brokerId, time.milliseconds(), segment.log().sizeInBytes(), segmentLeaderEpochs);\\n        remoteLogMetadataManager.addRemoteLogSegmentMetadata(copySegmentStartedRlsm).get();\\n        ByteBuffer leaderEpochsIndex = epochEntriesAsByteBuffer(getLeaderEpochEntries(log, -1, nextSegmentBaseOffset));\\n        LogSegmentData segmentData = new LogSegmentData(logFile.toPath(), toPathIfExists(segment.offsetIndex().file()), toPathIfExists(segment.timeIndex().file()), Optional.ofNullable(toPathIfExists(segment.txnIndex().file())), producerStateSnapshotFile.toPath(), leaderEpochsIndex);\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyRequestRate().mark();\\n        brokerTopicStats.allTopicsStats().remoteCopyRequestRate().mark();\\n        Optional<CustomMetadata> customMetadata = remoteLogStorageManager.copyLogSegmentData(copySegmentStartedRlsm, segmentData);\\n        RemoteLogSegmentMetadataUpdate copySegmentFinishedRlsm = new RemoteLogSegmentMetadataUpdate(id, time.milliseconds(), customMetadata, RemoteLogSegmentState.COPY_SEGMENT_FINISHED, brokerId);\\n        if (customMetadata.isPresent()) {\\n            long customMetadataSize = customMetadata.get().value().length;\\n            if (customMetadataSize > this.customMetadataSizeLimit) {\\n                CustomMetadataSizeLimitExceededException e = new CustomMetadataSizeLimitExceededException();\\n                logger.error(\"Custom metadata size {} exceeds configured limit {}.\" + \" Copying will be stopped and copied segment will be attempted to clean.\" + \" Original metadata: {}\", customMetadataSize, this.customMetadataSizeLimit, copySegmentStartedRlsm, e);\\n                try {\\n                    // For deletion, we provide back the custom metadata by creating a new metadata object from the update.\\n                    // However, the update itself will not be stored in this case.\\n                    remoteLogStorageManager.deleteLogSegmentData(copySegmentStartedRlsm.createWithUpdates(copySegmentFinishedRlsm));\\n                    logger.info(\"Successfully cleaned segment after custom metadata size exceeded\");\\n                } catch (RemoteStorageException e1) {\\n                    logger.error(\"Error while cleaning segment after custom metadata size exceeded, consider cleaning manually\", e1);\\n                }\\n                throw e;\\n            }\\n        }\\n        remoteLogMetadataManager.updateRemoteLogSegmentMetadata(copySegmentFinishedRlsm).get();\\n        brokerTopicStats.topicStats(log.topicPartition().topic()).remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        brokerTopicStats.allTopicsStats().remoteCopyBytesRate().mark(copySegmentStartedRlsm.segmentSizeInBytes());\\n        // `epochEntries` cannot be empty, there is a pre-condition validation in RemoteLogSegmentMetadata\\n        // constructor\\n        int lastEpochInSegment = epochEntries.get(epochEntries.size() - 1).epoch;\\n        copiedOffsetOption = Optional.of(new OffsetAndEpoch(endOffset, lastEpochInSegment));\\n        // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n        // are not deleted before they are copied to remote storage.\\n        log.updateHighestOffsetInRemoteStorage(endOffset);\\n        logger.info(\"Copied {} to remote storage with segment-id: {}\", logFileName, copySegmentFinishedRlsm.remoteLogSegmentId());\\n        long bytesLag = log.onlyLocalLogSegmentsSize() - log.activeSegment().size();\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        long segmentsLag = log.onlyLocalLogSegmentsCount();\\n        brokerTopicStats.recordRemoteCopyLagBytes(topic, partition, bytesLag);\\n        brokerTopicStats.recordRemoteCopyLagSegments(topic, partition, segmentsLag);\\n    }\\n\\n    private Path toPathIfExists(File file) {\\n        return file.exists() ? file.toPath() : null;\\n    }\\n\\n    public void run() {\\n        if (isCancelled())\\n            return;\\n        try {\\n            Optional<UnifiedLog> unifiedLogOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n            if (!unifiedLogOptional.isPresent()) {\\n                return;\\n            }\\n            UnifiedLog log = unifiedLogOptional.get();\\n            // In the first run after completing altering logDir within broker, we should make sure the state is reset. (KAFKA-16711)\\n            if (!log.parentDir().equals(logDirectory.orElse(null))) {\\n                copiedOffsetOption = Optional.empty();\\n                isLogStartOffsetUpdatedOnBecomingLeader = false;\\n                logDirectory = Optional.of(log.parentDir());\\n            }\\n            if (isLeader()) {\\n                // Copy log segments to remote storage\\n                copyLogSegmentsToRemote(log);\\n                // Cleanup/delete expired remote log segments\\n                cleanupExpiredRemoteLogSegments();\\n            } else {\\n                OffsetAndEpoch offsetAndEpoch = findHighestRemoteOffset(topicIdPartition, log);\\n                // Update the highest offset in remote storage for this partition\\'s log so that the local log segments\\n                // are not deleted before they are copied to remote storage.\\n                log.updateHighestOffsetInRemoteStorage(offsetAndEpoch.offset());\\n            }\\n        } catch (InterruptedException ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current thread for topic-partition-id {} is interrupted\", topicIdPartition, ex);\\n            }\\n        } catch (RetriableException ex) {\\n            logger.debug(\"Encountered a retryable error while executing current task for topic-partition {}\", topicIdPartition, ex);\\n        } catch (Exception ex) {\\n            if (!isCancelled()) {\\n                logger.warn(\"Current task for topic-partition {} received error but it will be scheduled\", topicIdPartition, ex);\\n            }\\n        }\\n    }\\n\\n    public void handleLogStartOffsetUpdate(TopicPartition topicPartition, long remoteLogStartOffset) {\\n        if (isLeader()) {\\n            logger.debug(\"Updating {} with remoteLogStartOffset: {}\", topicPartition, remoteLogStartOffset);\\n            updateRemoteLogStartOffset.accept(topicPartition, remoteLogStartOffset);\\n        }\\n    }\\n\\n    class RemoteLogRetentionHandler {\\n\\n        private final Optional<RetentionSizeData> retentionSizeData;\\n\\n        private final Optional<RetentionTimeData> retentionTimeData;\\n\\n        private long remainingBreachedSize;\\n\\n        private OptionalLong logStartOffset = OptionalLong.empty();\\n\\n        public RemoteLogRetentionHandler(Optional<RetentionSizeData> retentionSizeData, Optional<RetentionTimeData> retentionTimeData) {\\n            this.retentionSizeData = retentionSizeData;\\n            this.retentionTimeData = retentionTimeData;\\n            remainingBreachedSize = retentionSizeData.map(sizeData -> sizeData.remainingBreachedSize).orElse(0L);\\n        }\\n\\n        private boolean isSegmentBreachedByRetentionSize(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionSizeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            // Assumption that segments contain size >= 0\\n            if (remainingBreachedSize > 0) {\\n                long remainingBytes = remainingBreachedSize - metadata.segmentSizeInBytes();\\n                if (remainingBytes >= 0) {\\n                    remainingBreachedSize = remainingBytes;\\n                    shouldDeleteSegment = true;\\n                }\\n            }\\n            if (shouldDeleteSegment) {\\n                if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                }\\n                logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\", metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        public boolean isSegmentBreachedByRetentionTime(RemoteLogSegmentMetadata metadata) {\\n            boolean shouldDeleteSegment = false;\\n            if (!retentionTimeData.isPresent()) {\\n                return shouldDeleteSegment;\\n            }\\n            shouldDeleteSegment = metadata.maxTimestampMs() <= retentionTimeData.get().cleanupUntilMs;\\n            if (shouldDeleteSegment) {\\n                remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                // are ascending with in an epoch.\\n                if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n                }\\n                logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\", metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        private boolean isSegmentBreachByLogStartOffset(RemoteLogSegmentMetadata metadata, long logStartOffset, NavigableMap<Integer, Long> leaderEpochEntries) {\\n            boolean shouldDeleteSegment = false;\\n            if (!leaderEpochEntries.isEmpty()) {\\n                // Note that `logStartOffset` and `leaderEpochEntries.firstEntry().getValue()` should be same\\n                Integer firstEpoch = leaderEpochEntries.firstKey();\\n                shouldDeleteSegment = metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch <= firstEpoch) && metadata.endOffset() < logStartOffset;\\n            }\\n            if (shouldDeleteSegment) {\\n                logger.info(\"About to delete remote log segment {} due to log-start-offset {} breach. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), logStartOffset, leaderEpochEntries.firstEntry(), metadata.endOffset(), metadata.segmentLeaderEpochs());\\n            }\\n            return shouldDeleteSegment;\\n        }\\n\\n        // It removes the segments beyond the current leader\\'s earliest epoch. Those segments are considered as\\n        // unreferenced because they are not part of the current leader epoch lineage.\\n        private boolean deleteLogSegmentsDueToLeaderEpochCacheTruncation(EpochEntry earliestEpochEntry, RemoteLogSegmentMetadata metadata) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            boolean isSegmentDeleted = deleteRemoteLogSegment(metadata, ignored -> metadata.segmentLeaderEpochs().keySet().stream().allMatch(epoch -> epoch < earliestEpochEntry.epoch));\\n            if (isSegmentDeleted) {\\n                logger.info(\"Deleted remote log segment {} due to leader-epoch-cache truncation. \" + \"Current earliest-epoch-entry: {}, segment-end-offset: {} and segment-epochs: {}\", metadata.remoteLogSegmentId(), earliestEpochEntry, metadata.endOffset(), metadata.segmentLeaderEpochs().keySet());\\n            }\\n            // No need to update the log-start-offset as these epochs/offsets are earlier to that value.\\n            return isSegmentDeleted;\\n        }\\n\\n        private boolean deleteRemoteLogSegment(RemoteLogSegmentMetadata segmentMetadata, Predicate<RemoteLogSegmentMetadata> predicate) throws RemoteStorageException, ExecutionException, InterruptedException {\\n            if (predicate.test(segmentMetadata)) {\\n                logger.debug(\"Deleting remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                String topic = segmentMetadata.topicIdPartition().topic();\\n                // Publish delete segment started event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_STARTED, brokerId)).get();\\n                brokerTopicStats.topicStats(topic).remoteDeleteRequestRate().mark();\\n                brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().mark();\\n                // Delete the segment in remote storage.\\n                try {\\n                    remoteLogStorageManager.deleteLogSegmentData(segmentMetadata);\\n                } catch (RemoteStorageException e) {\\n                    brokerTopicStats.topicStats(topic).failedRemoteDeleteRequestRate().mark();\\n                    brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().mark();\\n                    throw e;\\n                }\\n                // Publish delete segment finished event.\\n                remoteLogMetadataManager.updateRemoteLogSegmentMetadata(new RemoteLogSegmentMetadataUpdate(segmentMetadata.remoteLogSegmentId(), time.milliseconds(), segmentMetadata.customMetadata(), RemoteLogSegmentState.DELETE_SEGMENT_FINISHED, brokerId)).get();\\n                logger.debug(\"Deleted remote log segment {}\", segmentMetadata.remoteLogSegmentId());\\n                return true;\\n            }\\n            return false;\\n        }\\n    }\\n\\n    private void updateMetadataCountAndLogSizeWith(int metadataCount, long remoteLogSizeBytes) {\\n        int partition = topicIdPartition.partition();\\n        String topic = topicIdPartition.topic();\\n        brokerTopicStats.recordRemoteLogMetadataCount(topic, partition, metadataCount);\\n        brokerTopicStats.recordRemoteLogSizeBytes(topic, partition, remoteLogSizeBytes);\\n    }\\n\\n    private void updateRemoteDeleteLagWith(int segmentsLeftToDelete, long sizeOfDeletableSegmentsBytes) {\\n        String topic = topicIdPartition.topic();\\n        int partition = topicIdPartition.partition();\\n        brokerTopicStats.recordRemoteDeleteLagSegments(topic, partition, segmentsLeftToDelete);\\n        brokerTopicStats.recordRemoteDeleteLagBytes(topic, partition, sizeOfDeletableSegmentsBytes);\\n    }\\n\\n    void cleanupExpiredRemoteLogSegments() throws RemoteStorageException, ExecutionException, InterruptedException {\\n        if (isCancelled() || !isLeader()) {\\n            logger.info(\"Returning from remote log segments cleanup as the task state is changed\");\\n            return;\\n        }\\n        final Optional<UnifiedLog> logOptional = fetchLog.apply(topicIdPartition.topicPartition());\\n        if (!logOptional.isPresent()) {\\n            logger.debug(\"No UnifiedLog instance available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final UnifiedLog log = logOptional.get();\\n        final Option<LeaderEpochFileCache> leaderEpochCacheOption = log.leaderEpochCache();\\n        if (leaderEpochCacheOption.isEmpty()) {\\n            logger.debug(\"No leader epoch cache available for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        // Cleanup remote log segments and update the log start offset if applicable.\\n        final Iterator<RemoteLogSegmentMetadata> segmentMetadataIter = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition);\\n        if (!segmentMetadataIter.hasNext()) {\\n            updateMetadataCountAndLogSizeWith(0, 0);\\n            logger.debug(\"No remote log segments available on remote storage for partition: {}\", topicIdPartition);\\n            return;\\n        }\\n        final Set<Integer> epochsSet = new HashSet<>();\\n        int metadataCount = 0;\\n        long remoteLogSizeBytes = 0;\\n        // Good to have an API from RLMM to get all the remote leader epochs of all the segments of a partition\\n        // instead of going through all the segments and building it here.\\n        while (segmentMetadataIter.hasNext()) {\\n            RemoteLogSegmentMetadata segmentMetadata = segmentMetadataIter.next();\\n            epochsSet.addAll(segmentMetadata.segmentLeaderEpochs().keySet());\\n            metadataCount++;\\n            remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n        }\\n        updateMetadataCountAndLogSizeWith(metadataCount, remoteLogSizeBytes);\\n        // All the leader epochs in sorted order that exists in remote storage\\n        final List<Integer> remoteLeaderEpochs = new ArrayList<>(epochsSet);\\n        Collections.sort(remoteLeaderEpochs);\\n        LeaderEpochFileCache leaderEpochCache = leaderEpochCacheOption.get();\\n        // Build the leader epoch map by filtering the epochs that do not have any records.\\n        NavigableMap<Integer, Long> epochWithOffsets = buildFilteredLeaderEpochMap(leaderEpochCache.epochWithOffsets());\\n        long logStartOffset = log.logStartOffset();\\n        long logEndOffset = log.logEndOffset();\\n        Optional<RetentionSizeData> retentionSizeData = buildRetentionSizeData(log.config().retentionSize, log.onlyLocalLogSegmentsSize(), logEndOffset, epochWithOffsets);\\n        Optional<RetentionTimeData> retentionTimeData = buildRetentionTimeData(log.config().retentionMs);\\n        RemoteLogRetentionHandler remoteLogRetentionHandler = new RemoteLogRetentionHandler(retentionSizeData, retentionTimeData);\\n        Iterator<Integer> epochIterator = epochWithOffsets.navigableKeySet().iterator();\\n        boolean canProcess = true;\\n        List<RemoteLogSegmentMetadata> segmentsToDelete = new ArrayList<>();\\n        long sizeOfDeletableSegmentsBytes = 0L;\\n        while (canProcess && epochIterator.hasNext()) {\\n            Integer epoch = epochIterator.next();\\n            Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n            while (canProcess && segmentsIterator.hasNext()) {\\n                if (isCancelled() || !isLeader()) {\\n                    logger.info(\"Returning from remote log segments cleanup for the remaining segments as the task state is changed.\");\\n                    return;\\n                }\\n                RemoteLogSegmentMetadata metadata = segmentsIterator.next();\\n                if (RemoteLogSegmentState.DELETE_SEGMENT_FINISHED.equals(metadata.state())) {\\n                    continue;\\n                }\\n                if (segmentsToDelete.contains(metadata)) {\\n                    continue;\\n                }\\n                // When the log-start-offset is moved by the user, the leader-epoch-checkpoint file gets truncated\\n                // as per the log-start-offset. Until the rlm-cleaner-thread runs in the next iteration, those\\n                // remote log segments won\\'t be removed. The `isRemoteSegmentWithinLeaderEpoch` validates whether\\n                // the epochs present in the segment lies in the checkpoint file. It will always return false\\n                // since the checkpoint file was already truncated.\\n                boolean shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachByLogStartOffset(metadata, logStartOffset, epochWithOffsets);\\n                boolean isValidSegment = false;\\n                if (!shouldDeleteSegment) {\\n                    // check whether the segment contains the required epoch range with in the current leader epoch lineage.\\n                    isValidSegment = isRemoteSegmentWithinLeaderEpochs(metadata, logEndOffset, epochWithOffsets);\\n                    if (isValidSegment) {\\n                        shouldDeleteSegment = remoteLogRetentionHandler.isSegmentBreachedByRetentionTime(metadata) || remoteLogRetentionHandler.isSegmentBreachedByRetentionSize(metadata);\\n                    }\\n                }\\n                if (shouldDeleteSegment) {\\n                    segmentsToDelete.add(metadata);\\n                    sizeOfDeletableSegmentsBytes += metadata.segmentSizeInBytes();\\n                }\\n                canProcess = shouldDeleteSegment || !isValidSegment;\\n            }\\n        }\\n        // Update log start offset with the computed value after retention cleanup is done\\n        remoteLogRetentionHandler.logStartOffset.ifPresent(offset -> handleLogStartOffsetUpdate(topicIdPartition.topicPartition(), offset));\\n        // At this point in time we have updated the log start offsets, but not initiated a deletion.\\n        // Either a follower has picked up the changes to the log start offset, or they have not.\\n        // If the follower HAS picked up the changes, and they become the leader this replica won\\'t successfully complete\\n        // the deletion.\\n        // However, the new leader will correctly pick up all breaching segments as log start offset breaching ones\\n        // and delete them accordingly.\\n        // If the follower HAS NOT picked up the changes, and they become the leader then they will go through this process\\n        // again and delete them with the original deletion reason i.e. size, time or log start offset breach.\\n        int segmentsLeftToDelete = segmentsToDelete.size();\\n        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n        List<String> undeletedSegments = new ArrayList<>();\\n        for (RemoteLogSegmentMetadata segmentMetadata : segmentsToDelete) {\\n            if (!remoteLogRetentionHandler.deleteRemoteLogSegment(segmentMetadata, x -> !isCancelled() && isLeader())) {\\n                undeletedSegments.add(segmentMetadata.remoteLogSegmentId().toString());\\n            } else {\\n                sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                segmentsLeftToDelete--;\\n                updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            }\\n        }\\n        if (!undeletedSegments.isEmpty()) {\\n            logger.info(\"The following remote segments could not be deleted: {}\", String.join(\",\", undeletedSegments));\\n        }\\n        // Remove the remote log segments whose segment-leader-epochs are less than the earliest-epoch known\\n        // to the leader. This will remove the unreferenced segments in the remote storage. This is needed for\\n        // unclean leader election scenarios as the remote storage can have epochs earlier to the current leader\\'s\\n        // earliest leader epoch.\\n        Optional<EpochEntry> earliestEpochEntryOptional = leaderEpochCache.earliestEntry();\\n        if (earliestEpochEntryOptional.isPresent()) {\\n            EpochEntry earliestEpochEntry = earliestEpochEntryOptional.get();\\n            Iterator<Integer> epochsToClean = remoteLeaderEpochs.stream().filter(remoteEpoch -> remoteEpoch < earliestEpochEntry.epoch).iterator();\\n            List<RemoteLogSegmentMetadata> listOfSegmentsToBeCleaned = new ArrayList<>();\\n            while (epochsToClean.hasNext()) {\\n                int epoch = epochsToClean.next();\\n                Iterator<RemoteLogSegmentMetadata> segmentsToBeCleaned = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsToBeCleaned.hasNext()) {\\n                    if (!isCancelled() && isLeader()) {\\n                        RemoteLogSegmentMetadata nextSegmentMetadata = segmentsToBeCleaned.next();\\n                        sizeOfDeletableSegmentsBytes += nextSegmentMetadata.segmentSizeInBytes();\\n                        listOfSegmentsToBeCleaned.add(nextSegmentMetadata);\\n                    }\\n                }\\n            }\\n            segmentsLeftToDelete += listOfSegmentsToBeCleaned.size();\\n            updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n            for (RemoteLogSegmentMetadata segmentMetadata : listOfSegmentsToBeCleaned) {\\n                if (!isCancelled() && isLeader()) {\\n                    // No need to update the log-start-offset even though the segment is deleted as these epochs/offsets are earlier to that value.\\n                    if (remoteLogRetentionHandler.deleteLogSegmentsDueToLeaderEpochCacheTruncation(earliestEpochEntry, segmentMetadata)) {\\n                        sizeOfDeletableSegmentsBytes -= segmentMetadata.segmentSizeInBytes();\\n                        segmentsLeftToDelete--;\\n                        updateRemoteDeleteLagWith(segmentsLeftToDelete, sizeOfDeletableSegmentsBytes);\\n                    }\\n                }\\n            }\\n        }\\n    }\\n\\n    private Optional<RetentionTimeData> buildRetentionTimeData(long retentionMs) {\\n        return retentionMs > -1 ? Optional.of(new RetentionTimeData(retentionMs, time.milliseconds() - retentionMs)) : Optional.empty();\\n    }\\n\\n    private Optional<RetentionSizeData> buildRetentionSizeData(long retentionSize, long onlyLocalLogSegmentsSize, long logEndOffset, NavigableMap<Integer, Long> epochEntries) throws RemoteStorageException {\\n        if (retentionSize > -1) {\\n            long startTimeMs = time.milliseconds();\\n            long remoteLogSizeBytes = 0L;\\n            Set<RemoteLogSegmentId> visitedSegmentIds = new HashSet<>();\\n            for (Integer epoch : epochEntries.navigableKeySet()) {\\n                // remoteLogSize(topicIdPartition, epochEntry.epoch) may not be completely accurate as the remote\\n                // log size may be computed for all the segments but not for segments with in the current\\n                // partition\\'s leader epoch lineage. Better to revisit this API.\\n                // remoteLogSizeBytes += remoteLogMetadataManager.remoteLogSize(topicIdPartition, epochEntry.epoch);\\n                Iterator<RemoteLogSegmentMetadata> segmentsIterator = remoteLogMetadataManager.listRemoteLogSegments(topicIdPartition, epoch);\\n                while (segmentsIterator.hasNext()) {\\n                    RemoteLogSegmentMetadata segmentMetadata = segmentsIterator.next();\\n                    RemoteLogSegmentId segmentId = segmentMetadata.remoteLogSegmentId();\\n                    if (!visitedSegmentIds.contains(segmentId) && isRemoteSegmentWithinLeaderEpochs(segmentMetadata, logEndOffset, epochEntries)) {\\n                        remoteLogSizeBytes += segmentMetadata.segmentSizeInBytes();\\n                        visitedSegmentIds.add(segmentId);\\n                    }\\n                }\\n            }\\n            brokerTopicStats.recordRemoteLogSizeComputationTime(topicIdPartition.topic(), topicIdPartition.partition(), time.milliseconds() - startTimeMs);\\n            // This is the total size of segments in local log that have their base-offset > local-log-start-offset\\n            // and size of the segments in remote storage which have their end-offset < local-log-start-offset.\\n            long totalSize = onlyLocalLogSegmentsSize + remoteLogSizeBytes;\\n            if (totalSize > retentionSize) {\\n                long remainingBreachedSize = totalSize - retentionSize;\\n                RetentionSizeData retentionSizeData = new RetentionSizeData(retentionSize, remainingBreachedSize);\\n                return Optional.of(retentionSizeData);\\n            }\\n        }\\n        return Optional.empty();\\n    }\\n\\n    public String toString() {\\n        return this.getClass() + \"[\" + topicIdPartition + \"]\";\\n    }\\n}\\n}\\n\\ncore/src/test/java/kafka/log/remote/RemoteLogManagerTest.java (Before)\\npublic class RemoteLogManagerTest {\\n@ParameterizedTest(name = \"testDeletionOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    doAnswer(ans -> {\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic)));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments\"), String.format(\"Expected to find 2 for RemoteDeleteLagSegments metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments\")));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 2 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).doAnswer(ans -> {\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).when(remoteStorageManager).deleteLogSegmentData(any(RemoteLogSegmentMetadata.class));\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagBytes\"));\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagSegments\"));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic));\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n}\\n}\\n\\ncore/src/test/java/kafka/log/remote/RemoteLogManagerTest.java (After)\\npublic class RemoteLogManagerTest {\\n@ParameterizedTest(name = \"testDeletionOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED).get(0);\\n    // overlapping segment\\n    RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()), metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(), metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128, metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n    // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n    // returns the segments in order of (valid ++ unreferenced) segments:\\n    // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n    //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n    //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n    // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n    List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n    metadataList.add(metadata2);\\n    metadataList.add(metadata1);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n    // Verify the metric for remote delete is updated correctly\\n    assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n    // Verify we did not report any failure for remote deletes\\n    assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n    // Verify aggregate metrics\\n    assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n    assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n}\\n@ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n@CsvSource(value = { \"0, -1\", \"-1, 0\" })\\npublic void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize, long retentionMs) throws RemoteStorageException, ExecutionException, InterruptedException {\\n    Map<String, Long> logProps = new HashMap<>();\\n    logProps.put(\"retention.bytes\", retentionSize);\\n    logProps.put(\"retention.ms\", retentionMs);\\n    LogConfig mockLogConfig = new LogConfig(logProps);\\n    when(mockLog.config()).thenReturn(mockLogConfig);\\n    List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n    checkpoint.write(epochEntries);\\n    LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n    when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n    when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n    when(mockLog.logEndOffset()).thenReturn(200L);\\n    List<RemoteLogSegmentMetadata> metadataList = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 2, 100, 1024, epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED);\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition)).thenReturn(metadataList.iterator());\\n    when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0)).thenAnswer(ans -> metadataList.iterator());\\n    when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class))).thenReturn(CompletableFuture.runAsync(() -> {\\n    }));\\n    doAnswer(ans -> {\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(2048, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic), String.format(\"Expected to find 2048 for RemoteDeleteLagBytes for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic)));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments\"), String.format(\"Expected to find 2 for RemoteDeleteLagSegments metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments\")));\\n        assertEquals(2, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 2 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).doAnswer(ans -> {\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        assertEquals(1024, safeLongYammerMetricValue(\"RemoteDeleteLagBytes\"), String.format(\"Expected to find 1024 for RemoteDeleteLagBytes metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagBytes\")));\\n        assertEquals(1, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic), String.format(\"Expected to find 1 for RemoteDeleteLagSegments for \\'Leader\\' topic metric value, but found %d\", safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic)));\\n        return Optional.empty();\\n    }).when(remoteStorageManager).deleteLogSegmentData(any(RemoteLogSegmentMetadata.class));\\n    RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagBytes\"));\\n    assertEquals(0L, yammerMetricValue(\"RemoteDeleteLagSegments\"));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagBytes,topic=\" + leaderTopic));\\n    assertEquals(0L, safeLongYammerMetricValue(\"RemoteDeleteLagSegments,topic=\" + leaderTopic));\\n    task.convertToLeader(0);\\n    task.cleanupExpiredRemoteLogSegments();\\n    assertEquals(200L, currentLogStartOffset.get());\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n    verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n}\\n}\\n\\n\\nSummary:', 'role': 'user'}], 'model': 'deepseek/deepseek-r1-distill-qwen-32b', 'max_tokens': 4096, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB72F3230>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021AB6052720> server_hostname='openrouter.ai' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB7410B90>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 25 Feb 2025 12:26:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Origin', b'*'), (b'x-clerk-auth-message', b'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)'), (b'x-clerk-auth-reason', b'token-invalid'), (b'x-clerk-auth-status', b'signed-out'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9177af476be93f7c-SIN'), (b'Content-Encoding', b'gzip')])\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 25 Feb 2025 12:26:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'x-clerk-auth-message': 'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)', 'x-clerk-auth-reason': 'token-invalid', 'x-clerk-auth-status': 'signed-out', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'cf-ray': '9177af476be93f7c-SIN', 'content-encoding': 'gzip'})\n",
      "DEBUG:openai._base_client:request_id: None\n",
      "DEBUG:faiss.loader:Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU\n",
      "INFO:faiss.loader:Loading faiss with AVX512 support.\n",
      "INFO:faiss.loader:Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x0000021AB79C7600>, 'json_data': {'input': [[791, 2082, 4442, 3044, 750, 2713, 279, 1595, 848, 3563, 6582, 63, 2391, 8870, 1515, 10449, 37166, 311, 6106, 433, 1193, 12992, 994, 5995, 11, 27252, 4754, 4819, 449, 50917, 477, 23329, 21282, 13, 23212, 11, 264, 502, 1296, 574, 3779, 311, 10356, 279, 4495, 11850, 323, 37166, 315, 50917, 8870, 1515, 21282, 1234, 38231, 10396, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 34\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB72BF890>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021AB60523C0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB74ABA80>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 34\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 25 Feb 2025 12:26:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'97'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-db5fdd654-lxs5d'), (b'x-envoy-upstream-service-time', b'53'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999943'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_7314545776cf68e21de4d38909565a51'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=h2f_LmhpzcZPB6YvFvaDey1tTlh8hjBIYnBeySr4ReE-1740486409-1.0.1.1-4P_VPNrg1edvv7xlHXZA_5jH.J852fAKYDgENQtqViWo7VdV0TUDttb4FlS1vDVbAMV7aSNIRl5HHBwi15vAMA; path=/; expires=Tue, 25-Feb-25 12:56:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=6ay_xZSM1_QlKwFnIWGhPg3twrFh5dbZI7t.AUPrHEw-1740486409364-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9177af9828c3fdb4-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Tue, 25 Feb 2025 12:26:49 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '97'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-db5fdd654-lxs5d'), ('x-envoy-upstream-service-time', '53'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999943'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '3ms'), ('x-request-id', 'req_7314545776cf68e21de4d38909565a51'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=h2f_LmhpzcZPB6YvFvaDey1tTlh8hjBIYnBeySr4ReE-1740486409-1.0.1.1-4P_VPNrg1edvv7xlHXZA_5jH.J852fAKYDgENQtqViWo7VdV0TUDttb4FlS1vDVbAMV7aSNIRl5HHBwi15vAMA; path=/; expires=Tue, 25-Feb-25 12:56:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=6ay_xZSM1_QlKwFnIWGhPg3twrFh5dbZI7t.AUPrHEw-1740486409364-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9177af9828c3fdb4-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_7314545776cf68e21de4d38909565a51\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context is strictly relevant to the code changes. Otherwise, return NO.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: \\n>>>\\ndiff --git a/core/src/main/java/kafka/log/remote/RemoteLogManager.java b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\nindex c1c87d579e..3eacbea475 100644\\n--- a/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n+++ b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n@@ -983,7 +983,9 @@ public class RemoteLogManager implements Closeable {\\n                     }\\n                 }\\n                 if (shouldDeleteSegment) {\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\",\\n                             metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n                 }\\n@@ -1000,7 +1002,9 @@ public class RemoteLogManager implements Closeable {\\n                     remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                     // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                     // are ascending with in an epoch.\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\",\\n                             metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n                 }\\ndiff --git a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\nindex 4c4976f060..3c9b8a48e9 100644\\n--- a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n+++ b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n@@ -2055,6 +2055,75 @@ public class RemoteLogManagerTest {\\n         assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n     }\\n \\n+    @ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n+    @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n+    public void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize,\\n+                                                                   long retentionMs)\\n+            throws RemoteStorageException, ExecutionException, InterruptedException {\\n+        Map<String, Long> logProps = new HashMap<>();\\n+        logProps.put(\"retention.bytes\", retentionSize);\\n+        logProps.put(\"retention.ms\", retentionMs);\\n+        LogConfig mockLogConfig = new LogConfig(logProps);\\n+        when(mockLog.config()).thenReturn(mockLogConfig);\\n+\\n+        List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n+        checkpoint.write(epochEntries);\\n+        LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n+        when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n+\\n+        when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n+        when(mockLog.logEndOffset()).thenReturn(200L);\\n+\\n+        RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024,\\n+                epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED)\\n+                .get(0);\\n+        // overlapping segment\\n+        RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()),\\n+                metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(),\\n+                metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128,\\n+                metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n+\\n+        // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n+        // returns the segments in order of (valid ++ unreferenced) segments:\\n+        // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n+        //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n+        //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n+        // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n+        List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n+        metadataList.add(metadata2);\\n+        metadataList.add(metadata1);\\n+\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition))\\n+                .thenReturn(metadataList.iterator());\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0))\\n+                .thenAnswer(ans -> metadataList.iterator());\\n+        when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class)))\\n+                .thenReturn(CompletableFuture.runAsync(() -> { }));\\n+\\n+        // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+\\n+        RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n+        task.convertToLeader(0);\\n+        task.cleanupExpiredRemoteLogSegments();\\n+\\n+        assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n+\\n+        // Verify the metric for remote delete is updated correctly\\n+        assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        // Verify we did not report any failure for remote deletes\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+    }\\n+\\n     @ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n     @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n     public void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize,\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: KAFKA-16890\\nIssue Summary: Failing to build aux state on broker failover\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nWe have clusters where we replace machines often falling into a state where we keep having \"Error building remote log auxiliary state for loadtest_topic-22\" and the partition being under-replicated until the leader is manually restarted.\\xa0\\n\\n\\n\\nLooking into a specific case, here is what we observed in __remote_log_metadata topic:\\n\\n\\n\\n\\n\\n{code:java}\\n\\n\\xa0\\n\\npartition: 29, offset: 183593, value: RemoteLogSegmentMetadata{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=GZeRTXLMSNe2BQjRXkg6hQ}, startOffset=10823, endOffset=11536, brokerId=10013, maxTimestampMs=1715774588597, eventTimestampMs=1715781657604, segmentLeaderEpochs={125=10823, 126=10968, 128=11047, 130=11048, 131=11324, 133=11442, 134=11443, 135=11445, 136=11521, 137=11533, 139=11535}, segmentSizeInBytes=704895, customMetadata=Optional.empty, state=COPY_SEGMENT_STARTED}\\n\\npartition: 29, offset: 183594, value: RemoteLogSegmentMetadataUpdate{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=GZeRTXLMSNe2BQjRXkg6hQ}, customMetadata=Optional.empty, state=COPY_SEGMENT_FINISHED, eventTimestampMs=1715781658183, brokerId=10013}\\n\\npartition: 29, offset: 183669, value: RemoteLogSegmentMetadata{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=L1TYzx0lQkagRIF86Kp0QQ}, startOffset=10823, endOffset=11544, brokerId=10008, maxTimestampMs=1715781445270, eventTimestampMs=1715782717593, segmentLeaderEpochs={125=10823, 126=10968, 128=11047, 130=11048, 131=11324, 133=11442, 134=11443, 135=11445, 136=11521, 137=11533, 139=11535, 140=11537, 142=11543}, segmentSizeInBytes=713088, customMetadata=Optional.empty, state=COPY_SEGMENT_STARTED}\\n\\npartition: 29, offset: 183670, value: RemoteLogSegmentMetadataUpdate{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=L1TYzx0lQkagRIF86Kp0QQ}, customMetadata=Optional.empty, state=COPY_SEGMENT_FINISHED, eventTimestampMs=1715782718370, brokerId=10008}\\n\\npartition: 29, offset: 186215, value: RemoteLogSegmentMetadataUpdate{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=L1TYzx0lQkagRIF86Kp0QQ}, customMetadata=Optional.empty, state=DELETE_SEGMENT_STARTED, eventTimestampMs=1715867874617, brokerId=10008}\\n\\npartition: 29, offset: 186216, value: RemoteLogSegmentMetadataUpdate{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=L1TYzx0lQkagRIF86Kp0QQ}, customMetadata=Optional.empty, state=DELETE_SEGMENT_FINISHED, eventTimestampMs=1715867874725, brokerId=10008}\\n\\npartition: 29, offset: 186217, value: RemoteLogSegmentMetadataUpdate{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=GZeRTXLMSNe2BQjRXkg6hQ}, customMetadata=Optional.empty, state=DELETE_SEGMENT_STARTED, eventTimestampMs=1715867874729, brokerId=10008}\\n\\npartition: 29, offset: 186218, value: RemoteLogSegmentMetadataUpdate{remoteLogSegmentId=RemoteLogSegmentId{topicIdPartition=ClnIeN0MQsi_d4FAOFKaDA:loadtest_topic-22, id=GZeRTXLMSNe2BQjRXkg6hQ}, customMetadata=Optional.empty, state=DELETE_SEGMENT_FINISHED, eventTimestampMs=1715867874817, brokerId=10008}\\n\\n{code}\\n\\n\\xa0\\n\\n\\n\\nIt seems that at the time the leader is restarted (10013), a second copy of the same segment is tiered by the new leader (10008). Interestingly the segment doesn\\'t have the same end offset, which is concerning.\\xa0\\n\\n\\n\\nThen the follower sees the following error repeatedly until the leader is restarted:\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\xa0\\n\\n{code:java}\\n\\n[2024-05-17 20:46:42,133] DEBUG [ReplicaFetcher replicaId=10013, leaderId=10008, fetcherId=0] Handling errors in processFetchRequest for partitions HashSet(loadtest_topic-22) (kafka.server.ReplicaFetcherThread)\\n\\n[2024-05-17 20:46:43,174] DEBUG [ReplicaFetcher replicaId=10013, leaderId=10008, fetcherId=0] Received error OFFSET_MOVED_TO_TIERED_STORAGE, at fetch offset: 11537, topic-partition: loadtest_topic-22 (kafka.server.ReplicaFetcherThread)\\n\\n[2024-05-17 20:46:43,175] ERROR [ReplicaFetcher replicaId=10013, leaderId=10008, fetcherId=0] Error building remote log auxiliary state for loadtest_topic-22 (kafka.server.ReplicaFetcherThread)\\n\\norg.apache.kafka.server.log.remote.storage.RemoteStorageException: Couldn\\'t build the state from remote store for partition: loadtest_topic-22, currentLeaderEpoch: 153, leaderLocalLogStartOffset: 11545, leaderLogStartOffset: 11537, epoch: 142as the previous remote log segment metadata was not found\\n\\n{code}\\n\\nThe follower is trying to fetch from 11537 and gets OFFSET_MOVED_TO_TIERED_STORAGE . Then when the follower retries, it still thinks it needs to fetch from 11537 . There is no data in S3, so the correct leaderLogStartOffset should be 11545 .\\xa0 I\\'m not sure yet if its intentional that there can be two copies of the same segment that are different uploaded to S3 or if the segments were just deleted in the wrong order, but that is what ultimately caused the leaderLogStartOffset to be set incorrectly.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'deepseek/deepseek-r1-distill-qwen-32b', 'max_tokens': 4096, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context is strictly relevant to the code changes. Otherwise, return NO.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: \\n>>>\\ndiff --git a/core/src/main/java/kafka/log/remote/RemoteLogManager.java b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\nindex c1c87d579e..3eacbea475 100644\\n--- a/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n+++ b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n@@ -983,7 +983,9 @@ public class RemoteLogManager implements Closeable {\\n                     }\\n                 }\\n                 if (shouldDeleteSegment) {\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\",\\n                             metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n                 }\\n@@ -1000,7 +1002,9 @@ public class RemoteLogManager implements Closeable {\\n                     remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                     // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                     // are ascending with in an epoch.\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\",\\n                             metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n                 }\\ndiff --git a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\nindex 4c4976f060..3c9b8a48e9 100644\\n--- a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n+++ b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n@@ -2055,6 +2055,75 @@ public class RemoteLogManagerTest {\\n         assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n     }\\n \\n+    @ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n+    @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n+    public void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize,\\n+                                                                   long retentionMs)\\n+            throws RemoteStorageException, ExecutionException, InterruptedException {\\n+        Map<String, Long> logProps = new HashMap<>();\\n+        logProps.put(\"retention.bytes\", retentionSize);\\n+        logProps.put(\"retention.ms\", retentionMs);\\n+        LogConfig mockLogConfig = new LogConfig(logProps);\\n+        when(mockLog.config()).thenReturn(mockLogConfig);\\n+\\n+        List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n+        checkpoint.write(epochEntries);\\n+        LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n+        when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n+\\n+        when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n+        when(mockLog.logEndOffset()).thenReturn(200L);\\n+\\n+        RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024,\\n+                epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED)\\n+                .get(0);\\n+        // overlapping segment\\n+        RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()),\\n+                metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(),\\n+                metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128,\\n+                metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n+\\n+        // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n+        // returns the segments in order of (valid ++ unreferenced) segments:\\n+        // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n+        //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n+        //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n+        // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n+        List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n+        metadataList.add(metadata2);\\n+        metadataList.add(metadata1);\\n+\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition))\\n+                .thenReturn(metadataList.iterator());\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0))\\n+                .thenAnswer(ans -> metadataList.iterator());\\n+        when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class)))\\n+                .thenReturn(CompletableFuture.runAsync(() -> { }));\\n+\\n+        // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+\\n+        RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n+        task.convertToLeader(0);\\n+        task.cleanupExpiredRemoteLogSegments();\\n+\\n+        assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n+\\n+        // Verify the metric for remote delete is updated correctly\\n+        assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        // Verify we did not report any failure for remote deletes\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+    }\\n+\\n     @ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n     @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n     public void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize,\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: KAFKA-18401\\nIssue Summary: Transaction version 2 does not support commit transaction without records\\nIssue Type: Bug\\nPriority: Blocker\\n\\nDescription:\\nThis issue was observed when implementing https://issues.apache.org/jira/browse/KAFKA-18206.\\n\\n\\n\\nIn short, under transaction version 2, it doesn\\'t support commit transaction without sending any records while transaction version 0 & 1 do support this kind of scenario.\\n\\n\\n\\nCommit transactions without sending any records is fine when using transaction versions 0 or 1 because the producer won\\'t send EndTxnRequest to the broker [0]. However, with transaction version 2, the producer still sends an EndTxnRequest to the broker while in transaction coordinator, the txn state is still in EMPTY, resulting in an error from the broker.\\n\\n\\n\\nThis issue can be reproduced with the test in below. I\\'m unsure if this behavior is expected. If it\\'s not, one potential fix could be to follow the approach used in TV_0 and TV_1, where the EndTxnRequest is not sent if no partitions or offsets have been successfully added to the transaction. If this behavior is expected, we should document it and let user know this change.\\n\\n{code:java}\\n\\n    @ClusterTests({\\n\\n        @ClusterTest(brokers = 3, features = {\\n\\n            @ClusterFeature(feature = Feature.TRANSACTION_VERSION, version = 0)}),\\n\\n        @ClusterTest(brokers = 3, features = {\\n\\n            @ClusterFeature(feature = Feature.TRANSACTION_VERSION, version = 1)}),\\n\\n        @ClusterTest(brokers = 3, features = {\\n\\n            @ClusterFeature(feature = Feature.TRANSACTION_VERSION, version = 2)})\\n\\n    })\\n\\n    public void testProducerEndTransaction2(ClusterInstance cluster) throws InterruptedException {\\n\\n        Map<String, Object> properties = new HashMap<>();\\n\\n        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"foobar\");\\n\\n        properties.put(ProducerConfig.CLIENT_ID_CONFIG, \"test\");\\n\\n        properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\\n\\n        try (Producer<byte[], byte[]> producer1 = cluster.producer(properties)) {\\n\\n\\n\\n            producer1.initTransactions();\\n\\n            producer1.beginTransaction();\\n\\n            producer1.commitTransaction(); // In TV_2, we\\'ll get InvalidTxnStateException\\n\\n        }\\n\\n    }\\n\\n{code}\\n\\nAnother test case, which is essentially the same as the previous one, starts with a transaction that includes records, and then proceeds to start the next transaction. When using transaction version 2, we encounter an error, but this time it\\'s a different error from the one seen in the previous case.\\n\\n{code:java}\\n\\n    @ClusterTests({\\n\\n        @ClusterTest(brokers = 3, features = {\\n\\n            @ClusterFeature(feature = Feature.TRANSACTION_VERSION, version = 0)}),\\n\\n        @ClusterTest(brokers = 3, features = {\\n\\n            @ClusterFeature(feature = Feature.TRANSACTION_VERSION, version = 1)}),\\n\\n        @ClusterTest(brokers = 3, features = {\\n\\n            @ClusterFeature(feature = Feature.TRANSACTION_VERSION, version = 2)})\\n\\n    })\\n\\n    public void testProducerEndTransaction(ClusterInstance cluster) {\\n\\n        Map<String, Object> properties = new HashMap<>();\\n\\n        properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"foobar\");\\n\\n        properties.put(ProducerConfig.CLIENT_ID_CONFIG, \"test\");\\n\\n        properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);\\n\\n        try (Producer<byte[], byte[]> producer1 = cluster.producer(properties)) {\\n\\n\\n\\n            producer1.initTransactions();\\n\\n            producer1.beginTransaction();\\n\\n            producer1.send(new ProducerRecord<>(\"test\", \"key\".getBytes(), \"value\".getBytes()));\\n\\n            producer1.commitTransaction();\\n\\n\\n\\n            producer1.beginTransaction();\\n\\n            producer1.commitTransaction(); // In TV_2, we\\'ll get ProducerFencedException\\n\\n        }\\n\\n    }\\n\\n{code}\\n\\n\\xa0\\n\\n\\n\\n[0]: [https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L857-L865]\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'deepseek/deepseek-r1-distill-qwen-32b', 'max_tokens': 4096, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context is strictly relevant to the code changes. Otherwise, return NO.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: \\n>>>\\ndiff --git a/core/src/main/java/kafka/log/remote/RemoteLogManager.java b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\nindex c1c87d579e..3eacbea475 100644\\n--- a/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n+++ b/core/src/main/java/kafka/log/remote/RemoteLogManager.java\\n@@ -983,7 +983,9 @@ public class RemoteLogManager implements Closeable {\\n                     }\\n                 }\\n                 if (shouldDeleteSegment) {\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention size {} breach. Log size after deletion will be {}.\",\\n                             metadata.remoteLogSegmentId(), retentionSizeData.get().retentionSize, remainingBreachedSize + retentionSizeData.get().retentionSize);\\n                 }\\n@@ -1000,7 +1002,9 @@ public class RemoteLogManager implements Closeable {\\n                     remainingBreachedSize = Math.max(0, remainingBreachedSize - metadata.segmentSizeInBytes());\\n                     // It is fine to have logStartOffset as `metadata.endOffset() + 1` as the segment offset intervals\\n                     // are ascending with in an epoch.\\n-                    logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    if (!logStartOffset.isPresent() || logStartOffset.getAsLong() < metadata.endOffset() + 1) {\\n+                        logStartOffset = OptionalLong.of(metadata.endOffset() + 1);\\n+                    }\\n                     logger.info(\"About to delete remote log segment {} due to retention time {}ms breach based on the largest record timestamp in the segment\",\\n                             metadata.remoteLogSegmentId(), retentionTimeData.get().retentionMs);\\n                 }\\ndiff --git a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\nindex 4c4976f060..3c9b8a48e9 100644\\n--- a/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n+++ b/core/src/test/java/kafka/log/remote/RemoteLogManagerTest.java\\n@@ -2055,6 +2055,75 @@ public class RemoteLogManagerTest {\\n         assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n     }\\n \\n+    @ParameterizedTest(name = \"testDeletionOnOverlappingRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n+    @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n+    public void testDeletionOnOverlappingRetentionBreachedSegments(long retentionSize,\\n+                                                                   long retentionMs)\\n+            throws RemoteStorageException, ExecutionException, InterruptedException {\\n+        Map<String, Long> logProps = new HashMap<>();\\n+        logProps.put(\"retention.bytes\", retentionSize);\\n+        logProps.put(\"retention.ms\", retentionMs);\\n+        LogConfig mockLogConfig = new LogConfig(logProps);\\n+        when(mockLog.config()).thenReturn(mockLogConfig);\\n+\\n+        List<EpochEntry> epochEntries = Collections.singletonList(epochEntry0);\\n+        checkpoint.write(epochEntries);\\n+        LeaderEpochFileCache cache = new LeaderEpochFileCache(tp, checkpoint, scheduler);\\n+        when(mockLog.leaderEpochCache()).thenReturn(Option.apply(cache));\\n+\\n+        when(mockLog.topicPartition()).thenReturn(leaderTopicIdPartition.topicPartition());\\n+        when(mockLog.logEndOffset()).thenReturn(200L);\\n+\\n+        RemoteLogSegmentMetadata metadata1 = listRemoteLogSegmentMetadata(leaderTopicIdPartition, 1, 100, 1024,\\n+                epochEntries, RemoteLogSegmentState.COPY_SEGMENT_FINISHED)\\n+                .get(0);\\n+        // overlapping segment\\n+        RemoteLogSegmentMetadata metadata2 = new RemoteLogSegmentMetadata(new RemoteLogSegmentId(leaderTopicIdPartition, Uuid.randomUuid()),\\n+                metadata1.startOffset(), metadata1.endOffset() + 5, metadata1.maxTimestampMs(),\\n+                metadata1.brokerId() + 1, metadata1.eventTimestampMs(), metadata1.segmentSizeInBytes() + 128,\\n+                metadata1.customMetadata(), metadata1.state(), metadata1.segmentLeaderEpochs());\\n+\\n+        // When there are overlapping/duplicate segments, the RemoteLogMetadataManager#listRemoteLogSegments\\n+        // returns the segments in order of (valid ++ unreferenced) segments:\\n+        // (eg) B0 uploaded segment S0 with offsets 0-100 and B1 uploaded segment S1 with offsets 0-200.\\n+        //      We will mark the segment S0 as duplicate and add it to unreferencedSegmentIds.\\n+        //      The order of segments returned by listRemoteLogSegments will be S1, S0.\\n+        // While computing the next-log-start-offset, taking the max of deleted segment\\'s end-offset + 1.\\n+        List<RemoteLogSegmentMetadata> metadataList = new ArrayList<>();\\n+        metadataList.add(metadata2);\\n+        metadataList.add(metadata1);\\n+\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition))\\n+                .thenReturn(metadataList.iterator());\\n+        when(remoteLogMetadataManager.listRemoteLogSegments(leaderTopicIdPartition, 0))\\n+                .thenAnswer(ans -> metadataList.iterator());\\n+        when(remoteLogMetadataManager.updateRemoteLogSegmentMetadata(any(RemoteLogSegmentMetadataUpdate.class)))\\n+                .thenReturn(CompletableFuture.runAsync(() -> { }));\\n+\\n+        // Verify the metrics for remote deletes and for failures is zero before attempt to delete segments\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+\\n+        RemoteLogManager.RLMTask task = remoteLogManager.new RLMTask(leaderTopicIdPartition, 128);\\n+        task.convertToLeader(0);\\n+        task.cleanupExpiredRemoteLogSegments();\\n+\\n+        assertEquals(metadata2.endOffset() + 1, currentLogStartOffset.get());\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(0));\\n+        verify(remoteStorageManager).deleteLogSegmentData(metadataList.get(1));\\n+\\n+        // Verify the metric for remote delete is updated correctly\\n+        assertEquals(2, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).remoteDeleteRequestRate().count());\\n+        // Verify we did not report any failure for remote deletes\\n+        assertEquals(0, brokerTopicStats.topicStats(leaderTopicIdPartition.topic()).failedRemoteDeleteRequestRate().count());\\n+        // Verify aggregate metrics\\n+        assertEquals(2, brokerTopicStats.allTopicsStats().remoteDeleteRequestRate().count());\\n+        assertEquals(0, brokerTopicStats.allTopicsStats().failedRemoteDeleteRequestRate().count());\\n+    }\\n+\\n     @ParameterizedTest(name = \"testRemoteDeleteLagsOnRetentionBreachedSegments retentionSize={0} retentionMs={1}\")\\n     @CsvSource(value = {\"0, -1\", \"-1, 0\"})\\n     public void testRemoteDeleteLagsOnRetentionBreachedSegments(long retentionSize,\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: KAFKA-14020\\nIssue Summary: Performance regression in Producer\\nIssue Type: Bug\\nPriority: Blocker\\n\\nDescription:\\n[https://github.com/apache/kafka/commit/f7db6031b84a136ad0e257df722b20faa7c37b8a] introduced a 10% performance regression in the KafkaProducer under a default config.\\n\\n\\n\\n\\xa0\\n\\n\\n\\nThe context for this result is a benchmark that we run for Kafka Streams. The benchmark provisions 5 independent AWS clusters, including one broker node on an i3.large and one client node on an i3.large. During a benchmark run, we first run the Producer for 10 minutes to generate test data, and then we run Kafka Streams under a number of configurations to measure its performance.\\n\\n\\n\\nOur observation was a 10% regression in throughput under the simplest configuration, in which Streams simply consumes from a topic and does nothing else. That benchmark actually runs faster than the producer that generates the test data, so its thoughput is bounded by the data generator\\'s throughput. After investigation, we realized that the regression was in the data generator, not the consumer or Streams.\\n\\n\\n\\nWe have numerous benchmark runs leading up to the commit in question, and they all show a throughput in the neighborhood of 115,000 records per second. We also have 40 runs including and after that commit, and they all show a throughput in the neighborhood of 105,000 records per second. A test on [trunk with the commit reverted |https://github.com/apache/kafka/pull/12342]\\xa0shows a return to around 115,000 records per second.\\n\\n\\n\\nConfig:\\n\\n{code:java}\\n\\nfinal Properties properties = new Properties();\\n\\nproperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, broker);\\n\\nproperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\\n\\nproperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\\n\\n{code}\\n\\nHere\\'s the producer code in the data generator. Our tests were running with three produceThreads.\\n\\n{code:java}\\n\\n for (int t = 0; t < produceThreads; t++) {\\n\\n    futures.add(executorService.submit(() -> {\\n\\n        int threadTotal = 0;\\n\\n        long lastPrint = start;\\n\\n        final long printInterval = Duration.ofSeconds(10).toMillis();\\n\\n        long now;\\n\\n        try (final org.apache.kafka.clients.producer.Producer<String, String> producer = new KafkaProducer<>(producerConfig(broker))) {\\n\\n            while (limit > (now = System.currentTimeMillis()) - start) {\\n\\n                for (int i = 0; i < 1000; i++) {\\n\\n                    final String key = keys.next();\\n\\n                    final String data = dataGen.generate();\\n\\n\\n\\n                    producer.send(new ProducerRecord<>(topic, key, valueBuilder.apply(key, data)));\\n\\n\\n\\n                    threadTotal++;\\n\\n                }\\n\\n\\n\\n                if ((now - lastPrint) > printInterval) {\\n\\n                    System.out.println(Thread.currentThread().getName() + \" produced \" + numberFormat.format(threadTotal) + \" to \" + topic + \" in \" + Duration.ofMillis(now - start));\\n\\n                    lastPrint = now;\\n\\n                }\\n\\n            }\\n\\n        }\\n\\n        total.addAndGet(threadTotal);\\n\\n        System.out.println(Thread.currentThread().getName() + \" finished (\" + numberFormat.format(threadTotal) + \") in \" + Duration.ofMillis(now - start));\\n\\n    }));\\n\\n}{code}\\n\\nAs you can see, this is a very basic usage.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'deepseek/deepseek-r1-distill-qwen-32b', 'max_tokens': 4096, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB74AA060>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021AB6052840> server_hostname='openrouter.ai' timeout=5.0\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021A9B681B50>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021AB6052840> server_hostname='openrouter.ai' timeout=5.0\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB722B460>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000021AB6052840> server_hostname='openrouter.ai' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB74D2030>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB750AD50>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000021AB7510C50>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 25 Feb 2025 12:26:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Origin', b'*'), (b'x-clerk-auth-message', b'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)'), (b'x-clerk-auth-reason', b'token-invalid'), (b'x-clerk-auth-status', b'signed-out'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9177af9d0edff8fc-SIN'), (b'Content-Encoding', b'gzip')])\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 25 Feb 2025 12:26:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Origin', b'*'), (b'x-clerk-auth-message', b'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)'), (b'x-clerk-auth-reason', b'token-invalid'), (b'x-clerk-auth-status', b'signed-out'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9177af9d09af3fb0-SIN'), (b'Content-Encoding', b'gzip')])\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 25 Feb 2025 12:26:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Origin', b'*'), (b'x-clerk-auth-message', b'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)'), (b'x-clerk-auth-reason', b'token-invalid'), (b'x-clerk-auth-status', b'signed-out'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9177af9d1e6dfd8d-SIN'), (b'Content-Encoding', b'gzip')])\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 34\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 25 Feb 2025 12:26:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'x-clerk-auth-message': 'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)', 'x-clerk-auth-reason': 'token-invalid', 'x-clerk-auth-status': 'signed-out', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'cf-ray': '9177af9d1e6dfd8d-SIN', 'content-encoding': 'gzip'})\n",
      "DEBUG:openai._base_client:request_id: None\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 34\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 25 Feb 2025 12:26:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'x-clerk-auth-message': 'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)', 'x-clerk-auth-reason': 'token-invalid', 'x-clerk-auth-status': 'signed-out', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'cf-ray': '9177af9d0edff8fc-SIN', 'content-encoding': 'gzip'})\n",
      "DEBUG:openai._base_client:request_id: None\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 34\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Tue, 25 Feb 2025 12:26:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'x-clerk-auth-message': 'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)', 'x-clerk-auth-reason': 'token-invalid', 'x-clerk-auth-status': 'signed-out', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'cf-ray': '9177af9d09af3fb0-SIN', 'content-encoding': 'gzip'})\n",
      "DEBUG:openai._base_client:request_id: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 34\n"
     ]
    }
   ],
   "source": [
    "INCLUDED_HIGH_LEVEL_CONTEXT_CHAIN_INDEXES = [0, 1]\n",
    "INCLUDED_HIGH_LEVEL_CONTEXT_CHAIN_INDEXES = [0]\n",
    "\n",
    "for index in INCLUDED_HIGH_LEVEL_CONTEXT_CHAIN_INDEXES:\n",
    "    evaluator.get_high_level_contexts(\n",
    "        HIGH_LEVEL_CONTEXT_CHAINS[index],\n",
    "        COMMITS, \n",
    "        CONTEXT_DATA_PATH, \n",
    "        HIGH_LEVEL_CONTEXT_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Commit Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCLUDED_GENERATOR_INDEXES = [0, 1, 2]\n",
    "# INCLUDED_GENERATOR_INDEXES = [3]\n",
    "\n",
    "# filtered_generators = [GENERATORS[i] for i in INCLUDED_GENERATOR_INDEXES]\n",
    "# evaluator.evaluate(filtered_generators, COMMITS, CONTEXT_DATA_PATH, CMG_OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
