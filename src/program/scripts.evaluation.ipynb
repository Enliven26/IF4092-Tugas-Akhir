{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "load_dotenv(dotenv_path=\".env.evaluation\", verbose=True, override=True)\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from core.enums import EnvironmentKey\n",
    "from cmg.evaluators import CommitMessageGenerator\n",
    "from cmg import evaluator\n",
    "from core import (\n",
    "    open_ai_few_shot_high_level_context_cmg_chain,\n",
    "    open_ai_low_level_context_cmg_chain,\n",
    "    open_ai_zero_shot_high_level_context_cmg_chain,\n",
    "    open_ai_high_level_context_chain,\n",
    "    deepseek_zero_shot_high_level_context_cmg_chain,\n",
    "    deepseek_high_level_context_chain,\n",
    ")\n",
    "from core.models import CommitDataModel\n",
    "from datapreparation import context_generator, example_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMIT_DATA_JSON_FILE_PATH = os.path.join(\"data\", \"cmg\", \"commits.evaluation.json\")\n",
    "CONTEXT_DATA_PATH = os.path.join(\"data\", \"context\")\n",
    "\n",
    "DEFAULT_CONTEXT_GENERATION_OUTPUT_PATH = os.path.join(\n",
    "    \"data\", \"context\"\n",
    ")\n",
    "DEFAULT_HIGH_LEVEL_CONTEXT_OUTPUT_PATH = os.path.join(\n",
    "    \"out\", \"evaluation\", \"highlevelcontext\"\n",
    ")\n",
    "DEFAULT_CMG_OUTPUT_PATH = os.path.join(\"out\", \"evaluation\", \"cmg\")\n",
    "DEFAULT_DIFF_CLASSIFICATION_OUTPUT_PATH = os.path.join(\n",
    "    \"out\", \"evaluation\", \"diffclassification\"\n",
    ")\n",
    "\n",
    "DIFF_CLASSIFIER_CHAINS = [\n",
    "    open_ai_zero_shot_high_level_context_cmg_chain,\n",
    "    open_ai_low_level_context_cmg_chain,\n",
    "    deepseek_zero_shot_high_level_context_cmg_chain\n",
    "]\n",
    "\n",
    "HIGH_LEVEL_CONTEXT_CHAINS = [\n",
    "    open_ai_high_level_context_chain,\n",
    "    deepseek_high_level_context_chain,\n",
    "]\n",
    "\n",
    "GENERATORS = [\n",
    "    CommitMessageGenerator(\n",
    "        \"Open AI Zero-Shot High-Level Context Generator\", open_ai_zero_shot_high_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"Open AI Few-Shot High-Level Context Generator\", open_ai_few_shot_high_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\"Open AI Low-Level Context Generator\", open_ai_low_level_context_cmg_chain),\n",
    "    CommitMessageGenerator(\n",
    "        \"DeepSeek Zero-Shot High-Level Context Generator\", deepseek_zero_shot_high_level_context_cmg_chain\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_GENERATION_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.CONTEXT_GENERATION_OUTPUT_PATH.value,\n",
    "        DEFAULT_CONTEXT_GENERATION_OUTPUT_PATH,\n",
    "    )\n",
    "\n",
    "HIGH_LEVEL_CONTEXT_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.HIGH_LEVEL_CONTEXT_OUTPUT_PATH.value,\n",
    "        DEFAULT_HIGH_LEVEL_CONTEXT_OUTPUT_PATH,\n",
    "    )\n",
    "\n",
    "CMG_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.CMG_OUTPUT_PATH.value, DEFAULT_CMG_OUTPUT_PATH\n",
    "    )\n",
    "\n",
    "DIFF_CLASSIFICATION_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.DIFF_CLASSIFICATION_OUTPUT_PATH.value,\n",
    "        DEFAULT_DIFF_CLASSIFICATION_OUTPUT_PATH,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(path: str) -> list[CommitDataModel]:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            json_string = file.read()\n",
    "\n",
    "        return CommitDataModel.from_json(json_string)\n",
    "\n",
    "COMMITS = get_commits(COMMIT_DATA_JSON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/clients/src/main/java/org/apache/kafka/common/security/JaasUtils.java b/clients/src/main/java/org/apache/kafka/common/security/JaasUtils.java\\nindex 742319c4f4..800283e56e 100644\\n--- a/clients/src/main/java/org/apache/kafka/common/security/JaasUtils.java\\n+++ b/clients/src/main/java/org/apache/kafka/common/security/JaasUtils.java\\n@@ -16,67 +16,12 @@\\n  */\\n package org.apache.kafka.common.security;\\n \\n-import org.apache.kafka.common.KafkaException;\\n-\\n-import org.slf4j.Logger;\\n-import org.slf4j.LoggerFactory;\\n-\\n-import javax.security.auth.login.Configuration;\\n-\\n public final class JaasUtils {\\n-    private static final Logger LOG = LoggerFactory.getLogger(JaasUtils.class);\\n     public static final String JAVA_LOGIN_CONFIG_PARAM = \"java.security.auth.login.config\";\\n     public static final String DISALLOWED_LOGIN_MODULES_CONFIG = \"org.apache.kafka.disallowed.login.modules\";\\n     public static final String DISALLOWED_LOGIN_MODULES_DEFAULT = \"com.sun.security.auth.module.JndiLoginModule\";\\n     public static final String SERVICE_NAME = \"serviceName\";\\n \\n-    public static final String ZK_SASL_CLIENT = \"zookeeper.sasl.client\";\\n-    public static final String ZK_LOGIN_CONTEXT_NAME_KEY = \"zookeeper.sasl.clientconfig\";\\n-\\n-    private static final String DEFAULT_ZK_LOGIN_CONTEXT_NAME = \"Client\";\\n-    private static final String DEFAULT_ZK_SASL_CLIENT = \"true\";\\n-\\n     private JaasUtils() {}\\n \\n-    public static String zkSecuritySysConfigString() {\\n-        String loginConfig = System.getProperty(JAVA_LOGIN_CONFIG_PARAM);\\n-        String clientEnabled = System.getProperty(ZK_SASL_CLIENT, \"default:\" + DEFAULT_ZK_SASL_CLIENT);\\n-        String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, \"default:\" + DEFAULT_ZK_LOGIN_CONTEXT_NAME);\\n-        return \"[\" +\\n-                JAVA_LOGIN_CONFIG_PARAM + \"=\" + loginConfig +\\n-                \", \" +\\n-                ZK_SASL_CLIENT + \"=\" + clientEnabled +\\n-                \", \" +\\n-                ZK_LOGIN_CONTEXT_NAME_KEY + \"=\" + contextName +\\n-                \"]\";\\n-    }\\n-\\n-    public static boolean isZkSaslEnabled() {\\n-        // Technically a client must also check if TLS mutual authentication has been configured,\\n-        // but we will leave that up to the client code to determine since direct connectivity to ZooKeeper\\n-        // has been deprecated in many clients and we don\\'t wish to re-introduce a ZooKeeper jar dependency here.\\n-        boolean zkSaslEnabled = Boolean.parseBoolean(System.getProperty(ZK_SASL_CLIENT, DEFAULT_ZK_SASL_CLIENT));\\n-        String zkLoginContextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, DEFAULT_ZK_LOGIN_CONTEXT_NAME);\\n-\\n-        LOG.debug(\"Checking login config for Zookeeper JAAS context {}\", zkSecuritySysConfigString());\\n-\\n-        boolean foundLoginConfigEntry;\\n-        try {\\n-            Configuration loginConf = Configuration.getConfiguration();\\n-            foundLoginConfigEntry = loginConf.getAppConfigurationEntry(zkLoginContextName) != null;\\n-        } catch (Exception e) {\\n-            throw new KafkaException(\"Exception while loading Zookeeper JAAS login context \" +\\n-                    zkSecuritySysConfigString(), e);\\n-        }\\n-\\n-        if (foundLoginConfigEntry && !zkSaslEnabled) {\\n-            LOG.error(\"JAAS configuration is present, but system property \" +\\n-                        ZK_SASL_CLIENT + \" is set to false, which disables \" +\\n-                        \"SASL in the ZooKeeper client\");\\n-            throw new KafkaException(\"Exception while determining if ZooKeeper is secure \" +\\n-                    zkSecuritySysConfigString());\\n-        }\\n-\\n-        return foundLoginConfigEntry;\\n-    }\\n }\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000198FBAA1BF0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x00000198FA7B90A0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000198FBAA1D00>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 17 Jan 2025 11:02:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'346'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'198851'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'344ms'), (b'x-request-id', b'req_f8b67d42c578c870c61992636040936e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=P2jtAL_FEaDK3CRUidgx.vSHCrcxjnLVrlKGdjLHuBI-1737111748-1.0.1.1-sp4aCATUJc1WsGiUPnE9prjKHD2wXmXUQFb8fF7xwNP0KkmY4C16RriMBPp9kSB6INvau0jRo1B5VECK6gavHQ; path=/; expires=Fri, 17-Jan-25 11:32:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4Gy5.pTuCADlaRt_.ZxnsdwQs26dOAtytdrDX62mrRI-1737111748554-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9035da689e93fd35-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Fri, 17 Jan 2025 11:02:28 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '346'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '198851'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '344ms'), ('x-request-id', 'req_f8b67d42c578c870c61992636040936e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=P2jtAL_FEaDK3CRUidgx.vSHCrcxjnLVrlKGdjLHuBI-1737111748-1.0.1.1-sp4aCATUJc1WsGiUPnE9prjKHD2wXmXUQFb8fF7xwNP0KkmY4C16RriMBPp9kSB6INvau0jRo1B5VECK6gavHQ; path=/; expires=Fri, 17-Jan-25 11:32:28 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=4Gy5.pTuCADlaRt_.ZxnsdwQs26dOAtytdrDX62mrRI-1737111748554-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9035da689e93fd35-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_f8b67d42c578c870c61992636040936e\n"
     ]
    }
   ],
   "source": [
    "INCLUDED_DIFF_CLASSIFIER_CHAIN_INDEXES = [0, 1, 2]\n",
    "\n",
    "for index in INCLUDED_DIFF_CLASSIFIER_CHAIN_INDEXES:\n",
    "    evaluator.classify_diffs(DIFF_CLASSIFIER_CHAINS[index], COMMITS, CONTEXT_DATA_PATH, DIFF_CLASSIFICATION_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): issues.apache.org:443\n",
      "DEBUG:urllib3.connectionpool:https://issues.apache.org:443 \"GET /jira/rest/api/2/serverInfo HTTP/11\" 200 229\n",
      "DEBUG:urllib3.connectionpool:https://issues.apache.org:443 \"GET /jira/rest/api/2/issue/DRILL-8400 HTTP/11\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): issues.apache.org:443\n",
      "DEBUG:urllib3.connectionpool:https://issues.apache.org:443 \"GET /jira/rest/api/2/serverInfo HTTP/11\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://issues.apache.org:443 \"GET /jira/rest/api/2/issue/ZOOKEEPER-3160 HTTP/11\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): issues.apache.org:443\n",
      "DEBUG:urllib3.connectionpool:https://issues.apache.org:443 \"GET /jira/rest/api/2/serverInfo HTTP/11\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://issues.apache.org:443 \"GET /jira/rest/api/2/issue/OPENNLP-1620 HTTP/11\" 200 None\n"
     ]
    }
   ],
   "source": [
    "context_generator.generate_context(COMMITS, CONTEXT_GENERATION_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get High Level Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\nSource code:\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (Before)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case LOGICAL:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (After)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case PARTITION_PRUNING:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (Before)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Ignore;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\n@Ignore(\"DRILL-8400\")\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (After)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\nSource code:\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (Before)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.ByteArrayInputStream;\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Arrays;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLParameters;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (After)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.lang.reflect.InvocationTargetException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslContextSupplierClassProperty() {\\n    return sslContextSupplierClassProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\n@SuppressWarnings(\"unchecked\")\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n    if (supplierContextClassName != null) {\\n        if (LOG.isDebugEnabled()) {\\n            LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n        }\\n        try {\\n            Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n            Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n            return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n        } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException | InstantiationException | IllegalAccessException e) {\\n            throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName + \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n        }\\n    } else {\\n        return createSSLContextAndOptionsFromConfig(config);\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (Before)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (After)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslContextSupplierClassProperty(), System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (Before)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (After)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.NoSuchAlgorithmException;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\n@Test(expected = X509Exception.SSLContextException.class)\\npublic void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n    clientX509Util.createSSLContext(zkConfig);\\n}\\n@Test\\npublic void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n    final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n    Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\npublic static class SslContextSupplier implements Supplier<SSLContext> {\\n\\n    @Override\\n    public SSLContext get() {\\n        try {\\n            return SSLContext.getDefault();\\n        } catch (NoSuchAlgorithmException e) {\\n            throw new RuntimeException(e);\\n        }\\n    }\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\nSource code:\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (Before)\\npublic class ThreadSafePOSTaggerME implements POSTagger {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (After)\\npublic class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (Before)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        sentenceDetectorThreadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (After)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = threadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        threadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (Before)\\npublic class ThreadSafeTokenizerME implements Tokenizer {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        tokenizerThreadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (After)\\npublic class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = threadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        threadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF9D0590>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF6F9370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF908910>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF908A50>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF6F9370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF6F9370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF98CD60>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF98CFC0>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF919EB0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /info HTTP/11\" 200 672\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'956'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'197432'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'770ms'), (b'x-request-id', b'req_3bcff83c936e491ae34aafac0ee6a2d5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=2LuocR8oYXVkIeYkKMaVcjzvD4Z8Eu0PSDzpH9oT.7s-1737874603-1.0.1.1-s_RkMh8SA5urU2OX63P_nipy_xtrfKcWlJ0DvH.I44wm9MKKR5wUoxoBqBx_GZ8AEwU8qMWocLcz0e3kv09XLg; path=/; expires=Sun, 26-Jan-25 07:26:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=HBZ7mxQSOc6Rv4LcfJZ919jQdsQ0HjgkrRtiwsnCaW0-1737874603256-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9ac37ef09cd4-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '956'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '197432'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '770ms'), ('x-request-id', 'req_3bcff83c936e491ae34aafac0ee6a2d5'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=2LuocR8oYXVkIeYkKMaVcjzvD4Z8Eu0PSDzpH9oT.7s-1737874603-1.0.1.1-s_RkMh8SA5urU2OX63P_nipy_xtrfKcWlJ0DvH.I44wm9MKKR5wUoxoBqBx_GZ8AEwU8qMWocLcz0e3kv09XLg; path=/; expires=Sun, 26-Jan-25 07:26:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=HBZ7mxQSOc6Rv4LcfJZ919jQdsQ0HjgkrRtiwsnCaW0-1737874603256-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9ac37ef09cd4-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_3bcff83c936e491ae34aafac0ee6a2d5\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'868'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'187277'), (b'x-ratelimit-reset-requests', b'25.823s'), (b'x-ratelimit-reset-tokens', b'3.816s'), (b'x-request-id', b'req_40ab2997ebb5effc73a08cdcf8022792'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mCF8V5sgRq0d8f0Vs3KjoATMnX9uIQcfU.CQbWSw23M-1737874603-1.0.1.1-Jjpcp16flefe.4C1DSsED5tXTUe3q1_dsC8nXvtHlWcNOQs0dbNb2e9iMa2JHyonR0eCz0vpk3.lBSurdX9NuA; path=/; expires=Sun, 26-Jan-25 07:26:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=rjBn3ZNQYU924PR2ufLD5eSxiADE3TF5HXidmi49ve0-1737874603295-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9ac37ec9604b-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '868'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '187277'), ('x-ratelimit-reset-requests', '25.823s'), ('x-ratelimit-reset-tokens', '3.816s'), ('x-request-id', 'req_40ab2997ebb5effc73a08cdcf8022792'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=mCF8V5sgRq0d8f0Vs3KjoATMnX9uIQcfU.CQbWSw23M-1737874603-1.0.1.1-Jjpcp16flefe.4C1DSsED5tXTUe3q1_dsC8nXvtHlWcNOQs0dbNb2e9iMa2JHyonR0eCz0vpk3.lBSurdX9NuA; path=/; expires=Sun, 26-Jan-25 07:26:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=rjBn3ZNQYU924PR2ufLD5eSxiADE3TF5HXidmi49ve0-1737874603295-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9ac37ec9604b-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_40ab2997ebb5effc73a08cdcf8022792\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1034'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'194648'), (b'x-ratelimit-reset-requests', b'17.245s'), (b'x-ratelimit-reset-tokens', b'1.605s'), (b'x-request-id', b'req_375163bba6a8e8eab2a455e4c40435d8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5mzhfYNUsiScog9fhRetQOpzVd59EI_FTY0z6hW8wss-1737874603-1.0.1.1-YvPRllm30yGQGR1GS06HT3_weeqQI3bzB.2ly8tp9CXXdtss.i3E8_Qq_J3nynsjTIU1drI7lnm_247XML2agA; path=/; expires=Sun, 26-Jan-25 07:26:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=NVyEjnCV04YrKRK.avlSThP6XSNswgVDPT13Et.A6ts-1737874603376-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9ac3693e9d17-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:43 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1034'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '194648'), ('x-ratelimit-reset-requests', '17.245s'), ('x-ratelimit-reset-tokens', '1.605s'), ('x-request-id', 'req_375163bba6a8e8eab2a455e4c40435d8'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=5mzhfYNUsiScog9fhRetQOpzVd59EI_FTY0z6hW8wss-1737874603-1.0.1.1-YvPRllm30yGQGR1GS06HT3_weeqQI3bzB.2ly8tp9CXXdtss.i3E8_Qq_J3nynsjTIU1drI7lnm_247XML2agA; path=/; expires=Sun, 26-Jan-25 07:26:43 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=NVyEjnCV04YrKRK.avlSThP6XSNswgVDPT13Et.A6ts-1737874603376-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9ac3693e9d17-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_375163bba6a8e8eab2a455e4c40435d8\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x0000014FFFBB4540>, 'json_data': {'input': [[35158, 3110, 25, 30941, 45, 12852, 12, 8258, 17, 198, 43106, 22241, 25, 3320, 266, 7676, 3103, 1288, 1920, 3626, 304, 1437, 266, 10803, 18299, 6315, 6449, 38210, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 30893, 271, 5116, 512, 2409, 279, 3293, 5369, 315, 5991, 6971, 266, 678, 18031, 3103, 4246, 2323, 3500, 4669, 30941, 45, 12852, 12, 11739, 20, 11, 433, 6244, 8196, 320, 55569, 1296, 1629, 705, 430, 279, 2082, 304, 3320, 266, 7676, 3103, 374, 38097, 311, 2536, 1773, 16890, 2191, 13, 1115, 44814, 505, 279, 2144, 430, 5991, 10248, 2013, 8744, 2, 1638, 11043, 57522, 53831, 1587, 539, 15803, 904, 2015, 315, 279, 6052, 5540, 13, 23535, 32, 4754, 5155, 369, 32145, 6449, 2191, 1578, 374, 311, 3460, 279, 1121, 315, 1160, 11043, 57522, 8, 28890, 2740, 304, 20382, 2015, 382, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 30941, 45, 12852, 12, 11247, 22, 198, 43106, 22241, 25, 2758, 4617, 56219, 2373, 315, 46613, 261, 7614, 198, 43106, 4078, 25, 1561, 20595, 198, 21197, 25, 17559, 271, 5116, 512, 34814, 11, 46613, 261, 7614, 374, 539, 4617, 56219, 13, 3161, 30941, 45, 12852, 12, 25612, 11, 264, 4617, 56219, 2373, 369, 3892, 5552, 6989, 574, 11784, 2055, 11458, 11, 420, 574, 539, 2884, 369, 279, 46613, 261, 1162, 382, 10267, 596, 19678, 323, 3493, 8926, 26747, 29404, 261, 7614, 9772, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 30941, 45, 12852, 12, 11247, 16, 198, 43106, 22241, 25, 20295, 2587, 4211, 1694, 49266, 505, 5377, 45, 12852, 1217, 23399, 6352, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 17559, 271, 5116, 512, 34814, 11, 264, 99675, 1977, 320, 3052, 27093, 77, 4335, 1296, 3500, 8, 84638, 6484, 4211, 304, 279, 43642, 882, 23399, 12196, 2569, 77, 13855, 3500, 6, 6352, 11, 439, 279, 2082, 304, 5991, 16328, 11631, 2810, 2323, 2, 56335, 4599, 20171, 3500, 690, 4335, 1884, 709, 1603, 279, 5552, 5528, 304, 5991, 11631, 2810, 3500, 690, 387, 12793, 2055, 11458, 11, 420, 11384, 1063, 47846, 11, 422, 2587, 70024, 4211, 449, 4528, 836, 12912, 3073, 304, 430, 6352, 11, 439, 14557, 1704, 3527, 54167, 1747, 11043, 5026, 12, 31666, 51442, 5146, 19327, 1704, 3527, 54167, 1747, 11043, 5026, 12, 52989, 51442, 5146, 19327, 1704, 3527, 54167, 1747, 11043, 5026, 12, 981, 51442, 5146, 19327, 1704, 3527, 54167, 1747, 11043, 5026, 12, 3516, 7044, 51442, 5146, 62, 1038, 14724, 387, 16070, 13, 23674, 11, 420, 1101, 11384, 264, 2763, 315, 32115, 369, 3567, 1274, 11, 439, 1855, 1629, 315, 279, 4459, 1296, 16578, 690, 4335, 709, 3060, 304, 279, 2218, 6352, 315, 5991, 2569, 77, 13855, 45746, 3500, 4793, 11, 477, 1524, 11201, 11, 279, 2254, 43642, 882, 23399, 12196, 2569, 77, 13855, 3500, 6, 6352, 11, 14718, 520, 3325, 220, 4386, 320, 843, 65052, 865, 220, 19, 1646, 4595, 8, 4211, 311, 387, 24174, 320, 2017, 323, 927, 1578, 31134, 32, 5861, 1473, 9, 30379, 912, 320, 9342, 8, 1646, 374, 33484, 7108, 505, 43642, 882, 23399, 12196, 2569, 77, 13855, 3500, 30736, 9, 30379, 4211, 31572, 7784, 956, 11763, 422, 814, 3073, 24392, 612, 527, 330, 1930, 1, 5570, 15605, 8358, 62, 696, 9, 24163, 50999, 24174, 4211, 3651, 6484, 6305, 311, 7142, 11102, 1646, 3626, 271, 9, 53253, 4232, 8286, 2631, 369, 2539, 320, 964, 8, 22890, 271, 9, 53253, 2865, 369, 47368, 14054, 271, 9, 53253, 8244, 50953, 43972, 1038, 9290, 25, 26823, 17208, 369, 364, 5979, 6, 99675, 5643, 13, 1666, 1317, 439, 912, 330, 27093, 77, 4335, 1, 374, 16070, 11, 6484, 4211, 8774, 304, 264, 1977, 596, 5991, 5775, 3500, 8695, 1288, 539, 387, 49266, 323, 539, 387, 312, 15220, 15961, 824, 1296, 16578, 11572, 382, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 30941, 45, 12852, 12, 10680, 20, 198, 43106, 22241, 25, 2758, 55817, 304, 80642, 32706, 7614, 323, 9857, 3213, 7614, 311, 15921, 2587, 72578, 11240, 198, 43106, 4078, 25, 53751, 198, 21197, 25, 17559, 271, 5116, 512, 7283, 315, 33895, 4194, 3052, 38534, 7614, 3500, 323, 5255, 5991, 85664, 32706, 7614, 3500, 1253, 1390, 311, 2865, 459, 5217, 477, 2587, 5991, 8685, 3500, 369, 40615, 17583, 1511, 304, 264, 3738, 4221, 477, 8106, 2055, 11458, 11, 420, 374, 539, 3284, 1314, 1457, 11, 520, 8246, 892, 315, 1884, 6989, 2055, 10267, 596, 5155, 420, 555, 7999, 459, 5217, 4797, 8405, 810, 25152, 382, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 30941, 45, 12852, 12, 6330, 15, 198, 43106, 22241, 25, 37083, 311, 11404, 27592, 25514, 198, 43106, 4078, 25, 1561, 20595, 198, 21197, 25, 17559, 271, 5116, 512, 12834, 2373, 220, 17, 13, 19, 13, 15, 11, 279, 5377, 45, 12852, 5764, 264, 23911, 27592, 4877, 25514, 902, 3060, 14370, 79651, 311, 13813, 27592, 9681, 477, 17192, 46391, 2055, 7184, 11, 420, 374, 264, 3575, 422, 499, 1390, 311, 5542, 264, 2587, 1646, 389, 1063, 25142, 1023, 27592, 4877, 751, 13, 23535, 2181, 1053, 387, 2294, 422, 1070, 574, 264, 574, 311, 11404, 279, 27592, 25514, 13, 23535, 644, 2144, 11, 358, 1053, 30714, 430, 27592, 13021, 374, 6656, 1022, 555, 1670, 7389, 264, 27592, 25514, 374, 20684, 17665, 311, 279, 27592, 4877, 1414, 482, 779, 6392, 1053, 7293, 29512, 18641, 2055, 4071, 520, 3325, 1694, 3025, 311, 2543, 315, 279, 25514, 323, 5255, 311, 3493, 264, 2587, 25514, 1053, 387, 26893, 13], [35158, 3110, 25, 30941, 45, 12852, 12, 10674, 15, 198, 43106, 22241, 25, 1102, 1288, 387, 3284, 311, 4148, 279, 20816, 8926, 7469, 198, 43106, 4078, 25, 53751, 198, 21197, 25, 17559, 271, 5116, 512, 2181, 1288, 387, 3284, 311, 4148, 279, 20816, 4617, 25958, 11, 422, 4460, 555, 279, 1217, 439, 433, 374, 17791, 311, 279, 19569, 315, 279, 4617, 1701, 433, 2055, 33895, 4194, 1038, 0, 1843, 12, 2366, 19, 12, 605, 12, 2318, 12, 806, 12, 2131, 12, 868, 12, 19319, 3592, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x0000014FFFBC47C0>, 'json_data': {'input': [[35158, 3110, 25, 14644, 9410, 12, 24866, 18, 198, 43106, 22241, 25, 10291, 6668, 16877, 449, 4384, 14043, 2007, 55719, 399, 82, 220, 15, 1121, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 17559, 271, 5116, 512, 9023, 484, 4780, 912, 3135, 389, 279, 1314, 6668, 16877, 422, 279, 22477, 18139, 8, 2007, 374, 4384, 2055, 791, 45648, 1648, 311, 23645, 279, 4360, 14557, 16, 3354, 5457, 77974, 539, 311, 1005, 11117, 5249, 323, 1005, 279, 5286, 5249, 5793, 4619, 1473, 90, 1889, 25, 10248, 633, 38377, 3882, 743, 50811, 29797, 21558, 6115, 284, 905, 401, 38377, 3882, 743, 50811, 29797, 67379, 10719, 6115, 28, 905, 26, 314, 1889, 633, 17, 13, 29127, 5249, 2015, 26329, 311, 5471, 77974, 505, 65761, 5249, 12920, 1473, 90, 1889, 25, 10248, 633, 38377, 3882, 743, 50811, 29797, 32117, 15382, 67064, 284, 905, 26, 220, 314, 1889, 633, 18, 13, 21517, 264, 3319, 449, 4384, 2163, 2007, 15632, 1473, 90, 1889, 25, 10248, 633, 4963, 20386, 31193, 33895, 4194, 271, 33895, 4194, 46433, 4194, 320, 4963, 353, 4393, 320, 47189, 320, 16, 11, 364, 6102, 518, 220, 1591, 705, 33895, 4194, 271, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 7, 17, 11, 364, 63602, 518, 220, 843, 18966, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 7, 18, 11, 364, 46864, 1677, 518, 220, 1682, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 8, 5871, 3932, 3809, 11, 836, 11, 4325, 696, 33895, 4194, 46433, 4194, 5401, 905, 271, 33895, 4194, 46433, 4194, 883, 5871, 3932, 271, 11833, 13369, 33895, 4194, 271, 33895, 4194, 46433, 4194, 320, 47189, 320, 16, 11, 364, 4674, 261, 4670, 33895, 4194, 271, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 320, 17, 11, 364, 43824, 4670, 33895, 4194, 271, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 320, 18, 11, 364, 46165, 4713, 33895, 4194, 46433, 4194, 883, 5871, 2683, 3809, 11, 2316, 696, 715, 3932, 1801, 284, 2683, 1801, 33895, 4194, 90, 1889, 633, 19430, 1121, 374, 1473, 8651, 307, 8651, 609, 8651, 425, 8651, 307, 15, 8651, 2150, 8651, 271, 23470, 23470, 23470, 91, 16, 91, 4674, 261, 44838, 23470, 23470, 23470, 91, 17, 91, 43824, 44838, 23470, 23470, 23470, 91, 18, 91, 46165, 91, 1038, 4071, 584, 636, 220, 15, 7123, 13], [35158, 3110, 25, 14644, 9410, 12, 24951, 24, 198, 43106, 22241, 25, 55710, 5044, 24237, 994, 36696, 16559, 4788, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 17559, 271, 5116, 512, 4599, 16559, 2571, 4204, 11, 422, 16559, 3835, 8243, 17650, 2568, 291, 11, 4272, 1919, 649, 4984, 3835, 11, 719, 31646, 5625, 3835, 311, 4470, 11130, 61348, 2097, 11, 779, 4272, 1919, 649, 539, 4984, 3835, 13, 420, 46433, 4194, 936, 4881, 4750, 5044, 37796, 1038, 7959, 3630, 33895, 4194, 271, 90, 1889, 25, 10248, 633, 2366, 19, 12, 2371, 12, 845, 220, 845, 25, 914, 25, 3226, 11, 19416, 510, 1061, 3032, 12, 22, 60, 13170, 297, 5973, 962, 16153, 56277, 2056, 4080, 62110, 482, 4204, 304, 35108, 10758, 13, 46433, 4194, 4627, 25, 611, 605, 13, 843, 13, 7261, 13, 10350, 25, 21848, 1187, 366, 30152, 611, 605, 13, 843, 13, 7261, 13, 10350, 25, 12226, 717, 320, 695, 3016, 570, 46433, 4194, 37394, 3717, 382, 822, 39796, 32271, 60416, 27696, 4414, 1378, 25, 1262, 5206, 38038, 484, 16153, 14161, 13, 32831, 10869, 1378, 25, 42544, 311, 22864, 4240, 315, 1404, 220, 12378, 21, 4245, 311, 5044, 4017, 320, 20275, 17609, 9639, 23717, 21144, 18216, 22, 570, 9303, 24691, 25, 220, 15, 271, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 32271, 60416, 8639, 1271, 2097, 20516, 3921, 30459, 1271, 2097, 20516, 11085, 25, 7699, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 16592, 38440, 9826, 76326, 28209, 8144, 15, 78319, 9826, 76326, 11085, 25, 25339, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 16592, 38440, 9826, 76326, 28209, 8144, 3112, 47974, 78319, 9826, 76326, 11085, 25, 21251, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 16592, 38440, 9826, 76326, 3, 8144, 6396, 7789, 78319, 9826, 76326, 11085, 25, 8874, 22, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 2013, 18456, 38440, 1585, 26321, 7789, 6396, 78319, 1585, 26321, 11085, 25, 11908, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 2013, 18456, 38440, 1585, 26321, 53983, 17617, 78319, 1585, 26321, 11085, 25, 11247, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 2013, 18456, 23993, 6998, 1585, 26321, 7789, 2460, 26527, 3844, 2222, 6998, 1585, 26321, 11085, 25, 17711, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 16592, 28565, 2112, 822, 1585, 14962, 7789, 8368, 822, 1585, 14962, 11085, 25, 23642, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 2013, 18456, 23993, 6998, 1585, 26321, 3, 19, 7789, 3844, 2222, 6998, 1585, 26321, 11085, 25, 22694, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 2013, 18765, 33132, 26321, 2276, 3, 17, 7789, 55153, 26321, 2276, 11085, 25, 5728, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 1674, 8178, 33132, 7789, 55153, 11085, 25, 20338, 696, 23389, 2656, 555, 25, 1262, 5206, 38038, 484, 16153, 14161, 13, 32831, 10869, 1378, 25, 42544, 311, 22864, 4240, 315, 1404, 220, 12378, 21, 4245, 311, 5044, 4017, 320, 20275, 17609, 9639, 23717, 21144, 18216, 22, 570, 9303, 24691, 25, 220, 15, 271, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 1262, 5206, 38038, 484, 16153, 37711, 13316, 43830, 25472, 23017, 43830, 11085, 25, 13078, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 1262, 5206, 38038, 484, 16153, 37711, 13316, 43830, 25472, 23017, 43830, 11085, 25, 8610, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 1262, 5206, 38038, 484, 16153, 37711, 920, 81, 484, 7300, 15414, 43830, 25472, 5549, 81, 484, 7300, 15414, 43830, 11085, 25, 2131, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 1262, 5206, 38038, 484, 16153, 37711, 920, 81, 484, 7300, 15414, 43830, 25472, 5549, 81, 484, 7300, 15414, 43830, 11085, 25, 1135, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 1262, 5206, 38038, 484, 16153, 56277, 2056, 4080, 20516, 17762, 1161, 5763, 16464, 11085, 25, 4044, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 1262, 5206, 38038, 484, 16153, 56277, 2056, 4080, 20516, 17762, 2855, 4080, 20516, 11085, 25, 1987, 696, 33895, 4194, 46433, 4194, 46433, 4194, 46433, 4194, 520, 6533, 39796, 32271, 60416, 8639, 1271, 2097, 20516, 3921, 30459, 1271, 2097, 20516, 11085, 25, 1954, 6226, 1889, 633, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 14644, 9410, 12, 16217, 18, 198, 43106, 22241, 25, 2758, 12499, 7104, 311, 26869, 16492, 19490, 369, 52298, 3200, 198, 43106, 4078, 25, 53751, 198, 21197, 25, 17559, 271, 5116, 512, 2028, 8743, 11621, 459, 3072, 311, 10936, 3552, 10741, 369, 26384, 13537, 311, 52298, 3200, 13, 33895, 4194, 271, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 14644, 9410, 12, 22741, 20, 198, 43106, 22241, 25, 27628, 31646, 11777, 311, 51936, 264, 44494, 3552, 2686, 311, 41960, 19393, 198, 43106, 4078, 25, 1561, 20595, 198, 21197, 25, 30893, 271, 5116, 512, 3947, 527, 3738, 15082, 11, 1778, 439, 4401, 77974, 304, 4332, 41649, 24794, 11, 304, 902, 433, 374, 35946, 311, 51936, 264, 2204, 29215, 311, 41960, 19393, 1109, 1053, 387, 2612, 555, 2006, 54962, 67041, 9480, 1020, 220, 358, 30714, 7999, 264, 6683, 3977, 364, 3696, 484, 16153, 56277, 31199, 11901, 1653, 4147, 18320, 6, 323, 12579, 420, 2686, 311, 41960, 19393, 994, 279, 6683, 3977, 374, 35459, 11, 6062, 16054, 1203, 311, 279, 3118, 7865, 13], [35158, 3110, 25, 14644, 9410, 12, 24250, 16, 198, 43106, 22241, 25, 2758, 1862, 369, 18797, 24069, 6880, 198, 43106, 4078, 25, 1561, 20595, 198, 21197, 25, 17559, 271, 5116, 512, 34814, 11, 77974, 49378, 13711, 369, 18797, 24069, 6880, 323, 4780, 15465, 3135, 382, 8586, 374, 279, 3187, 3319, 369, 902, 77974, 690, 471, 15465, 3135, 1473, 90, 1889, 25, 3628, 633, 4963, 1797, 1471, 1292, 8, 36452, 14358, 4678, 308, 21276, 798, 284, 220, 16, 8, 5871, 17089, 3259, 1265, 62, 16, 21276, 3638, 1868, 1471, 1292, 8, 36452, 14358, 4678, 308, 21276, 798, 284, 220, 17, 8, 5871, 17089, 3259, 1265, 62, 17, 21276, 3638, 1868, 1471, 1292, 8, 36452, 14358, 4678, 308, 21276, 798, 284, 220, 18, 8, 5871, 17089, 3259, 1265, 62, 18, 21276, 3638, 1868, 1471, 1292, 8, 36452, 14358, 4678, 308, 21276, 798, 284, 220, 19, 8, 5871, 17089, 3259, 1265, 62, 19, 21276, 3638, 1868, 1471, 1292, 8, 36452, 14358, 4678, 308, 21276, 798, 284, 220, 15, 8, 5871, 17089, 3259, 1265, 62, 15, 21276, 271, 31193, 12773, 15254, 796, 331, 9809, 367, 34377, 24181, 19884, 90, 1889, 633, 90, 2201, 2293, 633, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 42125, 91, 17089, 3259, 1265, 62, 16, 21276, 765, 17089, 3259, 1265, 62, 17, 21276, 765, 17089, 3259, 1265, 62, 18, 21276, 765, 17089, 3259, 1265, 62, 19, 21276, 765, 17089, 3259, 1265, 62, 15, 21276, 36821, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 42125, 91, 220, 914, 667, 765, 220, 914, 667, 765, 220, 914, 667, 765, 220, 914, 667, 765, 220, 914, 667, 36821, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 42125, 90, 2201, 2293, 633, 4071, 279, 4495, 1121, 374, 271, 90, 2201, 2293, 633, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 42125, 91, 17089, 3259, 1265, 62, 16, 21276, 765, 17089, 3259, 1265, 62, 17, 21276, 765, 17089, 3259, 1265, 62, 18, 21276, 765, 17089, 3259, 1265, 62, 19, 21276, 765, 17089, 3259, 1265, 62, 15, 21276, 36821, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 42125, 91, 220, 20, 5218, 765, 220, 20, 5218, 765, 220, 20, 5218, 765, 220, 20, 5218, 765, 220, 20, 5218, 36821, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 10, 776, 18580, 42125, 90, 2201, 2293, 633, 16789, 5296, 1473, 791, 3319, 3485, 1436, 387, 59624, 1701, 393, 3166, 1831, 1473, 90, 1889, 25, 3628, 633, 4963, 1595, 16, 63, 17089, 3259, 1265, 62, 16, 21276, 11, 1595, 17, 63, 17089, 3259, 1265, 62, 17, 21276, 11, 1595, 18, 63, 17089, 3259, 1265, 62, 18, 21276, 11, 1595, 19, 63, 17089, 3259, 1265, 62, 19, 21276, 11, 1595, 15, 63, 17089, 3259, 1265, 62, 15, 21276, 271, 31193, 320, 4963, 308, 1292, 11, 308, 21276, 798, 4393, 12773, 15254, 796, 331, 9809, 367, 34377, 24181, 33981, 4815, 1932, 53, 1831, 11773, 1471, 1292, 8, 4716, 308, 21276, 798, 2006, 320, 15, 11, 220, 16, 11, 220, 17, 11, 220, 18, 11, 220, 19, 4489, 90, 1889, 633, 3112, 690, 471, 4495, 3135, 994, 420, 4360, 374, 8521, 323, 35315, 635, 374, 6177, 311, 220, 16, 13, 1644, 13, 15, 271, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 14644, 9410, 12, 19899, 15, 198, 43106, 22241, 25, 20295, 86292, 47788, 449, 15753, 1380, 3486, 81127, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 17559, 271, 5116, 512, 10031, 5991, 2323, 39, 535, 51078, 3617, 38302, 10583, 2957, 5920, 6055, 29815, 1966, 3246, 3486, 52025, 25858, 368, 3500, 1296, 369, 3649, 2055, 791, 4360, 13980, 369, 20126, 1093, 1521, 1473, 90, 1889, 25, 3628, 633, 4963, 353, 4393, 66607, 80109, 5407, 38302, 4552, 259, 16, 4815, 76586, 66607, 80109, 6753, 766, 365, 646, 32226, 259, 17, 6328, 259, 16, 15254, 67, 63, 284, 259, 17, 15254, 67, 63, 3651, 259, 16, 15254, 68, 63, 284, 259, 17, 15254, 68, 63, 4815, 27611, 259, 17, 15254, 68, 63, 3507, 4276, 1808, 3651, 259, 16, 15254, 67, 63, 284, 220, 16, 271, 90, 1889, 13549, 791, 3685, 7865, 374, 311, 1893, 5217, 13711, 3196, 389, 279, 6484, 13711, 323, 5249, 4787, 13, 1226, 617, 264, 5991, 44203, 45450, 932, 38658, 4622, 3500, 9293, 10474, 11, 902, 374, 8647, 369, 1778, 3319, 54070, 11, 719, 77974, 41802, 1523, 13711, 505, 279, 5401, 3044, 1603, 430, 10474, 11, 779, 279, 26329, 374, 539, 10887, 2055, 75344, 750, 11, 584, 1288, 3351, 5718, 505, 279, 5991, 44203, 45450, 932, 38658, 4622, 3500, 10474, 311, 279, 5991, 7391, 15942, 3500, 10474, 779, 430, 279, 50811, 690, 5268, 279, 1455, 23669, 3197, 11, 719, 433, 8434, 956, 1520, 3156, 89349, 6119, 12, 6849, 23, 374, 8521, 320, 275, 374, 2631, 311, 6958, 81127, 994, 2380, 706, 5991, 6882, 71684, 3500, 7954, 570]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x0000014FFFBC4680>, 'json_data': {'input': [[35158, 3110, 25, 1901, 20066, 52901, 643, 12, 21848, 15, 198, 43106, 22241, 25, 42754, 3489, 34106, 29215, 23751, 18808, 304, 1063, 26350, 198, 43106, 4078, 25, 53751, 198, 21197, 25, 30893, 271, 5116, 512, 34814, 11, 28462, 3489, 34106, 42754, 690, 1304, 279, 3622, 9788, 60800, 82, 3016, 35537, 315, 21583, 934, 34106, 26081, 2403, 872, 10134, 28698, 2686, 13, 33895, 4194, 1038, 33895, 4194, 1687, 617, 3970, 420, 5353, 4819, 994, 4401, 304, 67474, 11, 4245, 311, 6125, 14564, 53583, 311, 5361, 45177, 5144, 11, 994, 41960, 78333, 55687, 16136, 304, 5361, 3600, 13, 23535, 12834, 1595, 644, 54962, 100183, 4383, 55358, 4780, 264, 935, 11, 433, 13524, 9221, 264, 1847, 315, 6140, 902, 45177, 836, 374, 10273, 2403, 279, 2847, 13, 4815, 2028, 6118, 63130, 5196, 20784, 1306, 264, 2478, 4520, 11, 994, 279, 29215, 430, 5334, 6052, 555, 279, 10134, 19128, 27716, 4442, 323, 682, 315, 264, 11210, 9248, 279, 16125, 1131, 719, 420, 374, 2753, 1109, 10728, 2055, 2028, 706, 1101, 9057, 4819, 304, 279, 4610, 318, 8510, 5793, 439, 1664, 320, 4151, 510, 576, 4360, 91, 2485, 1129, 5316, 916, 14, 496, 318, 8510, 14, 496, 318, 8510, 12934, 22645, 95787, 39845, 14, 15500, 24, 2526, 482, 814, 29056, 420, 555, 5128, 1790, 7999, 4205, 814, 649, 1505, 430, 2643, 387, 9959, 311, 279, 60800, 11, 323, 264, 2478, 8545, 26076, 389, 1948, 315, 430, 2055, 2028, 374, 2225, 11, 1493, 38097, 323, 3250, 956, 2216, 923, 904, 9959, 5066, 3392, 315, 4868, 11, 2533, 330, 2028, 16125, 9248, 279, 21583, 14734, 1, 13434, 956, 9651, 3152, 330, 576, 14734, 1288, 387, 5535, 311, 4667, 11690, 33895, 4194, 271, 33895, 4194, 3947, 527, 1403, 320, 55540, 810, 8, 5627, 311, 5155, 420, 14557, 2, 32662, 721, 543, 62, 220, 10134, 10925, 323, 1817, 2403, 682, 315, 1124, 271, 2, 578, 1901, 42, 3622, 1436, 10356, 279, 60800, 2403, 279, 1160, 315, 16692, 320, 3052, 6390, 68796, 2112, 90, 76642, 33895, 4194, 258, 279, 2242, 570, 362, 14734, 1288, 387, 3025, 311, 4667, 389, 279, 934, 34106, 2700, 422, 323, 1193, 422, 520, 3325, 832, 60800, 9248, 520, 3325, 832, 315, 279, 10212, 16692, 2055, 40, 4265, 18046, 430, 279, 2132, 3072, 374, 279, 2731, 832, 11, 5423, 2533, 279, 1674, 6464, 3250, 956, 1524, 2873, 311, 617, 279, 3072, 315, 49324, 682, 45177, 10925, 11, 719, 1101, 1606, 433, 2731, 9248, 279, 13605, 7537, 315, 279, 1901, 42, 4074, 2055, 50674, 11, 433, 1053, 387, 6555, 311, 617, 264, 330, 18502, 3016, 29215, 23751, 1, 3072, 430, 2103, 11141, 3622, 29215, 23751, 9147, 13, 53981, 398, 12365, 420, 374, 264, 8821, 4360, 3582, 11, 358, 4265, 387, 6380, 311, 12903, 430, 704, 1139, 264, 11989, 315, 1202, 1866, 13, 9772, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 1901, 20066, 52901, 643, 12, 19799, 18, 198, 43106, 22241, 25, 32430, 11850, 315, 56396, 5288, 5364, 35, 20, 6296, 480, 1242, 7227, 304, 934, 34106, 4259, 198, 43106, 4078, 25, 53751, 198, 21197, 25, 17559, 271, 5116, 512, 791, 51826, 43, 6108, 934, 34106, 3229, 3213, 1587, 539, 21650, 33137, 1990, 279, 56396, 5288, 5364, 35, 20, 323, 480, 1242, 7227, 24717, 25, 433, 374, 5042, 39661, 389, 5991, 678, 7646, 3500, 323, 5991, 4981, 7646, 3500, 369, 17066, 449, 279, 4846, 323, 38936, 36258, 93895, 82139, 304, 5991, 38583, 7646, 3500, 369, 279, 15629, 2055, 2181, 10800, 704, 430, 1063, 51826, 43, 15302, 1953, 5288, 5364, 35, 20, 33483, 5353, 17066, 323, 24645, 29460, 539, 311, 2489, 279, 3685, 3645, 11, 323, 279, 56396, 5288, 5364, 35, 20, 6108, 19885, 315, 279, 934, 34106, 1296, 16578, 311, 3775, 449, 40634, 6103, 13, 320, 7009, 649, 387, 51400, 311, 28950, 311, 5249, 279, 934, 34106, 11, 719, 1193, 555, 3411, 1139, 11944, 18929, 76794, 1687, 649, 1005, 279, 5982, 4793, 836, 311, 8417, 3508, 56396, 5288, 5364, 35, 20, 477, 480, 1242, 7227, 374, 1511, 11, 323, 12234, 279, 17066, 3110, 1817, 369, 279, 4846, 13, 220, 1666, 264, 21993, 11, 584, 649, 2567, 279, 3636, 6108, 41307, 2472, 4384, 994, 36258, 93895, 82139, 527, 3685, 13, 220, 17830, 11, 584, 649, 10737, 7177, 311, 6106, 330, 906, 2668, 398, 35831, 1, 16792, 1193, 5353, 17066, 28950, 304, 279, 480, 1242, 7227, 1162, 13], [35158, 3110, 25, 1901, 20066, 52901, 643, 12, 19773, 23, 198, 43106, 22241, 25, 11016, 279, 5409, 52240, 1990, 16694, 1303, 323, 279, 13105, 5784, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 17559, 271, 5116, 512, 13319, 279, 22183, 16570, 505, 41960, 19393, 41261, 15359, 368, 323, 220, 41960, 19393, 5592, 43527, 3915, 15359, 368, 5446, 11, 439, 433, 11384, 5409, 52240, 389, 279, 41960, 19393, 5592, 1665, 449, 279, 13105, 5784, 13, 23535, 644, 41960, 19393, 5592, 11085, 11, 584, 617, 279, 2768, 271, 90, 1889, 25, 10248, 13549, 586, 22183, 2958, 1935, 15359, 20074, 13105, 62971, 11, 2777, 374, 1542, 19846, 11, 2777, 5043, 27014, 3915, 2782, 1220, 8, 3872, 9530, 1504, 20838, 633, 90, 1889, 13549, 644, 35141, 57, 95271, 5592, 11085, 323, 435, 30134, 57, 95271, 5592, 11085, 11, 584, 617, 279, 2768, 271, 66768, 90, 1889, 25, 10248, 633, 898, 22183, 742, 13105, 368, 1504, 257, 5585, 262, 17398, 90, 1889, 633, 5244, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 1901, 20066, 52901, 643, 12, 18318, 22, 198, 43106, 22241, 25, 82727, 1378, 2581, 706, 57950, 994, 3428, 2373, 3016, 7540, 279, 1579, 2373, 3622, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 30893, 271, 5116, 512, 90, 1889, 25, 10248, 633, 65, 1706, 479, 4686, 389, 3622, 48522, 14, 6804, 13, 15, 13, 15, 13, 16, 25, 13302, 15, 11, 3882, 307, 284, 220, 15, 87, 1041, 21360, 23, 329, 4749, 11531, 24, 11, 51578, 9829, 284, 220, 3101, 410, 65, 1706, 479, 4686, 389, 3622, 48522, 14, 6804, 13, 15, 13, 15, 13, 16, 25, 13302, 15, 11, 3882, 307, 284, 220, 15, 87, 1041, 21360, 23, 329, 4749, 11531, 24, 11, 51578, 9829, 284, 220, 3101, 410, 10248, 8178, 24933, 40718, 520, 1262, 5206, 4025, 95271, 11606, 44131, 1378, 2581, 17155, 44131, 1378, 11085, 25, 6281, 8, 520, 1262, 5206, 4025, 95271, 11606, 44131, 1378, 2581, 17155, 44131, 1378, 11085, 25, 4370, 8, 520, 1262, 5206, 4025, 95271, 13784, 2689, 78333, 2581, 28955, 2689, 78333, 11085, 25, 9800, 23, 8, 520, 2816, 2441, 4942, 65, 7221, 4025, 95271, 13784, 42, 3032, 7175, 28955, 42, 3032, 11085, 25, 9263, 8, 520, 2816, 2441, 4942, 65, 23353, 11803, 7175, 33284, 11803, 11085, 25, 14206, 8, 520, 2816, 2441, 4942, 65, 18786, 33785, 13067, 6919, 1096, 16928, 14099, 78720, 6919, 1096, 11085, 25, 22488, 8, 520, 2816, 2441, 4942, 65, 11978, 6998, 7789, 47951, 6998, 11085, 25, 8878, 8, 520, 1674, 8178, 33132, 7789, 55153, 11085, 25, 20338, 8, 10248, 8178, 24933, 40718, 10248, 8178, 24933, 40718, 271, 520, 1262, 5206, 4025, 95271, 11606, 44131, 1378, 2581, 17155, 44131, 1378, 11085, 25, 6281, 8, 520, 1262, 5206, 4025, 95271, 11606, 44131, 1378, 2581, 17155, 44131, 1378, 11085, 25, 4370, 8, 520, 1262, 5206, 4025, 95271, 11606, 44131, 1378, 2581, 17155, 44131, 1378, 11085, 25, 6281, 8, 520, 1262, 5206, 4025, 95271, 13784, 2689, 78333, 2581, 28955, 2689, 78333, 11085, 25, 9800, 23, 696, 90, 1889, 92], [35158, 3110, 25, 1901, 20066, 52901, 643, 12, 18572, 16, 198, 43106, 22241, 25, 3489, 34106, 34, 24244, 2087, 49099, 2700, 10950, 23515, 1587, 539, 23515, 28698, 19128, 198, 43106, 4078, 25, 31601, 198, 21197, 25, 30893, 271, 5116, 512, 1687, 1629, 41960, 19393, 304, 264, 5593, 4676, 1405, 28698, 374, 539, 15528, 13, 1666, 11349, 555, 279, 9904, 11, 584, 743, 721, 62572, 7229, 10154, 52660, 62, 311, 220, 15, 320, 441, 7270, 23515, 287, 16058, 31134, 1966, 1063, 13422, 11, 584, 636, 279, 2768, 4788, 304, 459, 24746, 6471, 11, 1524, 3582, 279, 2686, 2736, 6244, 9006, 12, 481, 14557, 33895, 4194, 271, 90, 2201, 2293, 633, 41796, 12, 17, 62, 16, 220, 765, 220, 2366, 15, 12, 806, 12, 2839, 220, 605, 25, 3226, 25, 2318, 11, 18501, 510, 2465, 307, 25, 18, 60, 482, 13170, 510, 2811, 3126, 9319, 74, 12, 17, 6085, 25, 19081, 23, 25, 2232, 34106, 34, 24244, 2087, 3, 2811, 3, 2811, 3126, 31, 7743, 18, 60, 482, 4204, 1418, 14624, 271, 41796, 12, 17, 62, 16, 220, 765, 1674, 5181, 53189, 1378, 25, 1252, 40847, 2686, 271, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1674, 9105, 48300, 5181, 23858, 10498, 6218, 98956, 8922, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1674, 9105, 48300, 5181, 23858, 10498, 6218, 98956, 8922, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1262, 5206, 4025, 95271, 12926, 17731, 34106, 35007, 34106, 34, 24244, 2087, 3, 2811, 3, 2811, 3126, 85240, 5592, 10498, 7, 2232, 34106, 34, 24244, 2087, 11085, 25, 8011, 15, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1262, 5206, 4025, 95271, 12926, 17731, 34106, 35007, 34106, 34, 24244, 2087, 3, 2811, 3, 2811, 3126, 29662, 55851, 7, 2232, 34106, 34, 24244, 2087, 11085, 25, 7461, 19, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1262, 5206, 4025, 95271, 12926, 17731, 34106, 35007, 34106, 34, 24244, 2087, 3, 2811, 3, 2811, 3126, 7789, 7, 2232, 34106, 34, 24244, 2087, 11085, 25, 6889, 18, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1674, 9105, 48300, 2013, 18456, 31898, 9663, 3, 69936, 6065, 8692, 98956, 8922, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1674, 9105, 48300, 2013, 18456, 77456, 6396, 7789, 98956, 8922, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1674, 9105, 48300, 2013, 18456, 33132, 10774, 26321, 7789, 22701, 98956, 8922, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1674, 9105, 48300, 2013, 18456, 33132, 10774, 26321, 3, 22701, 7789, 98956, 8922, 696, 41796, 12, 17, 62, 16, 220, 765, 220, 36547, 1674, 9105, 48300, 8178, 33132, 7789, 98956, 8922, 6226, 2201, 2293, 633, 57, 95271, 1587, 539, 3604, 23515, 279, 28698, 11175, 11, 433, 1120, 13912, 1701, 279, 2362, 4745, 1121, 2055, 33895, 4194, 1038, 2028, 8741, 1606, 279, 763, 81607, 374, 3549, 3131, 323, 279, 28698, 19128, 8741, 994, 433, 374, 3549, 2055, 2028, 4360, 706, 2586, 709, 8767, 304, 3788, 1129, 18934, 5206, 2726, 4537, 9008, 91381, 73060, 20066, 52901, 643, 12, 3965, 21, 719, 433, 8111, 311, 2103, 3621, 1618, 2055, 40, 617, 12673, 264, 53823, 29148, 21637, 311, 1520, 23645, 420, 4360, 13, 40961, 1473, 353, 15448, 277, 53823, 29148, 21637, 271, 353, 27686, 66170, 709, 271, 353, 3580, 279, 4788, 13912, 12765, 369, 95628, 12, 17, 11, 539, 369, 279, 3885, 271, 353, 5377, 3000, 6085, 323, 63173, 279, 95628, 12, 17, 1584, 11, 16650, 279, 6275, 323, 3665, 271, 353, 14144, 264, 2478, 6622, 369, 279, 28698, 311, 10625, 271, 353, 26504, 430, 499, 649, 9006, 95628, 12, 17, 6085, 1457, 320, 45961, 571, 10861, 13, 845, 13, 1399, 13, 17, 95628, 12, 17, 6085, 8, 719, 279, 1493, 13912, 26449, 1038, 40, 617, 1101, 12673, 264, 11140, 430, 64397, 420, 13, 578, 11140, 690, 23515, 28698, 11175, 422, 279, 2686, 374, 2103, 81261, 1475, 892, 433, 16696, 311, 1893, 279, 3622, 7728, 2055, 33895, 4194, 271, 4521, 19003, 4403, 36, 22449, 58113, 328, 52697, 11424, 1198, 10669, 35158, 3110, 25, 1901, 20066, 52901, 643, 12, 15340, 15, 198, 43106, 22241, 25, 8572, 2724, 26384, 2014, 198, 43106, 4078, 25, 1561, 20595, 198, 21197, 25, 30893, 271, 5116, 512, 791, 41960, 19393, 20797, 5131, 2187, 499, 311, 743, 709, 701, 26384, 9805, 4669, 1887, 6012, 1778, 439, 330, 89, 95271, 58304, 4840, 6221, 8383, 1, 304, 279, 1630, 12448, 2810, 13, 1115, 14861, 1455, 4382, 1005, 5157, 11, 1405, 3932, 617, 3241, 100232, 4692, 389, 872, 2653, 33067, 2055, 3947, 527, 11, 4869, 11, 264, 2478, 5217, 26350, 430, 420, 3250, 956, 3504, 13, 9220, 3284, 6305, 1053, 387, 1473, 674, 578, 1217, 706, 264, 12035, 2004, 64473, 11, 6799, 304, 1701, 25864, 6546, 806, 477, 2555, 4528, 382, 674, 578, 1217, 706, 912, 2680, 311, 279, 3241, 2004, 64473, 11, 719, 649, 17622, 459, 2736, 12, 82678, 26384, 2014, 505, 872, 5593, 2055, 2520, 420, 11, 358, 1053, 30714, 430, 279, 1630, 12448, 2810, 387, 11838, 311, 2187, 264, 1217, 311, 743, 264, 3424, 1778, 439, 330, 89, 95271, 58304, 6718, 8852, 1, 311, 3493, 264, 538, 902, 17135, 264, 2587, 26384, 2317, 13, 1115, 6835, 264, 2763, 810, 25152, 311, 279, 1901, 42, 3016, 11, 323, 6276, 279, 1217, 311, 9429, 279, 26384, 2014, 304, 8996, 1648, 814, 4587, 320, 8370, 1101, 3938, 78259, 279, 8292, 14738, 31134, 40, 3077, 2736, 8308, 420, 4668, 11, 323, 690, 2231, 304, 264, 8743, 5246, 369, 433, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFFBC2140>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFFBC2250>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF8F1C70> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF8F20F0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF850250>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF850B50>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF929130>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF8F2060> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'125'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-85d8c45b57-96xqc'), (b'x-envoy-upstream-service-time', b'86'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'997817'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'130ms'), (b'x-request-id', b'req_fadd940004d6e812d57135c9a57ff578'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=w3TROZWVqUNYuCQThmsRhO1OZ_PxH63x4dFbhOrsy.w-1737874606-1.0.1.1-5sCUwJmhQbHSMqtb5b8ZhgCzdcWtFSq9H21wBTQRHsilZbj_dpUDyQbN5Rb6jN.djSGNXSzbsIz.urab8fnH_A; path=/; expires=Sun, 26-Jan-25 07:26:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=qgksXCIODvbdkdKKwvvcVkqeTPe_jgLIBT5PMMGuPRc-1737874606007-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9adb8ebaab5b-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'128'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7d6bf4769b-zc7lx'), (b'x-envoy-upstream-service-time', b'88'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999006'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'59ms'), (b'x-request-id', b'req_84edd81183daa6110f5940061c2d6663'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=EXoKMR4XvnW8PFGd5dfceeY0wszWNb0RYrK.YKLp8pc-1737874606-1.0.1.1-ZUsphbXbrj9NPB4GYZ8.s1P14r_v0DORk01BelL9SndyM84O9FrmesTAiwlG1V2LC1XSYnhgjTU0L8L_cvASig; path=/; expires=Sun, 26-Jan-25 07:26:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7YB3HP8cvY8CqWBMno04jF.oXOyBU5QSCAsmvF0_cNI-1737874606041-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9adb9e2b7976-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF929400>\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:46 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '125'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-85d8c45b57-96xqc'), ('x-envoy-upstream-service-time', '86'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '997817'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '130ms'), ('x-request-id', 'req_fadd940004d6e812d57135c9a57ff578'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=w3TROZWVqUNYuCQThmsRhO1OZ_PxH63x4dFbhOrsy.w-1737874606-1.0.1.1-5sCUwJmhQbHSMqtb5b8ZhgCzdcWtFSq9H21wBTQRHsilZbj_dpUDyQbN5Rb6jN.djSGNXSzbsIz.urab8fnH_A; path=/; expires=Sun, 26-Jan-25 07:26:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=qgksXCIODvbdkdKKwvvcVkqeTPe_jgLIBT5PMMGuPRc-1737874606007-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9adb8ebaab5b-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_fadd940004d6e812d57135c9a57ff578\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:46 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '128'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7d6bf4769b-zc7lx'), ('x-envoy-upstream-service-time', '88'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999006'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '59ms'), ('x-request-id', 'req_84edd81183daa6110f5940061c2d6663'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=EXoKMR4XvnW8PFGd5dfceeY0wszWNb0RYrK.YKLp8pc-1737874606-1.0.1.1-ZUsphbXbrj9NPB4GYZ8.s1P14r_v0DORk01BelL9SndyM84O9FrmesTAiwlG1V2LC1XSYnhgjTU0L8L_cvASig; path=/; expires=Sun, 26-Jan-25 07:26:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7YB3HP8cvY8CqWBMno04jF.oXOyBU5QSCAsmvF0_cNI-1737874606041-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9adb9e2b7976-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_84edd81183daa6110f5940061c2d6663\n",
      "DEBUG:faiss.loader:Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU\n",
      "INFO:faiss.loader:Loading faiss with AVX512 support.\n",
      "INFO:faiss.loader:Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'159'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5974ff86bc-m4nz9'), (b'x-envoy-upstream-service-time', b'79'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'997876'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'127ms'), (b'x-request-id', b'req_c937aa92a21c42227063e432561d2209'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=RjbD80qfdcVQYl3jn4JC_Q_xQWfYTjY3xiLznPs36Js-1737874606-1.0.1.1-QyGG_ABob0cyE_n6x3yjiKvtd6MtNPAl6O2wGuQ11kSFlt_BMyqG3mUq7qbPSpSLltF_QHavBSp0.9VhMbHDCA; path=/; expires=Sun, 26-Jan-25 07:26:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=q8rripM.mqUERpCMF.NY3xbrlXKcuqaDCc6Y_lieGXU-1737874606687-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9adfee84fd1e-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:46 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '159'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5974ff86bc-m4nz9'), ('x-envoy-upstream-service-time', '79'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '997876'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '127ms'), ('x-request-id', 'req_c937aa92a21c42227063e432561d2209'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=RjbD80qfdcVQYl3jn4JC_Q_xQWfYTjY3xiLznPs36Js-1737874606-1.0.1.1-QyGG_ABob0cyE_n6x3yjiKvtd6MtNPAl6O2wGuQ11kSFlt_BMyqG3mUq7qbPSpSLltF_QHavBSp0.9VhMbHDCA; path=/; expires=Sun, 26-Jan-25 07:26:46 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=q8rripM.mqUERpCMF.NY3xbrlXKcuqaDCc6Y_lieGXU-1737874606687-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9adfee84fd1e-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c937aa92a21c42227063e432561d2209\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x0000014FFF984C20>, 'json_data': {'input': [[791, 2082, 4442, 18885, 2380, 6956, 315, 264, 4221, 8863, 5507, 555, 23391, 814, 649, 387, 21676, 1511, 304, 7447, 61904, 291, 22484, 1418, 1101, 10923, 369, 6300, 5044, 6373, 13, 9062, 3777, 1457, 5764, 279, 5845, 311, 3345, 323, 2867, 1202, 20816, 5070, 994, 912, 5129, 4460, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x0000014F8AAE9F80>, 'json_data': {'input': [[791, 2082, 4442, 2713, 279, 1648, 279, 1887, 36611, 323, 13777, 828, 47788, 11, 11951, 555, 93990, 264, 10474, 505, 330, 7391, 15942, 1, 311, 330, 34590, 7237, 10794, 1899, 1753, 1210, 23212, 11, 264, 8767, 12305, 1296, 369, 86292, 47788, 3196, 389, 3738, 4787, 374, 1457, 4642, 11, 23391, 433, 8640, 439, 961, 315, 279, 7649, 1920, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x0000014F8AAEBCE0>, 'json_data': {'input': [[791, 2082, 4442, 19678, 264, 502, 3424, 311, 14158, 264, 2587, 26384, 2317, 19353, 11, 10923, 369, 810, 19303, 26384, 6683, 13, 23212, 11, 7177, 1051, 3779, 311, 6106, 430, 279, 1887, 12722, 13777, 2764, 323, 8482, 2587, 26384, 2317, 6989, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'46'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-85d8c45b57-qwmwh'), (b'x-envoy-upstream-service-time', b'30'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999940'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_b801d700d91b1853eab6f6a14eb728bb'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9aedaa98ab5b-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Sun, 26 Jan 2025 06:56:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '46', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-85d8c45b57-qwmwh', 'x-envoy-upstream-service-time': '30', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999940', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '3ms', 'x-request-id': 'req_b801d700d91b1853eab6f6a14eb728bb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '907e9aedaa98ab5b-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_b801d700d91b1853eab6f6a14eb728bb\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8381\\nIssue Summary: Add support for filtered aggregate calls\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, Drill ignores filters for filtered aggregate calls and returns incorrect results.\\n\\nHere is the example query for which Drill will return incorrect results:\\n\\n{code:sql}\\n\\nSELECT count(n_name) FILTER(WHERE n_regionkey = 1) AS nations_count_in_1_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 2) AS nations_count_in_2_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 3) AS nations_count_in_3_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 4) AS nations_count_in_4_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 0) AS nations_count_in_0_region\\n\\nFROM cp.`tpch/nation.parquet`\\n\\n{code}\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 25                        | 25                        | 25                        | 25                        | 25                        |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nBut the correct result is\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 5                         | 5                         | 5                         | 5                         | 5                         |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nSide note:\\n\\nThe query above could be rewritten using PIVOT:\\n\\n{code:sql}\\n\\nSELECT `1` nations_count_in_1_region, `2` nations_count_in_2_region, `3` nations_count_in_3_region, `4` nations_count_in_4_region, `0` nations_count_in_0_region\\n\\nFROM (SELECT n_name, n_regionkey FROM cp.`tpch/nation.parquet`) \\n\\nPIVOT(count(n_name) FOR n_regionkey IN (0, 1, 2, 3, 4))\\n\\n{code}\\n\\nAnd will return correct results when this issue is fixed and Calcite is updated to 1.33.0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8400\\nIssue Summary: Fix pruning partitions with pushed transitive predicates\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nSee {{TestHivePartitionPruning.prunePartitionsBasedOnTransitivePredicates()}} test for details.\\n\\n\\n\\nThe issue occurs for queries like these:\\n\\n{code:sql}\\n\\nSELECT * FROM hive.partition_pruning_test t1 \\n\\nJOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \\n\\nWHERE t2.`e` IS NOT NULL AND t1.`d` = 1\\n\\n{code}\\n\\n\\n\\nThe expected behavior is to create additional filters based on the existing filters and join conditions. We have a {{TRANSITIVE_CLOSURE}} planning phase, which is responsible for such query transformations, but Drill pushes down filters from the WHERE condition before that phase, so the optimization is not performed.\\n\\n\\n\\nIdeally, we should move rules from the {{TRANSITIVE_CLOSURE}} phase to the {{LOGICAL}} phase so that the planner will choose the most optimal plan, but it wouldn\\'t help until CALCITE-1048 is fixed (it is required to pull predicates when three has {{RelSubset}} nodes).\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8489\\nIssue Summary: Sender memory leak when rpc encode exception\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nWhen encode throw Exception, if encode msg instanceof ReferenceCounted, netty can release msg, but drill convert msg to OutboundRpcMessage, so netty can not release msg. this Â\\xa0causes sender memory leaks\\n\\n\\n\\nexception infoÂ\\xa0\\n\\n{code:java}\\n\\n2024-04-16 16:25:57,998 [DataClient-7] ERROR o.a.d.exec.rpc.RpcExceptionHandler - Exception in RPC communication. Â\\xa0Connection: /10.32.112.138:47924 <--> /10.32.112.138:31012 (data client). Â\\xa0Closing connection.\\n\\nio.netty.handler.codec.EncoderException: org.apache.drill.exec.exception.OutOfMemoryException: Unable to allocate buffer of size 4096 due to memory limit (9223372036854775807). Current allocation: 0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:107)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:881)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:940)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1247)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at java.lang.Thread.run(Thread.java:748)\\n\\nCaused by: org.apache.drill.exec.exception.OutOfMemoryException: Unable to allocate buffer of size 4096 due to memory limit (9223372036854775807). Current allocation: 0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.BaseAllocator.buffer(BaseAllocator.java:245)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.BaseAllocator.buffer(BaseAllocator.java:220)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.DrillByteBufAllocator.buffer(DrillByteBufAllocator.java:55)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.DrillByteBufAllocator.buffer(DrillByteBufAllocator.java:50)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.rpc.RpcEncoder.encode(safeRelease.java:87)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.rpc.RpcEncoder.encode(RpcEncoder.java:38)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:90){code}\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8503\\nIssue Summary: Add Configuration Option to Skip Host Validation for Splunk\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nThis PR adds an option to skip host validation for SSL connections to Splunk.Â\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-4935\\nIssue Summary: Allow drillbits to advertise a configurable host address to Zookeeper\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThere are certain situations, such as running Drill in distributed Docker containers, in which it is desirable to advertise a different hostname to Zookeeper than would be output by INetAddress.getLocalHost().  I propose adding a configuration variable \\'drill.exec.rpc.bit.advertised.host\\' and passing this address to Zookeeper when the configuration variable is populated, otherwise falling back to the present behavior.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8513\\nIssue Summary: Right Hash Join with empty Left table ruturns 0 result\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nDrill returns no results on the right Hash Join if the probe(left) table is empty.\\n\\n\\n\\nThe simplest way to reproduce the issue:\\n\\n\\n\\n1.To force Drill not to use merge join and use the hash join operator instead:\\n\\n{code:java}\\n\\nalter session set planner.enable_mergejoin = false;\\n\\nalter session set planner.enable_nestedloopjoin= false; {code}\\n\\n2. Disable join order optimization to prevent Drill from flipping join tables:\\n\\n{code:java}\\n\\nalter session set planner.enable_join_optimization = false;  {code}\\n\\n3. Execute a query with empty left table outcome:\\n\\n{code:java}\\n\\nSELECT *\\n\\nFROMÂ\\xa0\\n\\nÂ\\xa0 Â\\xa0 (SELECT * FROM (VALUES (1, \\'Max\\', 28),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0(2, \\'Jane\\', 32),\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0(3, \\'Saymon\\', 29)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0) AS users(id, name, age)\\n\\nÂ\\xa0 Â\\xa0 WHERE false\\n\\nÂ\\xa0 Â\\xa0 ) AS users\\n\\nRIGHT JOINÂ\\xa0\\n\\nÂ\\xa0 Â\\xa0 (VALUES (1, \\'Engineer\\'),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 (2, \\'Doctor\\'),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 (3, \\'Teacher\\')\\n\\nÂ\\xa0 Â\\xa0 ) AS job(id, title)\\n\\nON users.id = job.idÂ\\xa0{code}\\n\\nExpected result is:\\n\\n||id||name||age||id0||title||\\n\\n|null|null|null|1|Engineer|\\n\\n|null|null|null|2|Doctor|\\n\\n|null|null|null|3|Teacher|\\n\\n\\n\\nBut we get 0 rows.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'158'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7d6bf4769b-d4gr7'), (b'x-envoy-upstream-service-time', b'142'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999951'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_745a105d18874abd3e0d370126f8f5fd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9aedaf417976-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Sun, 26 Jan 2025 06:56:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '158', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7d6bf4769b-d4gr7', 'x-envoy-upstream-service-time': '142', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999951', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_745a105d18874abd3e0d370126f8f5fd', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '907e9aedaf417976-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_745a105d18874abd3e0d370126f8f5fd\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: OPENNLP-1620\\nIssue Summary: It should be possible to remove the allocated ThreadLocal\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nIt should be possible to remove the allocated thread locals, if needed by the user as it is tied to the lifetime of the thread using it.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\n!image-2024-10-08-11-55-15-901.png!\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: OPENNLP-1702\\nIssue Summary: BratDocumentStream should process files in bratCorpusDir deterministically\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWith the recent addition of {{BratNameSampleStreamFactoryTest}} via OPENNLP-1695, it became obvious (Eval test run), that the code in BratDocumentStream is prone to non-determinism. This stems from the fact that {{java.util.File#listFiles(..)}} does not guarantee any order of the returned elements. \\n\\n\\n\\nA potential fix for achieving determinism again is to sort the result of listFiles(..) alphabetically in ASC order.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1667\\nIssue Summary: Add thread-safe version of ChunkerME\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, ChunkerME is not thread-safe. With OPENNLP-936, a thread-safe version for several related classes was introduced.\\n\\n\\n\\nHowever, this was not done for the Chunker case.\\n\\nLet\\'s introduce and provide ThreadSafeChunkerME.\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1661\\nIssue Summary: Fix custom models being wiped from OpenNLP user.home directory\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nCurrently, a Maven build ({{mvn clean test}}) wipes existing models in the \\'{{user.home/.opennlp}}\\' directory, as the code in {{AbstractDownloadUtilTest#cleanupWhenOnline}} will clean those up before the related methods in {{DownloadUtil}} will be tested.\\n\\n\\n\\nHowever, this causes some headache, if custom-trained models with similar name patterns exist in that directory, as:\\n\\n\\n\\n_wipeExistingModelFiles(\"\\\\-tokens\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-sentence\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-pos\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-lemmas\\\\-\");_\\n\\n\\n\\nwill be executed. Moreover, this also causes a lot of overhead for dev people, as each run of the whole test suite will clean up either in the target directory of {{opennlp-tools}} module, or even worse, the local \\'{{user.home/.opennlp}}\\' directory, causing at least 128 (32 langs x 4 model types) models to be downloaded (over and over again).\\n\\n\\n\\nAims:\\n\\n* Ensure no (custom) model is accidentally removed from \\'{{user.home/.opennlp}}\\'.\\n\\n* Ensure models downloads aren\\'t repeated if they exist locally & are \"valid\" (_sha512_)\\n\\n* Validate freshly downloaded models AND existing ones to discover broken model files\\n\\n* Reduce download volume required for full (IT) builds\\n\\n* Reduce load for ASF infrastructure\\n\\n* Reduce overall ecological footprint\\n\\n\\n\\nNote: Same applies for \\'ci\\' Maven profile. As long as no \"mvn clean\" is executed, existing models kept in a build\\'s {{target}} folder should not be wiped and not be re-downloaded per test suite execution.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1655\\nIssue Summary: Add constructors in SentenceDetectorME and TokenizerME to inject custom abbreviation dictionary\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nUsers ofÂ\\xa0{{TokenizerME}} and/or {{SentenceDetectorME}} may want to load an additional or custom {{Dictionary}} for abbreviations used in a certain language or domain.\\n\\n\\n\\nHowever, this is not possible right now, at construction time of those classes.\\n\\n\\n\\nLet\\'s fix this by adding an additional constructor providing more flexibility.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1600\\nIssue Summary: Ability to disable POS mapper\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nSince version 2.4.0, the OpenNLP includes a mandatory POS tag mapper which either maps UD to Penn POS tags or vice versa.\\n\\n\\n\\nNow, this is a problem if you want to train a custom model on some arbitrary other POS tagset. \\n\\n\\n\\nIt would be great if there was a was to disable the POS mapper. \\n\\n\\n\\nIn fact, I would propose that POS mapping is turned off by default unless a POS mapper is manually supplied to the POS tagger - so stuff would remain backwards compatible.\\n\\n\\n\\nBut at least being able to turn of the mapper and/or to provide a custom mapper would be appreciated.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8B112CF0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014F8AA8E960> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8B112EB0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014F8AA8E960> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8AA59CC0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF8F2330> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF95D250>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014FFF8F2330> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF95D3D0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF8FEDB0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF8FD650>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8A8DCE10>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'175'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'193182'), (b'x-ratelimit-reset-requests', b'53.633s'), (b'x-ratelimit-reset-tokens', b'2.045s'), (b'x-request-id', b'req_2eb49bf71eff047c4589aca0f161ff03'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7_FIiPE6O0RSt4MZsQPLrBJnHuq3rJhIu52uWeJpgqA-1737874609-1.0.1.1-A_EvufYNrWkuV9xLhodywnGv.8WEcFW6rPLXoSyVhbrPN49AYDaqTlN.oZcuNHicDI_qyoF4AxDZhOUCalRDDA; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=9c4hkCGSDNAYjDMpPN5ASc4Mo_jNqtu9DzynmGIeGwc-1737874609353-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9af18f4a3dfb-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:49 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '175'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '193182'), ('x-ratelimit-reset-requests', '53.633s'), ('x-ratelimit-reset-tokens', '2.045s'), ('x-request-id', 'req_2eb49bf71eff047c4589aca0f161ff03'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=7_FIiPE6O0RSt4MZsQPLrBJnHuq3rJhIu52uWeJpgqA-1737874609-1.0.1.1-A_EvufYNrWkuV9xLhodywnGv.8WEcFW6rPLXoSyVhbrPN49AYDaqTlN.oZcuNHicDI_qyoF4AxDZhOUCalRDDA; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=9c4hkCGSDNAYjDMpPN5ASc4Mo_jNqtu9DzynmGIeGwc-1737874609353-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9af18f4a3dfb-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_2eb49bf71eff047c4589aca0f161ff03\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'369'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'198353'), (b'x-ratelimit-reset-requests', b'27.773s'), (b'x-ratelimit-reset-tokens', b'493ms'), (b'x-request-id', b'req_831b4a07a17fb13cea78f05a0df98406'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=DRdoHGU6gtfvrReTIJSka5xHevyRgo9XM_Z66KYmcLA-1737874609-1.0.1.1-tfpW4MLmUj6XqqbTVM9FQvpVu31nTBGeFqpxnREk49nybyNRzEofuyuGLGqh5L_znu0Jc79Su0QR5esOApB.9A; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=j7yuLHwsFxYZhaYZ91Bw8Y7h_F4Nz_6unyE3zctc7lg-1737874609462-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9af0ffbc9d23-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:49 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '369'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '198353'), ('x-ratelimit-reset-requests', '27.773s'), ('x-ratelimit-reset-tokens', '493ms'), ('x-request-id', 'req_831b4a07a17fb13cea78f05a0df98406'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=DRdoHGU6gtfvrReTIJSka5xHevyRgo9XM_Z66KYmcLA-1737874609-1.0.1.1-tfpW4MLmUj6XqqbTVM9FQvpVu31nTBGeFqpxnREk49nybyNRzEofuyuGLGqh5L_znu0Jc79Su0QR5esOApB.9A; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=j7yuLHwsFxYZhaYZ91Bw8Y7h_F4Nz_6unyE3zctc7lg-1737874609462-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9af0ffbc9d23-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_831b4a07a17fb13cea78f05a0df98406\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'333'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'194968'), (b'x-ratelimit-reset-requests', b'44.968s'), (b'x-ratelimit-reset-tokens', b'1.509s'), (b'x-request-id', b'req_53e413931cf5fe12002c5cc8fbdfe3cb'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Mj2zVim0UWdzhabb2MukLPqbDXrHPVskXEAubQfANJ0-1737874609-1.0.1.1-oIlEx41E1n.bAe_dyQKY3iok9OWSuYXS6Lhp1e5ajWMYLLtyyTLtMjzjybL8MSYGVzsplod5NjUIlXa4Yu6QtQ; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=LoFMqqtn.3ht.QzDghX__K6oW7fAF8g5h5i8xjRVje4-1737874609501-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9af14eb54a6b-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:49 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '333'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '194968'), ('x-ratelimit-reset-requests', '44.968s'), ('x-ratelimit-reset-tokens', '1.509s'), ('x-request-id', 'req_53e413931cf5fe12002c5cc8fbdfe3cb'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Mj2zVim0UWdzhabb2MukLPqbDXrHPVskXEAubQfANJ0-1737874609-1.0.1.1-oIlEx41E1n.bAe_dyQKY3iok9OWSuYXS6Lhp1e5ajWMYLLtyyTLtMjzjybL8MSYGVzsplod5NjUIlXa4Yu6QtQ; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=LoFMqqtn.3ht.QzDghX__K6oW7fAF8g5h5i8xjRVje4-1737874609501-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9af14eb54a6b-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_53e413931cf5fe12002c5cc8fbdfe3cb\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'198'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'197359'), (b'x-ratelimit-reset-requests', b'36.393s'), (b'x-ratelimit-reset-tokens', b'792ms'), (b'x-request-id', b'req_97db2a8f22fa998f6e13c1214c79f8c9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.xj.5aCfcR_aw_URZdXshCMb.W2ddiJQE0j9mrnYzNA-1737874609-1.0.1.1-ziQFGIPzge2qBqHmR8akHKj3DtXgxuP7PD59wh0OD_enDG9mcCqKJE2Dg2ZUoK54..vOTZ6G9F3VSVHiEz.YkQ; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ips5xKXJ0NCgoB0SpmZvcwKI16Yvjy2WWfBvvQWOXU0-1737874609528-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9af12c4bfde7-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:49 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '198'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '197359'), ('x-ratelimit-reset-requests', '36.393s'), ('x-ratelimit-reset-tokens', '792ms'), ('x-request-id', 'req_97db2a8f22fa998f6e13c1214c79f8c9'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.xj.5aCfcR_aw_URZdXshCMb.W2ddiJQE0j9mrnYzNA-1737874609-1.0.1.1-ziQFGIPzge2qBqHmR8akHKj3DtXgxuP7PD59wh0OD_enDG9mcCqKJE2Dg2ZUoK54..vOTZ6G9F3VSVHiEz.YkQ; path=/; expires=Sun, 26-Jan-25 07:26:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ips5xKXJ0NCgoB0SpmZvcwKI16Yvjy2WWfBvvQWOXU0-1737874609528-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9af12c4bfde7-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_97db2a8f22fa998f6e13c1214c79f8c9\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFF9851D0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014F8AA8E960> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8AA8F380>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'205'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'194694'), (b'x-ratelimit-reset-requests', b'1m1.383s'), (b'x-ratelimit-reset-tokens', b'1.591s'), (b'x-request-id', b'req_df9c946382f43f5503aacf8a179e259e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=O1JxTkbhJHGr2rXPJnYtG66BTcSU_h2lQzKOpN2td1o-1737874610-1.0.1.1-z5mVHd1zJwe7llF.HrL9KLeto4_p1tyGT3O5Cr_9eYD26Xde62r3kpvOrxU3tcCOSLqTIEOrHRWn8dyrAD8q9g; path=/; expires=Sun, 26-Jan-25 07:26:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=QgHYPXG9uBsjPGSzGpayph8PEu5kRXxItib0r1PniCg-1737874610240-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9af6e9c5fd04-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:50 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '205'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9992'), ('x-ratelimit-remaining-tokens', '194694'), ('x-ratelimit-reset-requests', '1m1.383s'), ('x-ratelimit-reset-tokens', '1.591s'), ('x-request-id', 'req_df9c946382f43f5503aacf8a179e259e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=O1JxTkbhJHGr2rXPJnYtG66BTcSU_h2lQzKOpN2td1o-1737874610-1.0.1.1-z5mVHd1zJwe7llF.HrL9KLeto4_p1tyGT3O5Cr_9eYD26Xde62r3kpvOrxU3tcCOSLqTIEOrHRWn8dyrAD8q9g; path=/; expires=Sun, 26-Jan-25 07:26:50 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=QgHYPXG9uBsjPGSzGpayph8PEu5kRXxItib0r1PniCg-1737874610240-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9af6e9c5fd04-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_df9c946382f43f5503aacf8a179e259e\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'84'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7d6bf4769b-7mx6c'), (b'x-envoy-upstream-service-time', b'48'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999957'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_1d29ce64b8a77d6bc332600abec7c086'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9aee1efefd1e-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Sun, 26 Jan 2025 06:56:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '84', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'via': 'envoy-router-7d6bf4769b-7mx6c', 'x-envoy-upstream-service-time': '48', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '1000000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '999957', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '2ms', 'x-request-id': 'req_1d29ce64b8a77d6bc332600abec7c086', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '907e9aee1efefd1e-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_1d29ce64b8a77d6bc332600abec7c086\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-3991\\nIssue Summary: QuorumCnxManager Listener port bind retry does not retry DNS lookup\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWe run Zookeeper in a container environment where DNS is not stable. As recommended by the documentation, we set _electionPortBindRetry_ to 0 (keeps retrying forever).\\n\\n\\n\\nOn some instances, we get the following exception in an infinite loop, even though the address already became resolve-able:\\n\\n\\n\\nÂ\\xa0\\n\\n{noformat}\\n\\nzk-2_1  | 2020-11-03 10:57:08,407 [myid:3] - ERROR [ListenerHandler-zk-2.test:3888:QuorumCnxManager$Listener$ListenerHandler@1093] - Exception while listening\\n\\nzk-2_1  | java.net.SocketException: Unresolved address\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.createNewServerSocket(QuorumCnxManager.java:1140)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.acceptConnections(QuorumCnxManager.java:1064)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.run(QuorumCnxManager.java:1033)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.lang.Thread.run(Unknown Source){noformat}\\n\\nZookeeper does not actually retry the DNS resolution, it just keeps using the old failed result.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\nThis happens because the InetSocketAddress is created once and the DNS lookup happens when it is created.\\n\\n\\n\\nThis issue has come up previously in https://issues.apache.org/jira/browse/ZOOKEEPER-1506 but it appears to still happen here.\\n\\n\\n\\nI have attached a repro.tar.gz to help reproduce this issue. Steps:\\n\\n * Untar repro.tar.gz\\n\\n * docker-compose up\\n\\n * See the exception keeps happening for zk-2, not for the others\\n\\n * Open db.test and uncomment the zk-2 line, increment the serial and save\\n\\n * Wait a few seconds for the DNS to refresh\\n\\n * Verify that you can resolve zk-2.test now (dig @172.16.60.2 zk-2.test) but the error keeps appearing\\n\\n\\n\\nI have also attached a patch that resolves this. The patch will retry DNS resolution if the address is still unresolved every time it tries to create the server socket.\\n\\n\\n\\nÂ\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-3160\\nIssue Summary: Custom User SSLContext\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThe Zookeeper libraries currently allow you to set up your SSL Context via system properties such as \"zookeeper.ssl.keyStore.location\" in the X509Util. This covers most simple use cases, where users have software keystores on their harddrive.\\n\\n\\n\\nThere are, however, a few additional scenarios that this doesn\\'t cover. Two possible ones would be:\\n\\n # The user has a hardware keystore, loaded in using PKCS11 or something similar.\\n\\n # The user has no access to the software keystore, but can retrieve an already-constructed SSLContext from their container.\\n\\n\\n\\nFor this, I would propose that the X509Util be extended to allow a user to set a property such as \"zookeeper.ssl.client.context\" to provide a class which supplies a custom SSL context. This gives a lot more flexibility to the ZK client, and allows the user to construct the SSLContext in whatever way they please (which also future proofs the implementation somewhat).\\n\\n\\n\\nI\\'ve already completed this feature, and will put in a PR soon for it.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-4790\\nIssue Summary: TLS Quorum hostname verification breaks in some scenarios\\nIssue Type: Improvement\\nPriority: Minor\\n\\nDescription:\\nCurrently, enabling Quorum TLS will make the server validate SANs client certificates of connecting quorum peers against their reverse DNS address.Â\\xa0\\n\\n\\n\\nÂ\\xa0We have seen this cause issues when running in Kubernetes, due to ip addresses resolving to multiple dns names, when ZooKeeper pods participate in multiple services. \\n\\n\\n\\nSince `InetAddress.getHostAddress()` returns a String, it basically becomes a game of chance which dns name is checked against the cert. \\n\\nThis usually shakes itself loose after a few minutes, when the hostname that gets returned by the reverse lookup randomly changes and all of a sudden matches the certificate... but this is less than ideal.\\n\\n\\n\\nThis has also caused issues in the Strimzi operator as well (see [this issue|https://github.com/strimzi/strimzi-kafka-operator/issues/3099]) - they solved this by pretty much adding anything they can find that might be relevant to the SAN, and a few wildcards on top of that.\\n\\n\\n\\nThis is both, error prone and doesn\\'t really add any relevant extra amount of security, since \"This certificate matches the connecting peer\" shouldn\\'t automatically mean \"this peer should be allowed to connect\".\\n\\nÂ\\xa0\\n\\nÂ\\xa0There are two (probably more) ways to fix this:\\n\\n\\n\\n# Retrieve _all_  reverse entries and check against all of them\\n\\n# The ZK server could verify the SAN against the list of servers ({{{}servers.N{}}}Â\\xa0in the config). A peer should be able to connect on the quorum port if and only if at least one SAN matches at least one of the listed servers.\\n\\n\\n\\nI\\'d argue that the second option is the better one, especially since the java api doesn\\'t even seem to have the option of retrieving all dns entries, but also because it better matches the expressed intent of the ZK admin.\\n\\n\\n\\nAdditionally, it would be nice to have a \"disable client hostname verification\" option that still leaves server hostname verification enabled. Strictly speaking this is a separate issue though, I\\'d be happy to spin that out into a ticket of its own..\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-4753\\nIssue Summary: Explicit handling of DIGEST-MD5 vs GSSAPI in quorum auth\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nThe SASL-based quorum authorizer does not explicitly distinguish between the DIGEST-MD5 and GSSAPI mechanisms: it is simply relying on {{NameCallback}} and {{PasswordCallback}} for authentication with the former and examining Kerberos principals in {{AuthorizeCallback}} for the latter.\\n\\n\\n\\nIt turns out that some SASL/DIGEST-MD5 configurations cause authentication and authorization IDs not to match the expected format, and the DIGEST-MD5-based portions of the quorum test suite to fail with obscure errors. (They can be traced to failures to join the quorum, but only by looking into detailed logs.)\\n\\n\\n\\nWe can use the login module name to determine whether DIGEST-MD5 or GSSAPI is used, and relax the authentication ID check for the former.  As a cleanup, we can keep the password-based credential map empty when Kerberos principals are expected.  Finally, we can adapt tests to ensure \"weirdly-shaped\" credentials only cause authentication failures in the GSSAPI case.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-4858\\nIssue Summary: Remove the lock contention between snapshotting and the sync operation\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nRemove the synchronized keyword from Zookeeper.takeSnapshot() and  ZookeeperServer.restoreFromSnapshot() API, as it causes lock contention on the ZookeeperServer object with the sync operation. \\n\\n\\n\\nIn ZookeeperServer.java, we have the following\\n\\n{code:java}\\n\\n\\n\\n public synchronized File takeSnapshot(boolean syncSnap, boolean isSevere, boolean fastForwardFromEdits) throws IOException {\\n\\n....\\n\\n}\\n\\n{code}\\n\\n\\n\\nIn ObserverZookeeperServer.java and FollowerZookeeperServer.java, we have the following\\n\\n       \\n\\n{code:java}\\n\\npublic synchronized void sync() {\\n\\n     ...\\n\\n    }\\n\\n\\n\\n{code}\\n\\n\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-4377\\nIssue Summary: KeeperException.create has NullPointerException when low version client requests the high version server\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\n{code:java}\\n\\nblishment complete on server localhost/127.0.0.1:2180, sessionid = 0x1000278adba0129, negotiated timeout = 30000blishment complete on server localhost/127.0.0.1:2180, sessionid = 0x1000278adba0129, negotiated timeout = 30000java.lang.NullPointerException at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.KeeperException.create(KeeperException.java:54) at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538) at site.ycsb.db.zookeeper.ZKClient.insert(ZKClient.java:131) at site.ycsb.DBWrapper.insert(DBWrapper.java:227) at site.ycsb.workloads.CoreWorkload.doInsert(CoreWorkload.java:621) at site.ycsb.ClientThread.run(ClientThread.java:135) at java.lang.Thread.run(Thread.java:748)java.lang.NullPointerExceptionjava.lang.NullPointerException\\n\\n at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.KeeperException.create(KeeperException.java:54) at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538)\\n\\n{code}\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8B14DFD0>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8B14E1D0>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFFC6F8C0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014F8AA8ED50> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014F8AA8ED50> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x0000014F8AA8ED50> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014F8B138DE0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFFC05B50>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000014FFFC06B10>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'235'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'197087'), (b'x-ratelimit-reset-requests', b'1m8.338s'), (b'x-ratelimit-reset-tokens', b'873ms'), (b'x-request-id', b'req_3e051ace65604b9ec3f581d49b4b44aa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=kF760K0VO7TMN5TZl4wJayMEwreWiHrjgc_hxzlYtQg-1737874611-1.0.1.1-HPSI46gTnYT_CCip0ixVMnIF5C566wIF7MAEydE0PaPrLa27TWmfKK415evTeL4N9G8MS1Igf3eb2V.D26dY2g; path=/; expires=Sun, 26-Jan-25 07:26:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=a.gljIJTNufCX_YKsOlXXk8oweCtQTOQ6jjfPJQKjVw-1737874611963-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9b014e334967-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'210'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'194680'), (b'x-ratelimit-reset-requests', b'1m16.952s'), (b'x-ratelimit-reset-tokens', b'1.595s'), (b'x-request-id', b'req_c3c4c9569a64d7169fd2b8dee295c1a6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=CCMsk_bq2rQlu1IhwDrWUqY2Kniz9QJeHzJcYvNovzA-1737874611-1.0.1.1-Aq4gz4SecO4NL8F3UJakavVWGbPMJ5FsfV9QJet3KASWZNUkJIZ8bDvO8mO7oTNZE596NDeG5R8rwWuXwkf5UQ; path=/; expires=Sun, 26-Jan-25 07:26:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=_E0dLJX4WhU4e9flrxppEB4U.mapWhCxaXHzA8hRoTU-1737874611965-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9b018aff0d90-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '235'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9992'), ('x-ratelimit-remaining-tokens', '197087'), ('x-ratelimit-reset-requests', '1m8.338s'), ('x-ratelimit-reset-tokens', '873ms'), ('x-request-id', 'req_3e051ace65604b9ec3f581d49b4b44aa'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=kF760K0VO7TMN5TZl4wJayMEwreWiHrjgc_hxzlYtQg-1737874611-1.0.1.1-HPSI46gTnYT_CCip0ixVMnIF5C566wIF7MAEydE0PaPrLa27TWmfKK415evTeL4N9G8MS1Igf3eb2V.D26dY2g; path=/; expires=Sun, 26-Jan-25 07:26:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=a.gljIJTNufCX_YKsOlXXk8oweCtQTOQ6jjfPJQKjVw-1737874611963-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9b014e334967-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:openai._base_client:request_id: req_3e051ace65604b9ec3f581d49b4b44aa\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:51 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '210'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9991'), ('x-ratelimit-remaining-tokens', '194680'), ('x-ratelimit-reset-requests', '1m16.952s'), ('x-ratelimit-reset-tokens', '1.595s'), ('x-request-id', 'req_c3c4c9569a64d7169fd2b8dee295c1a6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=CCMsk_bq2rQlu1IhwDrWUqY2Kniz9QJeHzJcYvNovzA-1737874611-1.0.1.1-Aq4gz4SecO4NL8F3UJakavVWGbPMJ5FsfV9QJet3KASWZNUkJIZ8bDvO8mO7oTNZE596NDeG5R8rwWuXwkf5UQ; path=/; expires=Sun, 26-Jan-25 07:26:51 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=_E0dLJX4WhU4e9flrxppEB4U.mapWhCxaXHzA8hRoTU-1737874611965-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9b018aff0d90-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c3c4c9569a64d7169fd2b8dee295c1a6\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 26 Jan 2025 06:56:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'181'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'194134'), (b'x-ratelimit-reset-requests', b'1m25.064s'), (b'x-ratelimit-reset-tokens', b'1.759s'), (b'x-request-id', b'req_dd222a68d2584616495b99fc267d57f9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=69Ump6GUejtuUVqcOqd1E7uv9cyIxaYZ6QNfLAPTOic-1737874612-1.0.1.1-sJOjWHNkr0fuqsa1q1RDC8.HTN3S.AEFxWL4lUHTJ9JaHQ9gjuPKnNPa7C1C4YQcEUieaxbrcnIMtzFM_z45nQ; path=/; expires=Sun, 26-Jan-25 07:26:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=sZ.WokdgAcY91wvL6WC3upLxxk4djl5DEM6gJtByF4Y-1737874612451-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'907e9b0199046bca-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sun, 26 Jan 2025 06:56:52 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '181'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9990'), ('x-ratelimit-remaining-tokens', '194134'), ('x-ratelimit-reset-requests', '1m25.064s'), ('x-ratelimit-reset-tokens', '1.759s'), ('x-request-id', 'req_dd222a68d2584616495b99fc267d57f9'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=69Ump6GUejtuUVqcOqd1E7uv9cyIxaYZ6QNfLAPTOic-1737874612-1.0.1.1-sJOjWHNkr0fuqsa1q1RDC8.HTN3S.AEFxWL4lUHTJ9JaHQ9gjuPKnNPa7C1C4YQcEUieaxbrcnIMtzFM_z45nQ; path=/; expires=Sun, 26-Jan-25 07:26:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=sZ.WokdgAcY91wvL6WC3upLxxk4djl5DEM6gJtByF4Y-1737874612451-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '907e9b0199046bca-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_dd222a68d2584616495b99fc267d57f9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n"
     ]
    }
   ],
   "source": [
    "INCLUDED_HIGH_LEVEL_CONTEXT_CHAIN_INDEXES = [0, 1]\n",
    "\n",
    "for index in INCLUDED_HIGH_LEVEL_CONTEXT_CHAIN_INDEXES:\n",
    "    evaluator.get_high_level_contexts(\n",
    "        HIGH_LEVEL_CONTEXT_CHAINS[index],\n",
    "        COMMITS, \n",
    "        CONTEXT_DATA_PATH, \n",
    "        HIGH_LEVEL_CONTEXT_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Commit Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\nSource code:\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (Before)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case LOGICAL:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (After)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case PARTITION_PRUNING:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (Before)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Ignore;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\n@Ignore(\"DRILL-8400\")\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (After)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\nSource code:\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (Before)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.ByteArrayInputStream;\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Arrays;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLParameters;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (After)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.lang.reflect.InvocationTargetException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslContextSupplierClassProperty() {\\n    return sslContextSupplierClassProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\n@SuppressWarnings(\"unchecked\")\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n    if (supplierContextClassName != null) {\\n        if (LOG.isDebugEnabled()) {\\n            LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n        }\\n        try {\\n            Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n            Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n            return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n        } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException | InstantiationException | IllegalAccessException e) {\\n            throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName + \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n        }\\n    } else {\\n        return createSSLContextAndOptionsFromConfig(config);\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (Before)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (After)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslContextSupplierClassProperty(), System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (Before)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (After)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.NoSuchAlgorithmException;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\n@Test(expected = X509Exception.SSLContextException.class)\\npublic void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n    clientX509Util.createSSLContext(zkConfig);\\n}\\n@Test\\npublic void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n    final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n    Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\npublic static class SslContextSupplier implements Supplier<SSLContext> {\\n\\n    @Override\\n    public SSLContext get() {\\n        try {\\n            return SSLContext.getDefault();\\n        } catch (NoSuchAlgorithmException e) {\\n            throw new RuntimeException(e);\\n        }\\n    }\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\nSource code:\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (Before)\\npublic class ThreadSafePOSTaggerME implements POSTagger {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (After)\\npublic class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (Before)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        sentenceDetectorThreadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (After)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = threadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        threadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (Before)\\npublic class ThreadSafeTokenizerME implements Tokenizer {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        tokenizerThreadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (After)\\npublic class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = threadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        threadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BACC20>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BC0550>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BC0690>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B49220>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B49350>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5AB9910>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /info HTTP/11\" 200 672\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'985'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'197432'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'770ms'), (b'x-request-id', b'req_96b91b380a54f097e0719399eb1015f9'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GSXxSJTc9vYAv6DO154it9a1_MRbHuq2ZjlkD8DOxTg-1737949466-1.0.1.1-gQRwmqM6Hy7w5Dobt90vTxML3C8OhoUQv0nU12bf5hxLR5GFDCKzWFkv7i.Yz9ROnfIT7O_emp4mA.QmbLwMdQ; path=/; expires=Mon, 27-Jan-25 04:14:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=d6BxGm497F0E_gRZc5DJgzhQZg0akheF9iQUR91oFpA-1737949466546-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be7ab8cb9c45-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:26 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '985'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '197432'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '770ms'), ('x-request-id', 'req_96b91b380a54f097e0719399eb1015f9'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=GSXxSJTc9vYAv6DO154it9a1_MRbHuq2ZjlkD8DOxTg-1737949466-1.0.1.1-gQRwmqM6Hy7w5Dobt90vTxML3C8OhoUQv0nU12bf5hxLR5GFDCKzWFkv7i.Yz9ROnfIT7O_emp4mA.QmbLwMdQ; path=/; expires=Mon, 27-Jan-25 04:14:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=d6BxGm497F0E_gRZc5DJgzhQZg0akheF9iQUR91oFpA-1737949466546-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be7ab8cb9c45-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_96b91b380a54f097e0719399eb1015f9\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1069'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'187430'), (b'x-ratelimit-reset-requests', b'25.777s'), (b'x-ratelimit-reset-tokens', b'3.77s'), (b'x-request-id', b'req_67bdeecaea9f4c056524e7916db14534'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zvYZ.x3DI0tQpB2QaFzfgi8uqgzN8tlk17iDykWuWwA-1737949466-1.0.1.1-ttisEO7VilVHzlZMxtWybT8eh3BqNVeq6KYdYMfli8fvYgKcm7djIpJugbRbrC9F52JAVBEXFn_bROHikRoNuw; path=/; expires=Mon, 27-Jan-25 04:14:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=tY8sOb_3sn0U9CRL_TUru3vmdeSxpA2eqhdq56mNxW8-1737949466783-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be7ab95eec69-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:26 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1069'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9997'), ('x-ratelimit-remaining-tokens', '187430'), ('x-ratelimit-reset-requests', '25.777s'), ('x-ratelimit-reset-tokens', '3.77s'), ('x-request-id', 'req_67bdeecaea9f4c056524e7916db14534'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zvYZ.x3DI0tQpB2QaFzfgi8uqgzN8tlk17iDykWuWwA-1737949466-1.0.1.1-ttisEO7VilVHzlZMxtWybT8eh3BqNVeq6KYdYMfli8fvYgKcm7djIpJugbRbrC9F52JAVBEXFn_bROHikRoNuw; path=/; expires=Mon, 27-Jan-25 04:14:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=tY8sOb_3sn0U9CRL_TUru3vmdeSxpA2eqhdq56mNxW8-1737949466783-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be7ab95eec69-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_67bdeecaea9f4c056524e7916db14534\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1237'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'194570'), (b'x-ratelimit-reset-requests', b'17.268s'), (b'x-ratelimit-reset-tokens', b'1.628s'), (b'x-request-id', b'req_ac7bc618e4dc2de8deafbaf404f43ce8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zsFm7QJRoErpatmc2UYKlFB9xDmknrbNsZD2cD5CzLc-1737949466-1.0.1.1-xijG4kH9KP1aWFRFrqB94eAESJYELYU2qr5MAbzbviQirlqaIzDWmG_FVlzM5wFDNe0xUY7vcCjSGR17wcwpqA; path=/; expires=Mon, 27-Jan-25 04:14:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=xeG7rkn7wCVrz62MCgcspsphfRaWSTDj3Q0l.KgcDbM-1737949466814-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be7abaeffd17-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:26 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1237'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9998'), ('x-ratelimit-remaining-tokens', '194570'), ('x-ratelimit-reset-requests', '17.268s'), ('x-ratelimit-reset-tokens', '1.628s'), ('x-request-id', 'req_ac7bc618e4dc2de8deafbaf404f43ce8'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zsFm7QJRoErpatmc2UYKlFB9xDmknrbNsZD2cD5CzLc-1737949466-1.0.1.1-xijG4kH9KP1aWFRFrqB94eAESJYELYU2qr5MAbzbviQirlqaIzDWmG_FVlzM5wFDNe0xUY7vcCjSGR17wcwpqA; path=/; expires=Mon, 27-Jan-25 04:14:26 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=xeG7rkn7wCVrz62MCgcspsphfRaWSTDj3Q0l.KgcDbM-1737949466814-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be7abaeffd17-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_ac7bc618e4dc2de8deafbaf404f43ce8\n",
      "DEBUG:faiss.loader:Environment variable FAISS_OPT_LEVEL is not set, so let's pick the instruction set according to the current CPU\n",
      "INFO:faiss.loader:Loading faiss with AVX512 support.\n",
      "INFO:faiss.loader:Could not load library with AVX512 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx512'\")\n",
      "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
      "INFO:faiss.loader:Successfully loaded faiss with AVX2 support.\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000001AEB007F420>, 'json_data': {'input': [[791, 2082, 4442, 923, 264, 4668, 430, 6276, 279, 6989, 311, 9651, 4335, 709, 5070, 994, 814, 527, 912, 5129, 4460, 13, 1115, 18065, 25976, 264, 1749, 311, 4148, 13643, 828, 5938, 449, 1855, 4617, 11, 902, 8779, 10299, 5044, 810, 13750, 304, 7447, 61904, 291, 8522, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000001AEB007F560>, 'json_data': {'input': [[791, 2082, 4442, 21736, 21686, 264, 1749, 311, 30536, 828, 57470, 304, 264, 810, 11297, 1648, 555, 10223, 279, 10474, 505, 330, 7391, 15942, 1, 311, 330, 34590, 7237, 10794, 1899, 1753, 1210, 23212, 11, 264, 8767, 12305, 1296, 1162, 374, 1457, 4642, 311, 6106, 430, 279, 1887, 12722, 13777, 828, 17071, 287, 3196, 389, 3230, 4787, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000001AEB007D800>, 'json_data': {'input': [[791, 2082, 706, 1027, 6177, 311, 2187, 369, 264, 2587, 26384, 2317, 19353, 11, 28462, 810, 19303, 26384, 6683, 13, 23212, 11, 502, 7177, 617, 1027, 3779, 311, 6106, 430, 279, 1887, 74157, 12722, 994, 1701, 2225, 2764, 323, 8482, 2587, 26384, 2317, 6989, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0308270>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0308380>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0300950>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA20F0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA1D00> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA2060> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0300250>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0306030>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0305C70>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'68'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5974ff86bc-zxvnk'), (b'x-envoy-upstream-service-time', b'52'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999942'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_c30508e1dec65469dd34f664c2cdf35c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=mNTKdBFx2Bs7R5HibmomPXsFlXKhCoPiUL0c0Y7QpkI-1737949469-1.0.1.1-TKe84IXhzxwFWh9U._BR_S2xtU3ZehI1lkfJEdkbFm8p7WeYcdlK6PTOx8fVvkxzSBeRGOkbUJ.t1VcMogDzPQ; path=/; expires=Mon, 27-Jan-25 04:14:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=s9MfrNTm52Cs6Dib70HfGv9acStmfTyV2h1PPj_72CQ-1737949469981-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be985b5df8d4-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '68'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5974ff86bc-zxvnk'), ('x-envoy-upstream-service-time', '52'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999942'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '3ms'), ('x-request-id', 'req_c30508e1dec65469dd34f664c2cdf35c'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=mNTKdBFx2Bs7R5HibmomPXsFlXKhCoPiUL0c0Y7QpkI-1737949469-1.0.1.1-TKe84IXhzxwFWh9U._BR_S2xtU3ZehI1lkfJEdkbFm8p7WeYcdlK6PTOx8fVvkxzSBeRGOkbUJ.t1VcMogDzPQ; path=/; expires=Mon, 27-Jan-25 04:14:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=s9MfrNTm52Cs6Dib70HfGv9acStmfTyV2h1PPj_72CQ-1737949469981-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be985b5df8d4-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c30508e1dec65469dd34f664c2cdf35c\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8381\\nIssue Summary: Add support for filtered aggregate calls\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, Drill ignores filters for filtered aggregate calls and returns incorrect results.\\n\\nHere is the example query for which Drill will return incorrect results:\\n\\n{code:sql}\\n\\nSELECT count(n_name) FILTER(WHERE n_regionkey = 1) AS nations_count_in_1_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 2) AS nations_count_in_2_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 3) AS nations_count_in_3_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 4) AS nations_count_in_4_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 0) AS nations_count_in_0_region\\n\\nFROM cp.`tpch/nation.parquet`\\n\\n{code}\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 25                        | 25                        | 25                        | 25                        | 25                        |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nBut the correct result is\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 5                         | 5                         | 5                         | 5                         | 5                         |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nSide note:\\n\\nThe query above could be rewritten using PIVOT:\\n\\n{code:sql}\\n\\nSELECT `1` nations_count_in_1_region, `2` nations_count_in_2_region, `3` nations_count_in_3_region, `4` nations_count_in_4_region, `0` nations_count_in_0_region\\n\\nFROM (SELECT n_name, n_regionkey FROM cp.`tpch/nation.parquet`) \\n\\nPIVOT(count(n_name) FOR n_regionkey IN (0, 1, 2, 3, 4))\\n\\n{code}\\n\\nAnd will return correct results when this issue is fixed and Calcite is updated to 1.33.0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8400\\nIssue Summary: Fix pruning partitions with pushed transitive predicates\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nSee {{TestHivePartitionPruning.prunePartitionsBasedOnTransitivePredicates()}} test for details.\\n\\n\\n\\nThe issue occurs for queries like these:\\n\\n{code:sql}\\n\\nSELECT * FROM hive.partition_pruning_test t1 \\n\\nJOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \\n\\nWHERE t2.`e` IS NOT NULL AND t1.`d` = 1\\n\\n{code}\\n\\n\\n\\nThe expected behavior is to create additional filters based on the existing filters and join conditions. We have a {{TRANSITIVE_CLOSURE}} planning phase, which is responsible for such query transformations, but Drill pushes down filters from the WHERE condition before that phase, so the optimization is not performed.\\n\\n\\n\\nIdeally, we should move rules from the {{TRANSITIVE_CLOSURE}} phase to the {{LOGICAL}} phase so that the planner will choose the most optimal plan, but it wouldn\\'t help until CALCITE-1048 is fixed (it is required to pull predicates when three has {{RelSubset}} nodes).\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8489\\nIssue Summary: Sender memory leak when rpc encode exception\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nWhen encode throw Exception, if encode msg instanceof ReferenceCounted, netty can release msg, but drill convert msg to OutboundRpcMessage, so netty can not release msg. this Â\\xa0causes sender memory leaks\\n\\n\\n\\nexception infoÂ\\xa0\\n\\n{code:java}\\n\\n2024-04-16 16:25:57,998 [DataClient-7] ERROR o.a.d.exec.rpc.RpcExceptionHandler - Exception in RPC communication. Â\\xa0Connection: /10.32.112.138:47924 <--> /10.32.112.138:31012 (data client). Â\\xa0Closing connection.\\n\\nio.netty.handler.codec.EncoderException: org.apache.drill.exec.exception.OutOfMemoryException: Unable to allocate buffer of size 4096 due to memory limit (9223372036854775807). Current allocation: 0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:107)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:881)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:940)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1247)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at java.lang.Thread.run(Thread.java:748)\\n\\nCaused by: org.apache.drill.exec.exception.OutOfMemoryException: Unable to allocate buffer of size 4096 due to memory limit (9223372036854775807). Current allocation: 0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.BaseAllocator.buffer(BaseAllocator.java:245)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.BaseAllocator.buffer(BaseAllocator.java:220)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.DrillByteBufAllocator.buffer(DrillByteBufAllocator.java:55)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.DrillByteBufAllocator.buffer(DrillByteBufAllocator.java:50)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.rpc.RpcEncoder.encode(safeRelease.java:87)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.rpc.RpcEncoder.encode(RpcEncoder.java:38)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:90){code}\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8503\\nIssue Summary: Add Configuration Option to Skip Host Validation for Splunk\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nThis PR adds an option to skip host validation for SSL connections to Splunk.Â\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-4935\\nIssue Summary: Allow drillbits to advertise a configurable host address to Zookeeper\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThere are certain situations, such as running Drill in distributed Docker containers, in which it is desirable to advertise a different hostname to Zookeeper than would be output by INetAddress.getLocalHost().  I propose adding a configuration variable \\'drill.exec.rpc.bit.advertised.host\\' and passing this address to Zookeeper when the configuration variable is populated, otherwise falling back to the present behavior.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8513\\nIssue Summary: Right Hash Join with empty Left table ruturns 0 result\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nDrill returns no results on the right Hash Join if the probe(left) table is empty.\\n\\n\\n\\nThe simplest way to reproduce the issue:\\n\\n\\n\\n1.To force Drill not to use merge join and use the hash join operator instead:\\n\\n{code:java}\\n\\nalter session set planner.enable_mergejoin = false;\\n\\nalter session set planner.enable_nestedloopjoin= false; {code}\\n\\n2. Disable join order optimization to prevent Drill from flipping join tables:\\n\\n{code:java}\\n\\nalter session set planner.enable_join_optimization = false;  {code}\\n\\n3. Execute a query with empty left table outcome:\\n\\n{code:java}\\n\\nSELECT *\\n\\nFROMÂ\\xa0\\n\\nÂ\\xa0 Â\\xa0 (SELECT * FROM (VALUES (1, \\'Max\\', 28),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0(2, \\'Jane\\', 32),\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0(3, \\'Saymon\\', 29)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0) AS users(id, name, age)\\n\\nÂ\\xa0 Â\\xa0 WHERE false\\n\\nÂ\\xa0 Â\\xa0 ) AS users\\n\\nRIGHT JOINÂ\\xa0\\n\\nÂ\\xa0 Â\\xa0 (VALUES (1, \\'Engineer\\'),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 (2, \\'Doctor\\'),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 (3, \\'Teacher\\')\\n\\nÂ\\xa0 Â\\xa0 ) AS job(id, title)\\n\\nON users.id = job.idÂ\\xa0{code}\\n\\nExpected result is:\\n\\n||id||name||age||id0||title||\\n\\n|null|null|null|1|Engineer|\\n\\n|null|null|null|2|Doctor|\\n\\n|null|null|null|3|Teacher|\\n\\n\\n\\nBut we get 0 rows.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0335010>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0334C90>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766AF00> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766AF00> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEBA4314A0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766AF00> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B1D0D0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B1C410>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BE12E0>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'234'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-6c95bd8c84-snbxd'), (b'x-envoy-upstream-service-time', b'213'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999952'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_c6f3f27f25d69482034ca82a28d288a4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0uknIUZIeflQeBtL7vq59fmZ0ys3_nkoNES7N5bGD_E-1737949470-1.0.1.1-iWzaVihVs3BQKd4eLhS.LkzWzYZCDEc.CoEvq3000BoIosMNC1t5VBaiciT6znrBrn52b.GeLvAP9cOO89tyag; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kOrezRlov4dCfKCujNI66CJfnO_ce_iwL46EAF7hIwg-1737949470197-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be985c5cfdc7-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'212'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-85d8c45b57-6z57s'), (b'x-envoy-upstream-service-time', b'197'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999955'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_d96a88a5497c4e62b60fcb1240dd08d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=GB3KV9szZ1c8l24najPBtiLDIj.ihZ.9boL731ItOuo-1737949470-1.0.1.1-rRHRd15UOTjp22iByh7QKiCY9pmf7_QxL2YuOl6tGk_xXkcgS0Wtt67C._LFmD6ukiu4c1nLCvJxFhWtww5jSQ; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=pZMz42Jc3cirSMu262LWHILNsAoPdnopEI6hA_GXU9I-1737949470198-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be985ad3fcf2-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '234'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-6c95bd8c84-snbxd'), ('x-envoy-upstream-service-time', '213'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999952'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '2ms'), ('x-request-id', 'req_c6f3f27f25d69482034ca82a28d288a4'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=0uknIUZIeflQeBtL7vq59fmZ0ys3_nkoNES7N5bGD_E-1737949470-1.0.1.1-iWzaVihVs3BQKd4eLhS.LkzWzYZCDEc.CoEvq3000BoIosMNC1t5VBaiciT6znrBrn52b.GeLvAP9cOO89tyag; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kOrezRlov4dCfKCujNI66CJfnO_ce_iwL46EAF7hIwg-1737949470197-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be985c5cfdc7-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '212'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-85d8c45b57-6z57s'), ('x-envoy-upstream-service-time', '197'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999955'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '2ms'), ('x-request-id', 'req_d96a88a5497c4e62b60fcb1240dd08d1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=GB3KV9szZ1c8l24najPBtiLDIj.ihZ.9boL731ItOuo-1737949470-1.0.1.1-rRHRd15UOTjp22iByh7QKiCY9pmf7_QxL2YuOl6tGk_xXkcgS0Wtt67C._LFmD6ukiu4c1nLCvJxFhWtww5jSQ; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=pZMz42Jc3cirSMu262LWHILNsAoPdnopEI6hA_GXU9I-1737949470198-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be985ad3fcf2-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c6f3f27f25d69482034ca82a28d288a4\n",
      "DEBUG:openai._base_client:request_id: req_d96a88a5497c4e62b60fcb1240dd08d1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: OPENNLP-1620\\nIssue Summary: It should be possible to remove the allocated ThreadLocal\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nIt should be possible to remove the allocated thread locals, if needed by the user as it is tied to the lifetime of the thread using it.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\n!image-2024-10-08-11-55-15-901.png!\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: OPENNLP-1702\\nIssue Summary: BratDocumentStream should process files in bratCorpusDir deterministically\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWith the recent addition of {{BratNameSampleStreamFactoryTest}} via OPENNLP-1695, it became obvious (Eval test run), that the code in BratDocumentStream is prone to non-determinism. This stems from the fact that {{java.util.File#listFiles(..)}} does not guarantee any order of the returned elements. \\n\\n\\n\\nA potential fix for achieving determinism again is to sort the result of listFiles(..) alphabetically in ASC order.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1667\\nIssue Summary: Add thread-safe version of ChunkerME\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, ChunkerME is not thread-safe. With OPENNLP-936, a thread-safe version for several related classes was introduced.\\n\\n\\n\\nHowever, this was not done for the Chunker case.\\n\\nLet\\'s introduce and provide ThreadSafeChunkerME.\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1661\\nIssue Summary: Fix custom models being wiped from OpenNLP user.home directory\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nCurrently, a Maven build ({{mvn clean test}}) wipes existing models in the \\'{{user.home/.opennlp}}\\' directory, as the code in {{AbstractDownloadUtilTest#cleanupWhenOnline}} will clean those up before the related methods in {{DownloadUtil}} will be tested.\\n\\n\\n\\nHowever, this causes some headache, if custom-trained models with similar name patterns exist in that directory, as:\\n\\n\\n\\n_wipeExistingModelFiles(\"\\\\-tokens\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-sentence\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-pos\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-lemmas\\\\-\");_\\n\\n\\n\\nwill be executed. Moreover, this also causes a lot of overhead for dev people, as each run of the whole test suite will clean up either in the target directory of {{opennlp-tools}} module, or even worse, the local \\'{{user.home/.opennlp}}\\' directory, causing at least 128 (32 langs x 4 model types) models to be downloaded (over and over again).\\n\\n\\n\\nAims:\\n\\n* Ensure no (custom) model is accidentally removed from \\'{{user.home/.opennlp}}\\'.\\n\\n* Ensure models downloads aren\\'t repeated if they exist locally & are \"valid\" (_sha512_)\\n\\n* Validate freshly downloaded models AND existing ones to discover broken model files\\n\\n* Reduce download volume required for full (IT) builds\\n\\n* Reduce load for ASF infrastructure\\n\\n* Reduce overall ecological footprint\\n\\n\\n\\nNote: Same applies for \\'ci\\' Maven profile. As long as no \"mvn clean\" is executed, existing models kept in a build\\'s {{target}} folder should not be wiped and not be re-downloaded per test suite execution.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1655\\nIssue Summary: Add constructors in SentenceDetectorME and TokenizerME to inject custom abbreviation dictionary\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nUsers ofÂ\\xa0{{TokenizerME}} and/or {{SentenceDetectorME}} may want to load an additional or custom {{Dictionary}} for abbreviations used in a certain language or domain.\\n\\n\\n\\nHowever, this is not possible right now, at construction time of those classes.\\n\\n\\n\\nLet\\'s fix this by adding an additional constructor providing more flexibility.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1600\\nIssue Summary: Ability to disable POS mapper\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nSince version 2.4.0, the OpenNLP includes a mandatory POS tag mapper which either maps UD to Penn POS tags or vice versa.\\n\\n\\n\\nNow, this is a problem if you want to train a custom model on some arbitrary other POS tagset. \\n\\n\\n\\nIt would be great if there was a was to disable the POS mapper. \\n\\n\\n\\nIn fact, I would propose that POS mapping is turned off by default unless a POS mapper is manually supplied to the POS tagger - so stuff would remain backwards compatible.\\n\\n\\n\\nBut at least being able to turn of the mapper and/or to provide a custom mapper would be appreciated.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-3991\\nIssue Summary: QuorumCnxManager Listener port bind retry does not retry DNS lookup\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWe run Zookeeper in a container environment where DNS is not stable. As recommended by the documentation, we set _electionPortBindRetry_ to 0 (keeps retrying forever).\\n\\n\\n\\nOn some instances, we get the following exception in an infinite loop, even though the address already became resolve-able:\\n\\n\\n\\nÂ\\xa0\\n\\n{noformat}\\n\\nzk-2_1  | 2020-11-03 10:57:08,407 [myid:3] - ERROR [ListenerHandler-zk-2.test:3888:QuorumCnxManager$Listener$ListenerHandler@1093] - Exception while listening\\n\\nzk-2_1  | java.net.SocketException: Unresolved address\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.createNewServerSocket(QuorumCnxManager.java:1140)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.acceptConnections(QuorumCnxManager.java:1064)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.run(QuorumCnxManager.java:1033)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.lang.Thread.run(Unknown Source){noformat}\\n\\nZookeeper does not actually retry the DNS resolution, it just keeps using the old failed result.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\nThis happens because the InetSocketAddress is created once and the DNS lookup happens when it is created.\\n\\n\\n\\nThis issue has come up previously in https://issues.apache.org/jira/browse/ZOOKEEPER-1506 but it appears to still happen here.\\n\\n\\n\\nI have attached a repro.tar.gz to help reproduce this issue. Steps:\\n\\n * Untar repro.tar.gz\\n\\n * docker-compose up\\n\\n * See the exception keeps happening for zk-2, not for the others\\n\\n * Open db.test and uncomment the zk-2 line, increment the serial and save\\n\\n * Wait a few seconds for the DNS to refresh\\n\\n * Verify that you can resolve zk-2.test now (dig @172.16.60.2 zk-2.test) but the error keeps appearing\\n\\n\\n\\nI have also attached a patch that resolves this. The patch will retry DNS resolution if the address is still unresolved every time it tries to create the server socket.\\n\\n\\n\\nÂ\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-3160\\nIssue Summary: Custom User SSLContext\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThe Zookeeper libraries currently allow you to set up your SSL Context via system properties such as \"zookeeper.ssl.keyStore.location\" in the X509Util. This covers most simple use cases, where users have software keystores on their harddrive.\\n\\n\\n\\nThere are, however, a few additional scenarios that this doesn\\'t cover. Two possible ones would be:\\n\\n # The user has a hardware keystore, loaded in using PKCS11 or something similar.\\n\\n # The user has no access to the software keystore, but can retrieve an already-constructed SSLContext from their container.\\n\\n\\n\\nFor this, I would propose that the X509Util be extended to allow a user to set a property such as \"zookeeper.ssl.client.context\" to provide a class which supplies a custom SSL context. This gives a lot more flexibility to the ZK client, and allows the user to construct the SSLContext in whatever way they please (which also future proofs the implementation somewhat).\\n\\n\\n\\nI\\'ve already completed this feature, and will put in a PR soon for it.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-4790\\nIssue Summary: TLS Quorum hostname verification breaks in some scenarios\\nIssue Type: Improvement\\nPriority: Minor\\n\\nDescription:\\nCurrently, enabling Quorum TLS will make the server validate SANs client certificates of connecting quorum peers against their reverse DNS address.Â\\xa0\\n\\n\\n\\nÂ\\xa0We have seen this cause issues when running in Kubernetes, due to ip addresses resolving to multiple dns names, when ZooKeeper pods participate in multiple services. \\n\\n\\n\\nSince `InetAddress.getHostAddress()` returns a String, it basically becomes a game of chance which dns name is checked against the cert. \\n\\nThis usually shakes itself loose after a few minutes, when the hostname that gets returned by the reverse lookup randomly changes and all of a sudden matches the certificate... but this is less than ideal.\\n\\n\\n\\nThis has also caused issues in the Strimzi operator as well (see [this issue|https://github.com/strimzi/strimzi-kafka-operator/issues/3099]) - they solved this by pretty much adding anything they can find that might be relevant to the SAN, and a few wildcards on top of that.\\n\\n\\n\\nThis is both, error prone and doesn\\'t really add any relevant extra amount of security, since \"This certificate matches the connecting peer\" shouldn\\'t automatically mean \"this peer should be allowed to connect\".\\n\\nÂ\\xa0\\n\\nÂ\\xa0There are two (probably more) ways to fix this:\\n\\n\\n\\n# Retrieve _all_  reverse entries and check against all of them\\n\\n# The ZK server could verify the SAN against the list of servers ({{{}servers.N{}}}Â\\xa0in the config). A peer should be able to connect on the quorum port if and only if at least one SAN matches at least one of the listed servers.\\n\\n\\n\\nI\\'d argue that the second option is the better one, especially since the java api doesn\\'t even seem to have the option of retrieving all dns entries, but also because it better matches the expressed intent of the ZK admin.\\n\\n\\n\\nAdditionally, it would be nice to have a \"disable client hostname verification\" option that still leaves server hostname verification enabled. Strictly speaking this is a separate issue though, I\\'d be happy to spin that out into a ticket of its own..\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-4753\\nIssue Summary: Explicit handling of DIGEST-MD5 vs GSSAPI in quorum auth\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nThe SASL-based quorum authorizer does not explicitly distinguish between the DIGEST-MD5 and GSSAPI mechanisms: it is simply relying on {{NameCallback}} and {{PasswordCallback}} for authentication with the former and examining Kerberos principals in {{AuthorizeCallback}} for the latter.\\n\\n\\n\\nIt turns out that some SASL/DIGEST-MD5 configurations cause authentication and authorization IDs not to match the expected format, and the DIGEST-MD5-based portions of the quorum test suite to fail with obscure errors. (They can be traced to failures to join the quorum, but only by looking into detailed logs.)\\n\\n\\n\\nWe can use the login module name to determine whether DIGEST-MD5 or GSSAPI is used, and relax the authentication ID check for the former.  As a cleanup, we can keep the password-based credential map empty when Kerberos principals are expected.  Finally, we can adapt tests to ensure \"weirdly-shaped\" credentials only cause authentication failures in the GSSAPI case.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-4858\\nIssue Summary: Remove the lock contention between snapshotting and the sync operation\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nRemove the synchronized keyword from Zookeeper.takeSnapshot() and  ZookeeperServer.restoreFromSnapshot() API, as it causes lock contention on the ZookeeperServer object with the sync operation. \\n\\n\\n\\nIn ZookeeperServer.java, we have the following\\n\\n{code:java}\\n\\n\\n\\n public synchronized File takeSnapshot(boolean syncSnap, boolean isSevere, boolean fastForwardFromEdits) throws IOException {\\n\\n....\\n\\n}\\n\\n{code}\\n\\n\\n\\nIn ObserverZookeeperServer.java and FollowerZookeeperServer.java, we have the following\\n\\n       \\n\\n{code:java}\\n\\npublic synchronized void sync() {\\n\\n     ...\\n\\n    }\\n\\n\\n\\n{code}\\n\\n\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-4377\\nIssue Summary: KeeperException.create has NullPointerException when low version client requests the high version server\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\n{code:java}\\n\\nblishment complete on server localhost/127.0.0.1:2180, sessionid = 0x1000278adba0129, negotiated timeout = 30000blishment complete on server localhost/127.0.0.1:2180, sessionid = 0x1000278adba0129, negotiated timeout = 30000java.lang.NullPointerException at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.KeeperException.create(KeeperException.java:54) at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538) at site.ycsb.db.zookeeper.ZKClient.insert(ZKClient.java:131) at site.ycsb.DBWrapper.insert(DBWrapper.java:227) at site.ycsb.workloads.CoreWorkload.doInsert(CoreWorkload.java:621) at site.ycsb.ClientThread.run(ClientThread.java:135) at java.lang.Thread.run(Thread.java:748)java.lang.NullPointerExceptionjava.lang.NullPointerException\\n\\n at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.KeeperException.create(KeeperException.java:54) at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538)\\n\\n{code}\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BE1020>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766AE70> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFB90C30>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766AE70> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFB90F50>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFF20680>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBB6C50>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBB73D0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766A960> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766AE70> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBB8C20>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBB90F0>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'190'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'196816'), (b'x-ratelimit-reset-requests', b'38.339s'), (b'x-ratelimit-reset-tokens', b'954ms'), (b'x-request-id', b'req_c101a5cbd15635ea1861eebe0c265887'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QUzI2.71mG0Hju7eFa_h_9s0CHO6MlUX8UwDbeytRYc-1737949470-1.0.1.1-ax72pAENf6xPChGvGq6BH.GsBItPoazKueJdkf.459sG3GaH0DHyjY.PwiOY7gegdeNk.MGFDrXUjEKm59DI2g; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7QfXhguwLuVBChpYeWRuNgnC7DN6I3VAIqk25.7MMIM-1737949470618-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be9c582ddd82-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '190'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9995'), ('x-ratelimit-remaining-tokens', '196816'), ('x-ratelimit-reset-requests', '38.339s'), ('x-ratelimit-reset-tokens', '954ms'), ('x-request-id', 'req_c101a5cbd15635ea1861eebe0c265887'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QUzI2.71mG0Hju7eFa_h_9s0CHO6MlUX8UwDbeytRYc-1737949470-1.0.1.1-ax72pAENf6xPChGvGq6BH.GsBItPoazKueJdkf.459sG3GaH0DHyjY.PwiOY7gegdeNk.MGFDrXUjEKm59DI2g; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7QfXhguwLuVBChpYeWRuNgnC7DN6I3VAIqk25.7MMIM-1737949470618-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be9c582ddd82-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c101a5cbd15635ea1861eebe0c265887\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'304'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'198353'), (b'x-ratelimit-reset-requests', b'29.73s'), (b'x-ratelimit-reset-tokens', b'493ms'), (b'x-request-id', b'req_9f6e0a0a7e663fe39aa88a40031c518c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=p76LwW.sEU3_rFP7tp6QK_AalKJCvey1LFD5xLdNxZA-1737949470-1.0.1.1-PAFEWhRQJvovRhLrQ_Q4Qfeb2nbmPDsK.aYE8cTdFho5asIAuLKmUkrekBtn3OF2zqO9iW.qu85CX08w_zgPRg; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=AjaKbstrVUWB9fDW.CM0Cco1jdVCIkl7YAQLu5I_V_Y-1737949470713-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be9c2b67e182-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '304'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9996'), ('x-ratelimit-remaining-tokens', '198353'), ('x-ratelimit-reset-requests', '29.73s'), ('x-ratelimit-reset-tokens', '493ms'), ('x-request-id', 'req_9f6e0a0a7e663fe39aa88a40031c518c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=p76LwW.sEU3_rFP7tp6QK_AalKJCvey1LFD5xLdNxZA-1737949470-1.0.1.1-PAFEWhRQJvovRhLrQ_Q4Qfeb2nbmPDsK.aYE8cTdFho5asIAuLKmUkrekBtn3OF2zqO9iW.qu85CX08w_zgPRg; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=AjaKbstrVUWB9fDW.CM0Cco1jdVCIkl7YAQLu5I_V_Y-1737949470713-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be9c2b67e182-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_9f6e0a0a7e663fe39aa88a40031c518c\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'270'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9994'), (b'x-ratelimit-remaining-tokens', b'195826'), (b'x-ratelimit-reset-requests', b'46.959s'), (b'x-ratelimit-reset-tokens', b'1.252s'), (b'x-request-id', b'req_7ab4d2d0e1b00416d1075d59ab1156ff'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=WGCysuaNf6PsH8TLzpPTGvNbQeTS.7Vs37uIkgrjeJI-1737949470-1.0.1.1-S_1UfQ4HdDhUSsnGL1oxvMcZO9USye7YaBRGYf6v2GHthiQI8MFKYuoZzZuTsNNR5YqymuIbpBhgv21VSUs9Bw; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kgc4vOKRzkoM1LSLQdCJliKudkKxbpd2ot8_yU9FYnI-1737949470721-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be9c6b03ce81-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '270'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9994'), ('x-ratelimit-remaining-tokens', '195826'), ('x-ratelimit-reset-requests', '46.959s'), ('x-ratelimit-reset-tokens', '1.252s'), ('x-request-id', 'req_7ab4d2d0e1b00416d1075d59ab1156ff'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=WGCysuaNf6PsH8TLzpPTGvNbQeTS.7Vs37uIkgrjeJI-1737949470-1.0.1.1-S_1UfQ4HdDhUSsnGL1oxvMcZO9USye7YaBRGYf6v2GHthiQI8MFKYuoZzZuTsNNR5YqymuIbpBhgv21VSUs9Bw; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kgc4vOKRzkoM1LSLQdCJliKudkKxbpd2ot8_yU9FYnI-1737949470721-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be9c6b03ce81-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_7ab4d2d0e1b00416d1075d59ab1156ff\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BCCC50>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED010> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BCCB30>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'276'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9992'), (b'x-ratelimit-remaining-tokens', b'191288'), (b'x-ratelimit-reset-requests', b'1m4.014s'), (b'x-ratelimit-reset-tokens', b'2.613s'), (b'x-request-id', b'req_5434fa355145802208b1a5445d87346a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Q9HXzk6BlKke59N2GytComrSxR4yLohdWyGstizYThc-1737949470-1.0.1.1-NuzffBp.EdXhCVG2eC75dPMEqGE30x0_jb0c4Q5UgflN040lOuw3yUrerH.3aEuKGzSdt.W8H6_.cNg95MqpVg; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Nj9U7yjIkUqNne6m64otzS6kQrm6uKIVhlPWd6QsjVk-1737949470966-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be9daf66fdc7-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '276'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9992'), ('x-ratelimit-remaining-tokens', '191288'), ('x-ratelimit-reset-requests', '1m4.014s'), ('x-ratelimit-reset-tokens', '2.613s'), ('x-request-id', 'req_5434fa355145802208b1a5445d87346a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Q9HXzk6BlKke59N2GytComrSxR4yLohdWyGstizYThc-1737949470-1.0.1.1-NuzffBp.EdXhCVG2eC75dPMEqGE30x0_jb0c4Q5UgflN040lOuw3yUrerH.3aEuKGzSdt.W8H6_.cNg95MqpVg; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=Nj9U7yjIkUqNne6m64otzS6kQrm6uKIVhlPWd6QsjVk-1737949470966-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be9daf66fdc7-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_5434fa355145802208b1a5445d87346a\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'300'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9993'), (b'x-ratelimit-remaining-tokens', b'193791'), (b'x-ratelimit-reset-requests', b'55.371s'), (b'x-ratelimit-reset-tokens', b'1.862s'), (b'x-request-id', b'req_39a8f46f9ffca6f8bb85df9c773b9853'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0XCNNQydpoYIYGn2wB6HCSkDFNeLoxnv5kCCo2xqses-1737949470-1.0.1.1-ArHD61.594kYm7Y_BFIkwHgmvMXQisAX9UjPbKmFYIkWWqrXt7DHaScT6rDoti6YJcF9hbkMkyi3HB34P7M8Jg; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=HUsDYimYDyYpNwcakOdxiE0TUixgrlswadS3KXRaw2k-1737949470974-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be9dadd64918-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:30 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '300'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9993'), ('x-ratelimit-remaining-tokens', '193791'), ('x-ratelimit-reset-requests', '55.371s'), ('x-ratelimit-reset-tokens', '1.862s'), ('x-request-id', 'req_39a8f46f9ffca6f8bb85df9c773b9853'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=0XCNNQydpoYIYGn2wB6HCSkDFNeLoxnv5kCCo2xqses-1737949470-1.0.1.1-ArHD61.594kYm7Y_BFIkwHgmvMXQisAX9UjPbKmFYIkWWqrXt7DHaScT6rDoti6YJcF9hbkMkyi3HB34P7M8Jg; path=/; expires=Mon, 27-Jan-25 04:14:30 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=HUsDYimYDyYpNwcakOdxiE0TUixgrlswadS3KXRaw2k-1737949470974-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be9dadd64918-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_39a8f46f9ffca6f8bb85df9c773b9853\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'228'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9991'), (b'x-ratelimit-remaining-tokens', b'189061'), (b'x-ratelimit-reset-requests', b'1m12.548s'), (b'x-ratelimit-reset-tokens', b'3.281s'), (b'x-request-id', b'req_d1e2402c438958b7591a5503fd72b092'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Xn0tDpKf5SFKQF2jfo9FAMeGRQhYwuLEBs6JyCK4XfQ-1737949471-1.0.1.1-k6gJA3XztUbe5eaBo66J8_OKTUAizPL41XcSapSevHn4r3uPNhHj9911k2Bd9GQC5uUzNYdgSwvsblUI81I0Vw; path=/; expires=Mon, 27-Jan-25 04:14:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=eMTXBrJGEgKU8tYfmXjkZd0n8qhegh_f9jclQcYdQbY-1737949471009-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be9e5ffefd26-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:31 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '228'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9991'), ('x-ratelimit-remaining-tokens', '189061'), ('x-ratelimit-reset-requests', '1m12.548s'), ('x-ratelimit-reset-tokens', '3.281s'), ('x-request-id', 'req_d1e2402c438958b7591a5503fd72b092'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Xn0tDpKf5SFKQF2jfo9FAMeGRQhYwuLEBs6JyCK4XfQ-1737949471-1.0.1.1-k6gJA3XztUbe5eaBo66J8_OKTUAizPL41XcSapSevHn4r3uPNhHj9911k2Bd9GQC5uUzNYdgSwvsblUI81I0Vw; path=/; expires=Mon, 27-Jan-25 04:14:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=eMTXBrJGEgKU8tYfmXjkZd0n8qhegh_f9jclQcYdQbY-1737949471009-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be9e5ffefd26-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_d1e2402c438958b7591a5503fd72b092\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'202'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9990'), (b'x-ratelimit-remaining-tokens', b'187741'), (b'x-ratelimit-reset-requests', b'1m20.931s'), (b'x-ratelimit-reset-tokens', b'3.677s'), (b'x-request-id', b'req_7a64b23a11d99b8d09c5e54e47973d1d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=SiNy0sd_A8.w85OUm9W6QCb8uKh1FpOAi1hOX87Wtig-1737949471-1.0.1.1-U7WM6BQw7RiiBBQmRoC5PMUTzB27O5FkqjU49TDjCm46lNoqX474ayAOVHd2b7O49MfyBusmoAVZwMUBqO0K0g; path=/; expires=Mon, 27-Jan-25 04:14:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=zLSb.XYH2BLvupyYCvEAnwgFX9rrreWn2X8fk3u3DpY-1737949471236-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085be9e6e79ce21-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:31 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '202'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9990'), ('x-ratelimit-remaining-tokens', '187741'), ('x-ratelimit-reset-requests', '1m20.931s'), ('x-ratelimit-reset-tokens', '3.677s'), ('x-request-id', 'req_7a64b23a11d99b8d09c5e54e47973d1d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=SiNy0sd_A8.w85OUm9W6QCb8uKh1FpOAi1hOX87Wtig-1737949471-1.0.1.1-U7WM6BQw7RiiBBQmRoC5PMUTzB27O5FkqjU49TDjCm46lNoqX474ayAOVHd2b7O49MfyBusmoAVZwMUBqO0K0g; path=/; expires=Mon, 27-Jan-25 04:14:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=zLSb.XYH2BLvupyYCvEAnwgFX9rrreWn2X8fk3u3DpY-1737949471236-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085be9e6e79ce21-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_7a64b23a11d99b8d09c5e54e47973d1d\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'238'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9989'), (b'x-ratelimit-remaining-tokens', b'187057'), (b'x-ratelimit-reset-requests', b'1m29.523s'), (b'x-ratelimit-reset-tokens', b'3.882s'), (b'x-request-id', b'req_8c75d2bfa64dd15584b519d5d40e7db2'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=7KU.vkhn6uJ0l0LhnT.zAaW_aIP0M5hiOeIveSuNRiA-1737949471-1.0.1.1-1cz.142FckKXsBWMKJumAUAjwGaWEc2MKUTEyum6N.RXNMhG0HgM1_WVFxXVJ96JszRx4uEuKjCUsW5zh1uJxA; path=/; expires=Mon, 27-Jan-25 04:14:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=FYUtrnka9owWFvqRb1Yk1t5Sm12zrozaa3_FyaN5YWo-1737949471324-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bea088d19cbf-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB0BEAC10>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFADA0>\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:31 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '238'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9989'), ('x-ratelimit-remaining-tokens', '187057'), ('x-ratelimit-reset-requests', '1m29.523s'), ('x-ratelimit-reset-tokens', '3.882s'), ('x-request-id', 'req_8c75d2bfa64dd15584b519d5d40e7db2'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=7KU.vkhn6uJ0l0LhnT.zAaW_aIP0M5hiOeIveSuNRiA-1737949471-1.0.1.1-1cz.142FckKXsBWMKJumAUAjwGaWEc2MKUTEyum6N.RXNMhG0HgM1_WVFxXVJ96JszRx4uEuKjCUsW5zh1uJxA; path=/; expires=Mon, 27-Jan-25 04:14:31 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=FYUtrnka9owWFvqRb1Yk1t5Sm12zrozaa3_FyaN5YWo-1737949471324-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bea088d19cbf-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766A960> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED010> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:openai._base_client:request_id: req_8c75d2bfa64dd15584b519d5d40e7db2\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B62E40>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B79EA0>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'290'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9988'), (b'x-ratelimit-remaining-tokens', b'187868'), (b'x-ratelimit-reset-requests', b'1m37.494s'), (b'x-ratelimit-reset-tokens', b'3.639s'), (b'x-request-id', b'req_6dc8cdb9fa20991f9d59b641245fc8a1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4kYm2dhl0YStC1jz2Ikq83i2fgkanQw11RXVZ6Vwoiw-1737949472-1.0.1.1-E3vYU75RjuETsMxBZNA_Y_bA_Jo8TkMCSXvCmu5DF1oHNGVSEpxNtKZDx8VYCmBqcSK6PElQHpfahMz0.hahqA; path=/; expires=Mon, 27-Jan-25 04:14:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=oig909LXoTooYcZMmTvx4cyNmVfzrzU3LBQ_6oepqlM-1737949472047-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bea42867102f-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:32 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '290'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9988'), ('x-ratelimit-remaining-tokens', '187868'), ('x-ratelimit-reset-requests', '1m37.494s'), ('x-ratelimit-reset-tokens', '3.639s'), ('x-request-id', 'req_6dc8cdb9fa20991f9d59b641245fc8a1'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=4kYm2dhl0YStC1jz2Ikq83i2fgkanQw11RXVZ6Vwoiw-1737949472-1.0.1.1-E3vYU75RjuETsMxBZNA_Y_bA_Jo8TkMCSXvCmu5DF1oHNGVSEpxNtKZDx8VYCmBqcSK6PElQHpfahMz0.hahqA; path=/; expires=Mon, 27-Jan-25 04:14:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=oig909LXoTooYcZMmTvx4cyNmVfzrzU3LBQ_6oepqlM-1737949472047-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bea42867102f-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_6dc8cdb9fa20991f9d59b641245fc8a1\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'260'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9987'), (b'x-ratelimit-remaining-tokens', b'187145'), (b'x-ratelimit-reset-requests', b'1m45.725s'), (b'x-ratelimit-reset-tokens', b'3.856s'), (b'x-request-id', b'req_d822fcc6ab6729e5d7550378d2eb8407'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9y7u1JPl27rvEOEvVKNGBD9Bp96G3MhB3ZCJSAKychE-1737949472-1.0.1.1-6F35N_DFvKLamQwlXp9Y820QTTy_pvbHqrE0o5BNkSA4Qb6WDu81Pqvb.e9IBnTbyKi6_kzzIPC2uKUFB0S7rA; path=/; expires=Mon, 27-Jan-25 04:14:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=eMq760u.S4QxZOizqTfRgxEdI40u0PmdXdP1LGD.f30-1737949472429-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bea43a734d45-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:32 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '260'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9987'), ('x-ratelimit-remaining-tokens', '187145'), ('x-ratelimit-reset-requests', '1m45.725s'), ('x-ratelimit-reset-tokens', '3.856s'), ('x-request-id', 'req_d822fcc6ab6729e5d7550378d2eb8407'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=9y7u1JPl27rvEOEvVKNGBD9Bp96G3MhB3ZCJSAKychE-1737949472-1.0.1.1-6F35N_DFvKLamQwlXp9Y820QTTy_pvbHqrE0o5BNkSA4Qb6WDu81Pqvb.e9IBnTbyKi6_kzzIPC2uKUFB0S7rA; path=/; expires=Mon, 27-Jan-25 04:14:32 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=eMq760u.S4QxZOizqTfRgxEdI40u0PmdXdP1LGD.f30-1737949472429-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bea43a734d45-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_d822fcc6ab6729e5d7550378d2eb8407\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'195'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9986'), (b'x-ratelimit-remaining-tokens', b'186115'), (b'x-ratelimit-reset-requests', b'1m54.145s'), (b'x-ratelimit-reset-tokens', b'4.165s'), (b'x-request-id', b'req_df0e603bc6ea34deac6084a1ea10c1e4'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bea888919cbf-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '195', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9986', 'x-ratelimit-remaining-tokens': '186115', 'x-ratelimit-reset-requests': '1m54.145s', 'x-ratelimit-reset-tokens': '4.165s', 'x-request-id': 'req_df0e603bc6ea34deac6084a1ea10c1e4', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085bea888919cbf-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_df0e603bc6ea34deac6084a1ea10c1e4\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and additional context provided. If the context is relevant, include it in the commit body. Use IDs, names, or titles to reference relevant contexts for brevity. Including multiple contexts is allowed.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff:\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\nAdditional context:\\nTicket ID: DRILL-8381\\nIssue Summary: Add support for filtered aggregate calls\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, Drill ignores filters for filtered aggregate calls and returns incorrect results.\\n\\nHere is the example query for which Drill will return incorrect results:\\n\\n{code:sql}\\n\\nSELECT count(n_name) FILTER(WHERE n_regionkey = 1) AS nations_count_in_1_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 2) AS nations_count_in_2_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 3) AS nations_count_in_3_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 4) AS nations_count_in_4_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 0) AS nations_count_in_0_region\\n\\nFROM cp.`tpch/nation.parquet`\\n\\n{code}\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 25                        | 25                        | 25                        | 25                        | 25                        |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nBut the correct result is\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 5                         | 5                         | 5                         | 5                         | 5                         |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nSide note:\\n\\nThe query above could be rewritten using PIVOT:\\n\\n{code:sql}\\n\\nSELECT `1` nations_count_in_1_region, `2` nations_count_in_2_region, `3` nations_count_in_3_region, `4` nations_count_in_4_region, `0` nations_count_in_0_region\\n\\nFROM (SELECT n_name, n_regionkey FROM cp.`tpch/nation.parquet`) \\n\\nPIVOT(count(n_name) FOR n_regionkey IN (0, 1, 2, 3, 4))\\n\\n{code}\\n\\nAnd will return correct results when this issue is fixed and Calcite is updated to 1.33.0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8400\\nIssue Summary: Fix pruning partitions with pushed transitive predicates\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nSee {{TestHivePartitionPruning.prunePartitionsBasedOnTransitivePredicates()}} test for details.\\n\\n\\n\\nThe issue occurs for queries like these:\\n\\n{code:sql}\\n\\nSELECT * FROM hive.partition_pruning_test t1 \\n\\nJOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \\n\\nWHERE t2.`e` IS NOT NULL AND t1.`d` = 1\\n\\n{code}\\n\\n\\n\\nThe expected behavior is to create additional filters based on the existing filters and join conditions. We have a {{TRANSITIVE_CLOSURE}} planning phase, which is responsible for such query transformations, but Drill pushes down filters from the WHERE condition before that phase, so the optimization is not performed.\\n\\n\\n\\nIdeally, we should move rules from the {{TRANSITIVE_CLOSURE}} phase to the {{LOGICAL}} phase so that the planner will choose the most optimal plan, but it wouldn\\'t help until CALCITE-1048 is fixed (it is required to pull predicates when three has {{RelSubset}} nodes).\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit type: refactor\\n\\nCommit message: ', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and additional context provided. If the context is relevant, include it in the commit body. Use IDs, names, or titles to reference relevant contexts for brevity. Including multiple contexts is allowed.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff:\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\nAdditional context:\\nTicket ID: ZOOKEEPER-3991\\nIssue Summary: QuorumCnxManager Listener port bind retry does not retry DNS lookup\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWe run Zookeeper in a container environment where DNS is not stable. As recommended by the documentation, we set _electionPortBindRetry_ to 0 (keeps retrying forever).\\n\\n\\n\\nOn some instances, we get the following exception in an infinite loop, even though the address already became resolve-able:\\n\\n\\n\\nÂ\\xa0\\n\\n{noformat}\\n\\nzk-2_1  | 2020-11-03 10:57:08,407 [myid:3] - ERROR [ListenerHandler-zk-2.test:3888:QuorumCnxManager$Listener$ListenerHandler@1093] - Exception while listening\\n\\nzk-2_1  | java.net.SocketException: Unresolved address\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.createNewServerSocket(QuorumCnxManager.java:1140)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.acceptConnections(QuorumCnxManager.java:1064)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.run(QuorumCnxManager.java:1033)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.lang.Thread.run(Unknown Source){noformat}\\n\\nZookeeper does not actually retry the DNS resolution, it just keeps using the old failed result.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\nThis happens because the InetSocketAddress is created once and the DNS lookup happens when it is created.\\n\\n\\n\\nThis issue has come up previously in https://issues.apache.org/jira/browse/ZOOKEEPER-1506 but it appears to still happen here.\\n\\n\\n\\nI have attached a repro.tar.gz to help reproduce this issue. Steps:\\n\\n * Untar repro.tar.gz\\n\\n * docker-compose up\\n\\n * See the exception keeps happening for zk-2, not for the others\\n\\n * Open db.test and uncomment the zk-2 line, increment the serial and save\\n\\n * Wait a few seconds for the DNS to refresh\\n\\n * Verify that you can resolve zk-2.test now (dig @172.16.60.2 zk-2.test) but the error keeps appearing\\n\\n\\n\\nI have also attached a patch that resolves this. The patch will retry DNS resolution if the address is still unresolved every time it tries to create the server socket.\\n\\n\\n\\nÂ\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-3160\\nIssue Summary: Custom User SSLContext\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThe Zookeeper libraries currently allow you to set up your SSL Context via system properties such as \"zookeeper.ssl.keyStore.location\" in the X509Util. This covers most simple use cases, where users have software keystores on their harddrive.\\n\\n\\n\\nThere are, however, a few additional scenarios that this doesn\\'t cover. Two possible ones would be:\\n\\n # The user has a hardware keystore, loaded in using PKCS11 or something similar.\\n\\n # The user has no access to the software keystore, but can retrieve an already-constructed SSLContext from their container.\\n\\n\\n\\nFor this, I would propose that the X509Util be extended to allow a user to set a property such as \"zookeeper.ssl.client.context\" to provide a class which supplies a custom SSL context. This gives a lot more flexibility to the ZK client, and allows the user to construct the SSLContext in whatever way they please (which also future proofs the implementation somewhat).\\n\\n\\n\\nI\\'ve already completed this feature, and will put in a PR soon for it.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit type: feat\\n\\nCommit message: ', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and additional context provided. If the context is relevant, include it in the commit body. Use IDs, names, or titles to reference relevant contexts for brevity. Including multiple contexts is allowed.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff:\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\nAdditional context:\\nTicket ID: OPENNLP-1620\\nIssue Summary: It should be possible to remove the allocated ThreadLocal\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nIt should be possible to remove the allocated thread locals, if needed by the user as it is tied to the lifetime of the thread using it.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\n!image-2024-10-08-11-55-15-901.png!\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit type: refactor\\n\\nCommit message: ', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B03E30>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B62CB0>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BD0320>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED520> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED520> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED520> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5B96BC0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BD1D60>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BD25D0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1207'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9985'), (b'x-ratelimit-remaining-tokens', b'185567'), (b'x-ratelimit-reset-requests', b'2m2.161s'), (b'x-ratelimit-reset-tokens', b'4.329s'), (b'x-request-id', b'req_27d998bbfa9f3a687370c0f31b6d6923'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4drX4h.50L8KUuRRdzxVeOlMbCvb4ZLr6o3YscHvT1c-1737949474-1.0.1.1-EWZ842EFfLxJ.8SS2dxdvYhGoHg01Potyjsm6U39gv3rNrGlci8qTfOFvRu9_VJf1FlZ9J21yGzRUltrn2lomw; path=/; expires=Mon, 27-Jan-25 04:14:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=A45QOyFoTIiavCDGMNcQ5uDAl02WrQa4XrqfnKkUjJo-1737949474220-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beac4d12f8f0-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1207'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9985'), ('x-ratelimit-remaining-tokens', '185567'), ('x-ratelimit-reset-requests', '2m2.161s'), ('x-ratelimit-reset-tokens', '4.329s'), ('x-request-id', 'req_27d998bbfa9f3a687370c0f31b6d6923'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=4drX4h.50L8KUuRRdzxVeOlMbCvb4ZLr6o3YscHvT1c-1737949474-1.0.1.1-EWZ842EFfLxJ.8SS2dxdvYhGoHg01Potyjsm6U39gv3rNrGlci8qTfOFvRu9_VJf1FlZ9J21yGzRUltrn2lomw; path=/; expires=Mon, 27-Jan-25 04:14:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=A45QOyFoTIiavCDGMNcQ5uDAl02WrQa4XrqfnKkUjJo-1737949474220-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085beac4d12f8f0-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_27d998bbfa9f3a687370c0f31b6d6923\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1189'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9984'), (b'x-ratelimit-remaining-tokens', b'183931'), (b'x-ratelimit-reset-requests', b'2m10.776s'), (b'x-ratelimit-reset-tokens', b'4.82s'), (b'x-request-id', b'req_585ca237ac37013c951c5a2c034cf3e6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9AjolTL_CCOsXrhTE.FDMcKRth6k7vX04J.uKj9MIjw-1737949474-1.0.1.1-evYgVeQFlj2jMcD8IEnAa1JJ75W4KCcd2kK6TIbgC3q9Hm8aqvlFTIeEFuII0A8pEcoZUAZOPTpH_DqCv3d2gg; path=/; expires=Mon, 27-Jan-25 04:14:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=vKiSfCn18qa0qtNTEZY2fELTJzOPOwf8NWdKN2kPdvM-1737949474239-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beac9f0cce82-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1189'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9984'), ('x-ratelimit-remaining-tokens', '183931'), ('x-ratelimit-reset-requests', '2m10.776s'), ('x-ratelimit-reset-tokens', '4.82s'), ('x-request-id', 'req_585ca237ac37013c951c5a2c034cf3e6'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=9AjolTL_CCOsXrhTE.FDMcKRth6k7vX04J.uKj9MIjw-1737949474-1.0.1.1-evYgVeQFlj2jMcD8IEnAa1JJ75W4KCcd2kK6TIbgC3q9Hm8aqvlFTIeEFuII0A8pEcoZUAZOPTpH_DqCv3d2gg; path=/; expires=Mon, 27-Jan-25 04:14:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=vKiSfCn18qa0qtNTEZY2fELTJzOPOwf8NWdKN2kPdvM-1737949474239-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085beac9f0cce82-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_585ca237ac37013c951c5a2c034cf3e6\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1430'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9983'), (b'x-ratelimit-remaining-tokens', b'182248'), (b'x-ratelimit-reset-requests', b'2m19.388s'), (b'x-ratelimit-reset-tokens', b'5.325s'), (b'x-request-id', b'req_c4f0a55f9b06c64ce44c3091e62d5bdd'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5z8nE.0gjVVYFvpKHec8dTgTz1J23nUxgex4JwB.iOE-1737949474-1.0.1.1-xxqFbCLY1lnvwo6ioj5bOD84QDMDK1amX9wDfj6pw0ahaChT6JWjvYXeXc4d3di8nhIHmHyMqDbl.ZA6Lm5H6g; path=/; expires=Mon, 27-Jan-25 04:14:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=SR03.U.mZIUVN4_Yv4nQVqrXrE_I5SA_YWuwvnBJA_0-1737949474508-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beacbe6bc694-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1430'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9983'), ('x-ratelimit-remaining-tokens', '182248'), ('x-ratelimit-reset-requests', '2m19.388s'), ('x-ratelimit-reset-tokens', '5.325s'), ('x-request-id', 'req_c4f0a55f9b06c64ce44c3091e62d5bdd'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=5z8nE.0gjVVYFvpKHec8dTgTz1J23nUxgex4JwB.iOE-1737949474-1.0.1.1-xxqFbCLY1lnvwo6ioj5bOD84QDMDK1amX9wDfj6pw0ahaChT6JWjvYXeXc4d3di8nhIHmHyMqDbl.ZA6Lm5H6g; path=/; expires=Mon, 27-Jan-25 04:14:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=SR03.U.mZIUVN4_Yv4nQVqrXrE_I5SA_YWuwvnBJA_0-1737949474508-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085beacbe6bc694-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_c4f0a55f9b06c64ce44c3091e62d5bdd\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\nSource code:\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (Before)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case LOGICAL:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (After)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case PARTITION_PRUNING:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (Before)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Ignore;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\n@Ignore(\"DRILL-8400\")\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (After)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\nSource code:\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (Before)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.ByteArrayInputStream;\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Arrays;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLParameters;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (After)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.lang.reflect.InvocationTargetException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslContextSupplierClassProperty() {\\n    return sslContextSupplierClassProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\n@SuppressWarnings(\"unchecked\")\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n    if (supplierContextClassName != null) {\\n        if (LOG.isDebugEnabled()) {\\n            LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n        }\\n        try {\\n            Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n            Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n            return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n        } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException | InstantiationException | IllegalAccessException e) {\\n            throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName + \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n        }\\n    } else {\\n        return createSSLContextAndOptionsFromConfig(config);\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (Before)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (After)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslContextSupplierClassProperty(), System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (Before)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (After)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.NoSuchAlgorithmException;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\n@Test(expected = X509Exception.SSLContextException.class)\\npublic void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n    clientX509Util.createSSLContext(zkConfig);\\n}\\n@Test\\npublic void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n    final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n    Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\npublic static class SslContextSupplier implements Supplier<SSLContext> {\\n\\n    @Override\\n    public SSLContext get() {\\n        try {\\n            return SSLContext.getDefault();\\n        } catch (NoSuchAlgorithmException e) {\\n            throw new RuntimeException(e);\\n        }\\n    }\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Given a Git diff and the relevant source code, write a concise summary of the code changes in a way that a non-technical person can understand. The query text must summarize the code changes in two very brief sentences.\\n\\nGit diff:\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\nSource code:\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (Before)\\npublic class ThreadSafePOSTaggerME implements POSTagger {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (After)\\npublic class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (Before)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        sentenceDetectorThreadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (After)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = threadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        threadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (Before)\\npublic class ThreadSafeTokenizerME implements Tokenizer {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        tokenizerThreadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (After)\\npublic class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = threadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        threadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\n\\nQuery text:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFB3EE40>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BB88C0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFAAD0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED370> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFBF70>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC340A0>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC34280>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'744'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9981'), (b'x-ratelimit-remaining-tokens', b'176456'), (b'x-ratelimit-reset-requests', b'2m43.207s'), (b'x-ratelimit-reset-tokens', b'7.062s'), (b'x-request-id', b'req_15373c2900ac34f99df636eeebe20b5d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beb8cd3afcfc-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '744', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9981', 'x-ratelimit-remaining-tokens': '176456', 'x-ratelimit-reset-requests': '2m43.207s', 'x-ratelimit-reset-tokens': '7.062s', 'x-request-id': 'req_15373c2900ac34f99df636eeebe20b5d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085beb8cd3afcfc-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_15373c2900ac34f99df636eeebe20b5d\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1002'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9983'), (b'x-ratelimit-remaining-tokens', b'186449'), (b'x-ratelimit-reset-requests', b'2m26.072s'), (b'x-ratelimit-reset-tokens', b'4.065s'), (b'x-request-id', b'req_c37be994bfe909ffe23c5426b034d681'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beb8cbf5602d-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '1002', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9983', 'x-ratelimit-remaining-tokens': '186449', 'x-ratelimit-reset-requests': '2m26.072s', 'x-ratelimit-reset-tokens': '4.065s', 'x-request-id': 'req_c37be994bfe909ffe23c5426b034d681', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085beb8cbf5602d-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_c37be994bfe909ffe23c5426b034d681\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1166'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9982'), (b'x-ratelimit-remaining-tokens', b'183699'), (b'x-ratelimit-reset-requests', b'2m34.667s'), (b'x-ratelimit-reset-tokens', b'4.89s'), (b'x-request-id', b'req_7683a3c7a1488326c0a64c36ea8539a0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beb8cb814565-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '1166', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9982', 'x-ratelimit-remaining-tokens': '183699', 'x-ratelimit-reset-requests': '2m34.667s', 'x-ratelimit-reset-tokens': '4.89s', 'x-request-id': 'req_7683a3c7a1488326c0a64c36ea8539a0', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085beb8cb814565-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_7683a3c7a1488326c0a64c36ea8539a0\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000001AEFFC79C60>, 'json_data': {'input': [[791, 2082, 4442, 19678, 264, 502, 4668, 430, 6276, 279, 1887, 311, 2865, 264, 2587, 26384, 2317, 19353, 505, 264, 6683, 3424, 11, 47594, 1202, 4868, 5110, 13, 23212, 11, 502, 7177, 6106, 430, 279, 8292, 12722, 13777, 2225, 2764, 323, 8482, 2587, 26384, 2317, 6989, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019E440>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766BC80> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019EAD0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000001AEFFC7B9C0>, 'json_data': {'input': [[791, 2082, 4442, 2713, 3892, 6989, 311, 6106, 814, 649, 387, 21676, 1511, 304, 7447, 61904, 291, 22484, 555, 25976, 264, 1749, 311, 2867, 5044, 13, 23212, 11, 1521, 6989, 1457, 1397, 3932, 311, 21650, 3345, 1124, 311, 5766, 4754, 5044, 4819, 505, 64610, 4617, 41160, 828, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBF83C0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766B800> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBF8460>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x000001AEFFE45800>, 'json_data': {'input': [[791, 2082, 4442, 2713, 1268, 264, 1887, 11618, 828, 555, 60923, 264, 3230, 3044, 505, 330, 7391, 15942, 1, 311, 330, 34590, 7237, 10794, 1899, 1753, 1359, 18899, 15374, 304, 11850, 828, 47788, 13, 23212, 11, 264, 8767, 12305, 1296, 1162, 706, 1027, 22756, 311, 6106, 430, 279, 1887, 30357, 550, 8699, 828, 3196, 389, 3738, 13186, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AED5BD0410>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED766B260> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBF8230>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'114'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7f68bc646b-zzlvf'), (b'x-envoy-upstream-service-time', b'57'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999952'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_875540033a405062a29ef1e0674efdd8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=6NH5P9SFj5wv3xxAgWHLlin1yGE3bokgV1gjopYkcuQ-1737949479-1.0.1.1-OFqb53dpjbm1AVeXrnLO0dqrZYdOL2y9_JqxoKys9mQue3KoVrUefx7TwISmjri04XA0vIHLKLTnzcnhK7uPmA; path=/; expires=Mon, 27-Jan-25 04:14:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=q0S7CKVE_5efYxSbZDjZFbNEPIQYsO69fGKp0YkwMlA-1737949479569-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bed4eac11012-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:39 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '114'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7f68bc646b-zzlvf'), ('x-envoy-upstream-service-time', '57'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999952'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '2ms'), ('x-request-id', 'req_875540033a405062a29ef1e0674efdd8'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=6NH5P9SFj5wv3xxAgWHLlin1yGE3bokgV1gjopYkcuQ-1737949479-1.0.1.1-OFqb53dpjbm1AVeXrnLO0dqrZYdOL2y9_JqxoKys9mQue3KoVrUefx7TwISmjri04XA0vIHLKLTnzcnhK7uPmA; path=/; expires=Mon, 27-Jan-25 04:14:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=q0S7CKVE_5efYxSbZDjZFbNEPIQYsO69fGKp0YkwMlA-1737949479569-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bed4eac11012-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_875540033a405062a29ef1e0674efdd8\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-3991\\nIssue Summary: QuorumCnxManager Listener port bind retry does not retry DNS lookup\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWe run Zookeeper in a container environment where DNS is not stable. As recommended by the documentation, we set _electionPortBindRetry_ to 0 (keeps retrying forever).\\n\\n\\n\\nOn some instances, we get the following exception in an infinite loop, even though the address already became resolve-able:\\n\\n\\n\\nÂ\\xa0\\n\\n{noformat}\\n\\nzk-2_1  | 2020-11-03 10:57:08,407 [myid:3] - ERROR [ListenerHandler-zk-2.test:3888:QuorumCnxManager$Listener$ListenerHandler@1093] - Exception while listening\\n\\nzk-2_1  | java.net.SocketException: Unresolved address\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.createNewServerSocket(QuorumCnxManager.java:1140)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.acceptConnections(QuorumCnxManager.java:1064)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.run(QuorumCnxManager.java:1033)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.lang.Thread.run(Unknown Source){noformat}\\n\\nZookeeper does not actually retry the DNS resolution, it just keeps using the old failed result.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\nThis happens because the InetSocketAddress is created once and the DNS lookup happens when it is created.\\n\\n\\n\\nThis issue has come up previously in https://issues.apache.org/jira/browse/ZOOKEEPER-1506 but it appears to still happen here.\\n\\n\\n\\nI have attached a repro.tar.gz to help reproduce this issue. Steps:\\n\\n * Untar repro.tar.gz\\n\\n * docker-compose up\\n\\n * See the exception keeps happening for zk-2, not for the others\\n\\n * Open db.test and uncomment the zk-2 line, increment the serial and save\\n\\n * Wait a few seconds for the DNS to refresh\\n\\n * Verify that you can resolve zk-2.test now (dig @172.16.60.2 zk-2.test) but the error keeps appearing\\n\\n\\n\\nI have also attached a patch that resolves this. The patch will retry DNS resolution if the address is still unresolved every time it tries to create the server socket.\\n\\n\\n\\nÂ\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-3160\\nIssue Summary: Custom User SSLContext\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThe Zookeeper libraries currently allow you to set up your SSL Context via system properties such as \"zookeeper.ssl.keyStore.location\" in the X509Util. This covers most simple use cases, where users have software keystores on their harddrive.\\n\\n\\n\\nThere are, however, a few additional scenarios that this doesn\\'t cover. Two possible ones would be:\\n\\n # The user has a hardware keystore, loaded in using PKCS11 or something similar.\\n\\n # The user has no access to the software keystore, but can retrieve an already-constructed SSLContext from their container.\\n\\n\\n\\nFor this, I would propose that the X509Util be extended to allow a user to set a property such as \"zookeeper.ssl.client.context\" to provide a class which supplies a custom SSL context. This gives a lot more flexibility to the ZK client, and allows the user to construct the SSLContext in whatever way they please (which also future proofs the implementation somewhat).\\n\\n\\n\\nI\\'ve already completed this feature, and will put in a PR soon for it.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-4790\\nIssue Summary: TLS Quorum hostname verification breaks in some scenarios\\nIssue Type: Improvement\\nPriority: Minor\\n\\nDescription:\\nCurrently, enabling Quorum TLS will make the server validate SANs client certificates of connecting quorum peers against their reverse DNS address.Â\\xa0\\n\\n\\n\\nÂ\\xa0We have seen this cause issues when running in Kubernetes, due to ip addresses resolving to multiple dns names, when ZooKeeper pods participate in multiple services. \\n\\n\\n\\nSince `InetAddress.getHostAddress()` returns a String, it basically becomes a game of chance which dns name is checked against the cert. \\n\\nThis usually shakes itself loose after a few minutes, when the hostname that gets returned by the reverse lookup randomly changes and all of a sudden matches the certificate... but this is less than ideal.\\n\\n\\n\\nThis has also caused issues in the Strimzi operator as well (see [this issue|https://github.com/strimzi/strimzi-kafka-operator/issues/3099]) - they solved this by pretty much adding anything they can find that might be relevant to the SAN, and a few wildcards on top of that.\\n\\n\\n\\nThis is both, error prone and doesn\\'t really add any relevant extra amount of security, since \"This certificate matches the connecting peer\" shouldn\\'t automatically mean \"this peer should be allowed to connect\".\\n\\nÂ\\xa0\\n\\nÂ\\xa0There are two (probably more) ways to fix this:\\n\\n\\n\\n# Retrieve _all_  reverse entries and check against all of them\\n\\n# The ZK server could verify the SAN against the list of servers ({{{}servers.N{}}}Â\\xa0in the config). A peer should be able to connect on the quorum port if and only if at least one SAN matches at least one of the listed servers.\\n\\n\\n\\nI\\'d argue that the second option is the better one, especially since the java api doesn\\'t even seem to have the option of retrieving all dns entries, but also because it better matches the expressed intent of the ZK admin.\\n\\n\\n\\nAdditionally, it would be nice to have a \"disable client hostname verification\" option that still leaves server hostname verification enabled. Strictly speaking this is a separate issue though, I\\'d be happy to spin that out into a ticket of its own..\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-4753\\nIssue Summary: Explicit handling of DIGEST-MD5 vs GSSAPI in quorum auth\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nThe SASL-based quorum authorizer does not explicitly distinguish between the DIGEST-MD5 and GSSAPI mechanisms: it is simply relying on {{NameCallback}} and {{PasswordCallback}} for authentication with the former and examining Kerberos principals in {{AuthorizeCallback}} for the latter.\\n\\n\\n\\nIt turns out that some SASL/DIGEST-MD5 configurations cause authentication and authorization IDs not to match the expected format, and the DIGEST-MD5-based portions of the quorum test suite to fail with obscure errors. (They can be traced to failures to join the quorum, but only by looking into detailed logs.)\\n\\n\\n\\nWe can use the login module name to determine whether DIGEST-MD5 or GSSAPI is used, and relax the authentication ID check for the former.  As a cleanup, we can keep the password-based credential map empty when Kerberos principals are expected.  Finally, we can adapt tests to ensure \"weirdly-shaped\" credentials only cause authentication failures in the GSSAPI case.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: ZOOKEEPER-4858\\nIssue Summary: Remove the lock contention between snapshotting and the sync operation\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nRemove the synchronized keyword from Zookeeper.takeSnapshot() and  ZookeeperServer.restoreFromSnapshot() API, as it causes lock contention on the ZookeeperServer object with the sync operation. \\n\\n\\n\\nIn ZookeeperServer.java, we have the following\\n\\n{code:java}\\n\\n\\n\\n public synchronized File takeSnapshot(boolean syncSnap, boolean isSevere, boolean fastForwardFromEdits) throws IOException {\\n\\n....\\n\\n}\\n\\n{code}\\n\\n\\n\\nIn ObserverZookeeperServer.java and FollowerZookeeperServer.java, we have the following\\n\\n       \\n\\n{code:java}\\n\\npublic synchronized void sync() {\\n\\n     ...\\n\\n    }\\n\\n\\n\\n{code}\\n\\n\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-4377\\nIssue Summary: KeeperException.create has NullPointerException when low version client requests the high version server\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\n{code:java}\\n\\nblishment complete on server localhost/127.0.0.1:2180, sessionid = 0x1000278adba0129, negotiated timeout = 30000blishment complete on server localhost/127.0.0.1:2180, sessionid = 0x1000278adba0129, negotiated timeout = 30000java.lang.NullPointerException at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.KeeperException.create(KeeperException.java:54) at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538) at site.ycsb.db.zookeeper.ZKClient.insert(ZKClient.java:131) at site.ycsb.DBWrapper.insert(DBWrapper.java:227) at site.ycsb.workloads.CoreWorkload.doInsert(CoreWorkload.java:621) at site.ycsb.ClientThread.run(ClientThread.java:135) at java.lang.Thread.run(Thread.java:748)java.lang.NullPointerExceptionjava.lang.NullPointerException\\n\\n at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.KeeperException.create(KeeperException.java:54) at org.apache.zookeeper.KeeperException.create(KeeperException.java:94) at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538)\\n\\n{code}\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBF82D0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AEFFF20440> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC34D70>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC35090>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AEFFF20440> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AEFFF20440> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFAB20>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFB660>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC35900>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'87'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-5cc9fb545f-pc95r'), (b'x-envoy-upstream-service-time', b'36'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999942'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'x-request-id', b'req_31560002bf45b21551ecce8276418e05'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=sUU1FkWzinJpYBE.7GaP.jSEKBDvoYOQnMGzHdiCL54-1737949480-1.0.1.1-BSDILILKs4Bk1HKuuLLISLlCoC8eDEQNWdVCkPIG1FtTO82eYlIei58ED887p8Htn1leejS8L6e1iaY_oa5ngQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=y62qxvPFrEFc_s9Eh9NyyeR3sdAqgAgb8nYCVWXsWfk-1737949480046-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bed6e85a5fe1-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '87'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-5cc9fb545f-pc95r'), ('x-envoy-upstream-service-time', '36'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999942'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '3ms'), ('x-request-id', 'req_31560002bf45b21551ecce8276418e05'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=sUU1FkWzinJpYBE.7GaP.jSEKBDvoYOQnMGzHdiCL54-1737949480-1.0.1.1-BSDILILKs4Bk1HKuuLLISLlCoC8eDEQNWdVCkPIG1FtTO82eYlIei58ED887p8Htn1leejS8L6e1iaY_oa5ngQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=y62qxvPFrEFc_s9Eh9NyyeR3sdAqgAgb8nYCVWXsWfk-1737949480046-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bed6e85a5fe1-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_31560002bf45b21551ecce8276418e05\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8381\\nIssue Summary: Add support for filtered aggregate calls\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, Drill ignores filters for filtered aggregate calls and returns incorrect results.\\n\\nHere is the example query for which Drill will return incorrect results:\\n\\n{code:sql}\\n\\nSELECT count(n_name) FILTER(WHERE n_regionkey = 1) AS nations_count_in_1_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 2) AS nations_count_in_2_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 3) AS nations_count_in_3_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 4) AS nations_count_in_4_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 0) AS nations_count_in_0_region\\n\\nFROM cp.`tpch/nation.parquet`\\n\\n{code}\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 25                        | 25                        | 25                        | 25                        | 25                        |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nBut the correct result is\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 5                         | 5                         | 5                         | 5                         | 5                         |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nSide note:\\n\\nThe query above could be rewritten using PIVOT:\\n\\n{code:sql}\\n\\nSELECT `1` nations_count_in_1_region, `2` nations_count_in_2_region, `3` nations_count_in_3_region, `4` nations_count_in_4_region, `0` nations_count_in_0_region\\n\\nFROM (SELECT n_name, n_regionkey FROM cp.`tpch/nation.parquet`) \\n\\nPIVOT(count(n_name) FOR n_regionkey IN (0, 1, 2, 3, 4))\\n\\n{code}\\n\\nAnd will return correct results when this issue is fixed and Calcite is updated to 1.33.0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8400\\nIssue Summary: Fix pruning partitions with pushed transitive predicates\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nSee {{TestHivePartitionPruning.prunePartitionsBasedOnTransitivePredicates()}} test for details.\\n\\n\\n\\nThe issue occurs for queries like these:\\n\\n{code:sql}\\n\\nSELECT * FROM hive.partition_pruning_test t1 \\n\\nJOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \\n\\nWHERE t2.`e` IS NOT NULL AND t1.`d` = 1\\n\\n{code}\\n\\n\\n\\nThe expected behavior is to create additional filters based on the existing filters and join conditions. We have a {{TRANSITIVE_CLOSURE}} planning phase, which is responsible for such query transformations, but Drill pushes down filters from the WHERE condition before that phase, so the optimization is not performed.\\n\\n\\n\\nIdeally, we should move rules from the {{TRANSITIVE_CLOSURE}} phase to the {{LOGICAL}} phase so that the planner will choose the most optimal plan, but it wouldn\\'t help until CALCITE-1048 is fixed (it is required to pull predicates when three has {{RelSubset}} nodes).\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8489\\nIssue Summary: Sender memory leak when rpc encode exception\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nWhen encode throw Exception, if encode msg instanceof ReferenceCounted, netty can release msg, but drill convert msg to OutboundRpcMessage, so netty can not release msg. this Â\\xa0causes sender memory leaks\\n\\n\\n\\nexception infoÂ\\xa0\\n\\n{code:java}\\n\\n2024-04-16 16:25:57,998 [DataClient-7] ERROR o.a.d.exec.rpc.RpcExceptionHandler - Exception in RPC communication. Â\\xa0Connection: /10.32.112.138:47924 <--> /10.32.112.138:31012 (data client). Â\\xa0Closing connection.\\n\\nio.netty.handler.codec.EncoderException: org.apache.drill.exec.exception.OutOfMemoryException: Unable to allocate buffer of size 4096 due to memory limit (9223372036854775807). Current allocation: 0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:107)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:881)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:940)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1247)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:173)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:166)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:569)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at java.lang.Thread.run(Thread.java:748)\\n\\nCaused by: org.apache.drill.exec.exception.OutOfMemoryException: Unable to allocate buffer of size 4096 due to memory limit (9223372036854775807). Current allocation: 0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.BaseAllocator.buffer(BaseAllocator.java:245)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.BaseAllocator.buffer(BaseAllocator.java:220)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.DrillByteBufAllocator.buffer(DrillByteBufAllocator.java:55)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.memory.DrillByteBufAllocator.buffer(DrillByteBufAllocator.java:50)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.rpc.RpcEncoder.encode(safeRelease.java:87)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at org.apache.drill.exec.rpc.RpcEncoder.encode(RpcEncoder.java:38)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 at io.netty.handler.codec.MessageToMessageEncoder.write(MessageToMessageEncoder.java:90){code}\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8503\\nIssue Summary: Add Configuration Option to Skip Host Validation for Splunk\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nThis PR adds an option to skip host validation for SSL connections to Splunk.Â\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-4935\\nIssue Summary: Allow drillbits to advertise a configurable host address to Zookeeper\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThere are certain situations, such as running Drill in distributed Docker containers, in which it is desirable to advertise a different hostname to Zookeeper than would be output by INetAddress.getLocalHost().  I propose adding a configuration variable \\'drill.exec.rpc.bit.advertised.host\\' and passing this address to Zookeeper when the configuration variable is populated, otherwise falling back to the present behavior.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: DRILL-8513\\nIssue Summary: Right Hash Join with empty Left table ruturns 0 result\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nDrill returns no results on the right Hash Join if the probe(left) table is empty.\\n\\n\\n\\nThe simplest way to reproduce the issue:\\n\\n\\n\\n1.To force Drill not to use merge join and use the hash join operator instead:\\n\\n{code:java}\\n\\nalter session set planner.enable_mergejoin = false;\\n\\nalter session set planner.enable_nestedloopjoin= false; {code}\\n\\n2. Disable join order optimization to prevent Drill from flipping join tables:\\n\\n{code:java}\\n\\nalter session set planner.enable_join_optimization = false;  {code}\\n\\n3. Execute a query with empty left table outcome:\\n\\n{code:java}\\n\\nSELECT *\\n\\nFROMÂ\\xa0\\n\\nÂ\\xa0 Â\\xa0 (SELECT * FROM (VALUES (1, \\'Max\\', 28),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0(2, \\'Jane\\', 32),\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0(3, \\'Saymon\\', 29)\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0) AS users(id, name, age)\\n\\nÂ\\xa0 Â\\xa0 WHERE false\\n\\nÂ\\xa0 Â\\xa0 ) AS users\\n\\nRIGHT JOINÂ\\xa0\\n\\nÂ\\xa0 Â\\xa0 (VALUES (1, \\'Engineer\\'),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 (2, \\'Doctor\\'),Â\\xa0\\n\\nÂ\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 Â\\xa0 (3, \\'Teacher\\')\\n\\nÂ\\xa0 Â\\xa0 ) AS job(id, title)\\n\\nON users.id = job.idÂ\\xa0{code}\\n\\nExpected result is:\\n\\n||id||name||age||id0||title||\\n\\n|null|null|null|1|Engineer|\\n\\n|null|null|null|2|Doctor|\\n\\n|null|null|null|3|Teacher|\\n\\n\\n\\nBut we get 0 rows.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC37930>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA19A0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC37980>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC37D40>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA19A0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA19A0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC375C0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC37F70>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFE981E0>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'337'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'via', b'envoy-router-7d6bf4769b-gdxwq'), (b'x-envoy-upstream-service-time', b'259'), (b'x-ratelimit-limit-requests', b'3000'), (b'x-ratelimit-limit-tokens', b'1000000'), (b'x-ratelimit-remaining-requests', b'2999'), (b'x-ratelimit-remaining-tokens', b'999951'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'x-request-id', b'req_dce1812aa9b6794808d645739bbc250e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=FPBsT4YSfIEmlL4gi2GmpbfRD_XmDXNMoroH0zW3fH4-1737949480-1.0.1.1-pE3yMcV8gwVrq72S_9XCayWbM_KsTBAdhZ9DSd8cpZTo_2AWbDP0xfHFjJyJQOwMJxXyt_Ec5bt9.TlwXasbzw; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DZJ1ct4vaypCljcgwsH.q.b1xTRsUrCx79xn5N_a634-1737949480166-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bed5adbda996-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-allow-origin', '*'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-model', 'text-embedding-3-small'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '337'), ('openai-version', '2020-10-01'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('via', 'envoy-router-7d6bf4769b-gdxwq'), ('x-envoy-upstream-service-time', '259'), ('x-ratelimit-limit-requests', '3000'), ('x-ratelimit-limit-tokens', '1000000'), ('x-ratelimit-remaining-requests', '2999'), ('x-ratelimit-remaining-tokens', '999951'), ('x-ratelimit-reset-requests', '20ms'), ('x-ratelimit-reset-tokens', '2ms'), ('x-request-id', 'req_dce1812aa9b6794808d645739bbc250e'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=FPBsT4YSfIEmlL4gi2GmpbfRD_XmDXNMoroH0zW3fH4-1737949480-1.0.1.1-pE3yMcV8gwVrq72S_9XCayWbM_KsTBAdhZ9DSd8cpZTo_2AWbDP0xfHFjJyJQOwMJxXyt_Ec5bt9.TlwXasbzw; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=DZJ1ct4vaypCljcgwsH.q.b1xTRsUrCx79xn5N_a634-1737949480166-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bed5adbda996-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_dce1812aa9b6794808d645739bbc250e\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: OPENNLP-1620\\nIssue Summary: It should be possible to remove the allocated ThreadLocal\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nIt should be possible to remove the allocated thread locals, if needed by the user as it is tied to the lifetime of the thread using it.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\n!image-2024-10-08-11-55-15-901.png!\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Evaluate the performance of a document retriever. Given the Git diff and retrieved context, return YES if the context directly or indirectly correlates with the changes in the Git diff. Otherwise, return NO.\\n\\n> Git diff: \\n>>>\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n>>>\\n> Retrieved context:\\n>>>\\nTicket ID: OPENNLP-1702\\nIssue Summary: BratDocumentStream should process files in bratCorpusDir deterministically\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWith the recent addition of {{BratNameSampleStreamFactoryTest}} via OPENNLP-1695, it became obvious (Eval test run), that the code in BratDocumentStream is prone to non-determinism. This stems from the fact that {{java.util.File#listFiles(..)}} does not guarantee any order of the returned elements. \\n\\n\\n\\nA potential fix for achieving determinism again is to sort the result of listFiles(..) alphabetically in ASC order.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1667\\nIssue Summary: Add thread-safe version of ChunkerME\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, ChunkerME is not thread-safe. With OPENNLP-936, a thread-safe version for several related classes was introduced.\\n\\n\\n\\nHowever, this was not done for the Chunker case.\\n\\nLet\\'s introduce and provide ThreadSafeChunkerME.\\n\\n\\n\\n\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1661\\nIssue Summary: Fix custom models being wiped from OpenNLP user.home directory\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nCurrently, a Maven build ({{mvn clean test}}) wipes existing models in the \\'{{user.home/.opennlp}}\\' directory, as the code in {{AbstractDownloadUtilTest#cleanupWhenOnline}} will clean those up before the related methods in {{DownloadUtil}} will be tested.\\n\\n\\n\\nHowever, this causes some headache, if custom-trained models with similar name patterns exist in that directory, as:\\n\\n\\n\\n_wipeExistingModelFiles(\"\\\\-tokens\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-sentence\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-pos\\\\-\");_\\n\\n_wipeExistingModelFiles(\"\\\\-lemmas\\\\-\");_\\n\\n\\n\\nwill be executed. Moreover, this also causes a lot of overhead for dev people, as each run of the whole test suite will clean up either in the target directory of {{opennlp-tools}} module, or even worse, the local \\'{{user.home/.opennlp}}\\' directory, causing at least 128 (32 langs x 4 model types) models to be downloaded (over and over again).\\n\\n\\n\\nAims:\\n\\n* Ensure no (custom) model is accidentally removed from \\'{{user.home/.opennlp}}\\'.\\n\\n* Ensure models downloads aren\\'t repeated if they exist locally & are \"valid\" (_sha512_)\\n\\n* Validate freshly downloaded models AND existing ones to discover broken model files\\n\\n* Reduce download volume required for full (IT) builds\\n\\n* Reduce load for ASF infrastructure\\n\\n* Reduce overall ecological footprint\\n\\n\\n\\nNote: Same applies for \\'ci\\' Maven profile. As long as no \"mvn clean\" is executed, existing models kept in a build\\'s {{target}} folder should not be wiped and not be re-downloaded per test suite execution.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1655\\nIssue Summary: Add constructors in SentenceDetectorME and TokenizerME to inject custom abbreviation dictionary\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nUsers ofÂ\\xa0{{TokenizerME}} and/or {{SentenceDetectorME}} may want to load an additional or custom {{Dictionary}} for abbreviations used in a certain language or domain.\\n\\n\\n\\nHowever, this is not possible right now, at construction time of those classes.\\n\\n\\n\\nLet\\'s fix this by adding an additional constructor providing more flexibility.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: OPENNLP-1600\\nIssue Summary: Ability to disable POS mapper\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nSince version 2.4.0, the OpenNLP includes a mandatory POS tag mapper which either maps UD to Penn POS tags or vice versa.\\n\\n\\n\\nNow, this is a problem if you want to train a custom model on some arbitrary other POS tagset. \\n\\n\\n\\nIt would be great if there was a was to disable the POS mapper. \\n\\n\\n\\nIn fact, I would propose that POS mapping is turned off by default unless a POS mapper is manually supplied to the POS tagger - so stuff would remain backwards compatible.\\n\\n\\n\\nBut at least being able to turn of the mapper and/or to provide a custom mapper would be appreciated.\\n>>>\\n> Relevant (YES / NO):', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'224'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9979'), (b'x-ratelimit-remaining-tokens', b'188278'), (b'x-ratelimit-reset-requests', b'2m55.627s'), (b'x-ratelimit-reset-tokens', b'3.516s'), (b'x-request-id', b'req_2cd8c9d2536ccabd48409ef06d406d20'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=MJHO0iQNOZWjl1I18p3Z3__5efSTO3AvYNDdmV4V6Zo-1737949480-1.0.1.1-Q0rdxVz74_eXp6dSCz7lafCQNGQhPaVkAISeUH9k2o0TgCvEOmJ32ECHIzjrYmLjiWz.Mf.DSPG1hTSZ2H.NBg; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=EKG7OrwqbQwjwwq2dGH1Xm52XOKu3BXuu5Z0wBzjf10-1737949480254-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bed84f33fdb6-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '224'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9979'), ('x-ratelimit-remaining-tokens', '188278'), ('x-ratelimit-reset-requests', '2m55.627s'), ('x-ratelimit-reset-tokens', '3.516s'), ('x-request-id', 'req_2cd8c9d2536ccabd48409ef06d406d20'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=MJHO0iQNOZWjl1I18p3Z3__5efSTO3AvYNDdmV4V6Zo-1737949480-1.0.1.1-Q0rdxVz74_eXp6dSCz7lafCQNGQhPaVkAISeUH9k2o0TgCvEOmJ32ECHIzjrYmLjiWz.Mf.DSPG1hTSZ2H.NBg; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=EKG7OrwqbQwjwwq2dGH1Xm52XOKu3BXuu5Z0wBzjf10-1737949480254-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bed84f33fdb6-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_2cd8c9d2536ccabd48409ef06d406d20\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'176'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9980'), (b'x-ratelimit-remaining-tokens', b'190975'), (b'x-ratelimit-reset-requests', b'2m47.02s'), (b'x-ratelimit-reset-tokens', b'2.707s'), (b'x-request-id', b'req_f0d1fb7faf4ace9d483a844dce8a465e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9oriNmAZU1x6D27.Tmis6MgRvVuGWOC7QnZEkvTrm.o-1737949480-1.0.1.1-ClEP9xj5vQcJLeOZCYLkSyv6bVCKdAws95CdGUKR_7hVpcEehir0ewgPJHbpo2d99BYGVHHEyomoYdeREGQoAQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7v0eeb6qJ2NwF430X_KfCBTvoQxBKlEANBTyGjU2Q7w-1737949480174-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bed7f99a6bff-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC346E0>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA2720> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFC36440>\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED5AA2720> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '176'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9980'), ('x-ratelimit-remaining-tokens', '190975'), ('x-ratelimit-reset-requests', '2m47.02s'), ('x-ratelimit-reset-tokens', '2.707s'), ('x-request-id', 'req_f0d1fb7faf4ace9d483a844dce8a465e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=9oriNmAZU1x6D27.Tmis6MgRvVuGWOC7QnZEkvTrm.o-1737949480-1.0.1.1-ClEP9xj5vQcJLeOZCYLkSyv6bVCKdAws95CdGUKR_7hVpcEehir0ewgPJHbpo2d99BYGVHHEyomoYdeREGQoAQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7v0eeb6qJ2NwF430X_KfCBTvoQxBKlEANBTyGjU2Q7w-1737949480174-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bed7f99a6bff-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_f0d1fb7faf4ace9d483a844dce8a465e\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'156'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9978'), (b'x-ratelimit-remaining-tokens', b'185997'), (b'x-ratelimit-reset-requests', b'3m4.203s'), (b'x-ratelimit-reset-tokens', b'4.2s'), (b'x-request-id', b'req_f8f31df19c48a280883dc7679e1b990b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Su.x00iOTx8ggt0XoPgM2SqejRraRI.sqUXjACfOswY-1737949480-1.0.1.1-x7ONs5siRpKSlCOhDHbep.CIhZdTDKfEdI0lK7EAxGRyyk5CBrDhTwaBet79EoWZKTxlT3gAeV.WJZCkHzPE2g; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=X7PfdByt07GnvB_mKuPp4rpZ0pf7pme29b.yHSKkVas-1737949480242-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bed88872a089-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFAA30>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFBAC0>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '156'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9978'), ('x-ratelimit-remaining-tokens', '185997'), ('x-ratelimit-reset-requests', '3m4.203s'), ('x-ratelimit-reset-tokens', '4.2s'), ('x-request-id', 'req_f8f31df19c48a280883dc7679e1b990b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Su.x00iOTx8ggt0XoPgM2SqejRraRI.sqUXjACfOswY-1737949480-1.0.1.1-x7ONs5siRpKSlCOhDHbep.CIhZdTDKfEdI0lK7EAxGRyyk5CBrDhTwaBet79EoWZKTxlT3gAeV.WJZCkHzPE2g; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=X7PfdByt07GnvB_mKuPp4rpZ0pf7pme29b.yHSKkVas-1737949480242-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bed88872a089-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:openai._base_client:request_id: req_f8f31df19c48a280883dc7679e1b990b\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFBFBBB0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED010> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019C730>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'182'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9977'), (b'x-ratelimit-remaining-tokens', b'186947'), (b'x-ratelimit-reset-requests', b'3m12.5s'), (b'x-ratelimit-reset-tokens', b'3.915s'), (b'x-request-id', b'req_60d752b0101198aa87c10305178bf82c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.IwtNaHjhhgtiA6V35jPkSsC.R8yHq4dIrbRAC8natI-1737949480-1.0.1.1-B8XYkICkql1JJeOts0RLI.4PFYFafIkW3fhPb1XGHQSySmC3w9FgIrQVUh1qGmQP.PPgNQF4FoUFT4x4p2y3kQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=C7mntQWmnAXGcBfmpJK47PeRm4ANXI3cxFAw239BiCU-1737949480610-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bedaf8c9fdb7-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '182'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9977'), ('x-ratelimit-remaining-tokens', '186947'), ('x-ratelimit-reset-requests', '3m12.5s'), ('x-ratelimit-reset-tokens', '3.915s'), ('x-request-id', 'req_60d752b0101198aa87c10305178bf82c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.IwtNaHjhhgtiA6V35jPkSsC.R8yHq4dIrbRAC8natI-1737949480-1.0.1.1-B8XYkICkql1JJeOts0RLI.4PFYFafIkW3fhPb1XGHQSySmC3w9FgIrQVUh1qGmQP.PPgNQF4FoUFT4x4p2y3kQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=C7mntQWmnAXGcBfmpJK47PeRm4ANXI3cxFAw239BiCU-1737949480610-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bedaf8c9fdb7-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_60d752b0101198aa87c10305178bf82c\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'197'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9976'), (b'x-ratelimit-remaining-tokens', b'185441'), (b'x-ratelimit-reset-requests', b'3m21.098s'), (b'x-ratelimit-reset-tokens', b'4.367s'), (b'x-request-id', b'req_4340b0e00a8e6a35b7f4e9b2e6d72897'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=kq6_43uY.E.Ov0j2cG0pJMA.9kzEoJi06h9q4A5tE1k-1737949480-1.0.1.1-nZvB1WBoBky8CcdfUs0dglxrepNOiSZY3b8ZFstUJH97zMo.UiRC2uPBAuk6GnCmTEW0mj66CjnwNKP0ja7Bsg; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ENhxoSXgpo4IztsPo0LLC9PoINXyCjF80TsPMpgYEkY-1737949480669-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bedb0a605e3d-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '197'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9976'), ('x-ratelimit-remaining-tokens', '185441'), ('x-ratelimit-reset-requests', '3m21.098s'), ('x-ratelimit-reset-tokens', '4.367s'), ('x-request-id', 'req_4340b0e00a8e6a35b7f4e9b2e6d72897'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=kq6_43uY.E.Ov0j2cG0pJMA.9kzEoJi06h9q4A5tE1k-1737949480-1.0.1.1-nZvB1WBoBky8CcdfUs0dglxrepNOiSZY3b8ZFstUJH97zMo.UiRC2uPBAuk6GnCmTEW0mj66CjnwNKP0ja7Bsg; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ENhxoSXgpo4IztsPo0LLC9PoINXyCjF80TsPMpgYEkY-1737949480669-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bedb0a605e3d-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_4340b0e00a8e6a35b7f4e9b2e6d72897\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'233'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9974'), (b'x-ratelimit-remaining-tokens', b'181748'), (b'x-ratelimit-reset-requests', b'3m38.186s'), (b'x-ratelimit-reset-tokens', b'5.475s'), (b'x-request-id', b'req_0d830c44e4f6e7fd28abcb053f03de5a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=f591ab7snATozNveLwmKSInjCfpFqrI5bxMRh4dUkPQ-1737949480-1.0.1.1-_IVsASuOg88aSU2fdOFrRTusrjI_eEr_30k.gIkhgY_L6HFTnkgnJGZrrYRs7rXdHvdihD0B8TC19MF.puO2HQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=8hBAIEOta2oV0eAy1UbC5VXhMcZCoNWUosMd_Huu5Mg-1737949480891-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bedc3a02fd26-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:40 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '233'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9974'), ('x-ratelimit-remaining-tokens', '181748'), ('x-ratelimit-reset-requests', '3m38.186s'), ('x-ratelimit-reset-tokens', '5.475s'), ('x-request-id', 'req_0d830c44e4f6e7fd28abcb053f03de5a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=f591ab7snATozNveLwmKSInjCfpFqrI5bxMRh4dUkPQ-1737949480-1.0.1.1-_IVsASuOg88aSU2fdOFrRTusrjI_eEr_30k.gIkhgY_L6HFTnkgnJGZrrYRs7rXdHvdihD0B8TC19MF.puO2HQ; path=/; expires=Mon, 27-Jan-25 04:14:40 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=8hBAIEOta2oV0eAy1UbC5VXhMcZCoNWUosMd_Huu5Mg-1737949480891-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bedc3a02fd26-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_0d830c44e4f6e7fd28abcb053f03de5a\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'164'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9973'), (b'x-ratelimit-remaining-tokens', b'180013'), (b'x-ratelimit-reset-requests', b'3m46.743s'), (b'x-ratelimit-reset-tokens', b'5.995s'), (b'x-request-id', b'req_8b6196258c65e226390af7fbedc83059'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bedcc8b83dd5-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '164', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9973', 'x-ratelimit-remaining-tokens': '180013', 'x-ratelimit-reset-requests': '3m46.743s', 'x-ratelimit-reset-tokens': '5.995s', 'x-request-id': 'req_8b6196258c65e226390af7fbedc83059', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085bedcc8b83dd5-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_8b6196258c65e226390af7fbedc83059\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'154'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9972'), (b'x-ratelimit-remaining-tokens', b'179844'), (b'x-ratelimit-reset-requests', b'3m55.044s'), (b'x-ratelimit-reset-tokens', b'6.046s'), (b'x-request-id', b'req_232fc1e8fbf66fae62c25cfc24e10a60'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=f8BIVwe1ZkfyfDwsSfc5q7Ki6saMy6ijr0t4Of1eqJ0-1737949481-1.0.1.1-WFvO2BzoSjYPJr_Fs_.fru5sDBvlyscdzFcgqpCoz2Y50YXvUyGnW6cvfPFQIVQsyo6EmhnEqOdus7ArRugRJA; path=/; expires=Mon, 27-Jan-25 04:14:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7dJG6_eThtPmneyCR0vbcpUqLgzGjHALNXybMefLTTo-1737949481237-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bedc0a75879f-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:41 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '154'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9972'), ('x-ratelimit-remaining-tokens', '179844'), ('x-ratelimit-reset-requests', '3m55.044s'), ('x-ratelimit-reset-tokens', '6.046s'), ('x-request-id', 'req_232fc1e8fbf66fae62c25cfc24e10a60'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=f8BIVwe1ZkfyfDwsSfc5q7Ki6saMy6ijr0t4Of1eqJ0-1737949481-1.0.1.1-WFvO2BzoSjYPJr_Fs_.fru5sDBvlyscdzFcgqpCoz2Y50YXvUyGnW6cvfPFQIVQsyo6EmhnEqOdus7ArRugRJA; path=/; expires=Mon, 27-Jan-25 04:14:41 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7dJG6_eThtPmneyCR0vbcpUqLgzGjHALNXybMefLTTo-1737949481237-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bedc0a75879f-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_232fc1e8fbf66fae62c25cfc24e10a60\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'209'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9971'), (b'x-ratelimit-remaining-tokens', b'179746'), (b'x-ratelimit-reset-requests', b'4m3.194s'), (b'x-ratelimit-reset-tokens', b'6.075s'), (b'x-request-id', b'req_bb5c15d6cbd06b15240e1106a0a06bcc'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bee1fc8e3dd5-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '209', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9971', 'x-ratelimit-remaining-tokens': '179746', 'x-ratelimit-reset-requests': '4m3.194s', 'x-ratelimit-reset-tokens': '6.075s', 'x-request-id': 'req_bb5c15d6cbd06b15240e1106a0a06bcc', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085bee1fc8e3dd5-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_bb5c15d6cbd06b15240e1106a0a06bcc\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1763'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9975'), (b'x-ratelimit-remaining-tokens', b'183951'), (b'x-ratelimit-reset-requests', b'3m29.693s'), (b'x-ratelimit-reset-tokens', b'4.814s'), (b'x-request-id', b'req_d196c1380ef1c3fa542509e64402eb4d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=gNq9LgEPVu0GtVE1XunRRM819_QMwnqkqmlxPdjeLFY-1737949482-1.0.1.1-OxPitcNfjdBoterOZKpdRvHXpWMrs26EKLsA595TyKZo7rkCE0MVWO4zxffKnxeBNuGpm_xwLQC29PjmeMIfVQ; path=/; expires=Mon, 27-Jan-25 04:14:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=7uC9rFLo04Mf0y5o51x5IG6XAP2Jxsklhnrr2dNUEww-1737949482318-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bedb1fe8a3e6-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:42 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1763'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9975'), ('x-ratelimit-remaining-tokens', '183951'), ('x-ratelimit-reset-requests', '3m29.693s'), ('x-ratelimit-reset-tokens', '4.814s'), ('x-request-id', 'req_d196c1380ef1c3fa542509e64402eb4d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=gNq9LgEPVu0GtVE1XunRRM819_QMwnqkqmlxPdjeLFY-1737949482-1.0.1.1-OxPitcNfjdBoterOZKpdRvHXpWMrs26EKLsA595TyKZo7rkCE0MVWO4zxffKnxeBNuGpm_xwLQC29PjmeMIfVQ; path=/; expires=Mon, 27-Jan-25 04:14:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=7uC9rFLo04Mf0y5o51x5IG6XAP2Jxsklhnrr2dNUEww-1737949482318-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bedb1fe8a3e6-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_d196c1380ef1c3fa542509e64402eb4d\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'191'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9970'), (b'x-ratelimit-remaining-tokens', b'182592'), (b'x-ratelimit-reset-requests', b'4m10.756s'), (b'x-ratelimit-reset-tokens', b'5.222s'), (b'x-request-id', b'req_c1eb61cff14fd99af8dfc12052b8c5b5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bee8db413dd5-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '191', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9970', 'x-ratelimit-remaining-tokens': '182592', 'x-ratelimit-reset-requests': '4m10.756s', 'x-ratelimit-reset-tokens': '5.222s', 'x-request-id': 'req_c1eb61cff14fd99af8dfc12052b8c5b5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085bee8db413dd5-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_c1eb61cff14fd99af8dfc12052b8c5b5\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and additional context provided. If the context is relevant, include it in the commit body. Use IDs, names, or titles to reference relevant contexts for brevity. Including multiple contexts is allowed.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff 1:\\ndiff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\nindex c4e42c94b93..e2fad7560e3 100644\\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n@@ -53,24 +53,29 @@ public static void registerCommands(CommandFactory factory) {\\n   /** merge multiple files together */\\n   public static class Merge extends FsCommand {\\n     public static final String NAME = \"getmerge\";    \\n-    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n+    public static final String USAGE = \"[-nl] [-skip-empty-file] \"\\n+        + \"<src> <localdst>\";\\n     public static final String DESCRIPTION =\\n-      \"Get all the files in the directories that \" +\\n-      \"match the source file pattern and merge and sort them to only \" +\\n-      \"one file on local fs. <src> is kept.\\\\n\" +\\n-      \"-nl: Add a newline character at the end of each file.\";\\n+        \"Get all the files in the directories that \"\\n+        + \"match the source file pattern and merge and sort them to only \"\\n+        + \"one file on local fs. <src> is kept.\\\\n\"\\n+        + \"-nl: Add a newline character at the end of each file.\\\\n\"\\n+        + \"-skip-empty-file: Do not add new line character for empty file.\";\\n \\n     protected PathData dst = null;\\n     protected String delimiter = null;\\n+    private boolean skipEmptyFileDelimiter;\\n     protected List<PathData> srcs = null;\\n \\n     @Override\\n     protected void processOptions(LinkedList<String> args) throws IOException {\\n       try {\\n-        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n+        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\",\\n+            \"skip-empty-file\");\\n         cf.parse(args);\\n \\n         delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n+        skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n \\n         dst = new PathData(new URI(args.removeLast()), getConf());\\n         if (dst.exists && dst.stat.isDirectory()) {\\n@@ -92,21 +97,26 @@ protected void processArguments(LinkedList<PathData> items)\\n       FSDataOutputStream out = dst.fs.create(dst.path);\\n       try {\\n         for (PathData src : srcs) {\\n-          FSDataInputStream in = src.fs.open(src.path);\\n-          try {\\n-            IOUtils.copyBytes(in, out, getConf(), false);\\n-            if (delimiter != null) {\\n-              out.write(delimiter.getBytes(\"UTF-8\"));\\n+          if (src.stat.getLen() != 0) {\\n+            try (FSDataInputStream in = src.fs.open(src.path)) {\\n+              IOUtils.copyBytes(in, out, getConf(), false);\\n+              writeDelimiter(out);\\n             }\\n-          } finally {\\n-            in.close();\\n+          } else if (!skipEmptyFileDelimiter) {\\n+            writeDelimiter(out);\\n           }\\n         }\\n       } finally {\\n         out.close();\\n-      }      \\n+      }\\n     }\\n- \\n+\\n+    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n+      if (delimiter != null) {\\n+        out.write(delimiter.getBytes(\"UTF-8\"));\\n+      }\\n+    }\\n+\\n     @Override\\n     protected void processNonexistentPath(PathData item) throws IOException {\\n       exitCode = 1; // flag that a path is bad\\n\\n\\nAdditional context 1:\\nTicket ID: HADOOP-12657\\nIssue Summary: Add a option to skip newline on empty files with getMerge -nl\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nHello everyone,\\n\\nI recently was in the need of using the new line option -nl with getMerge because the files I needed to merge simply didn\\'t had one. I was merging all the files from one directory and unfortunately this directory also included empty files, which effectively led to multiple newlines append after some files. I needed to remove them manually afterwards.\\n\\nIn this situation it is maybe good to have another argument that allows skipping empty files.\\nThing one could try to implement this feature:\\n\\nThe call for IOUtils.copyBytes(in, out, getConf(), false); doesn\\'t\\nreturn the number of bytes copied which would be convenient as one could\\nskip append the new line when 0 bytes where copied or one would check the file size before.\\n\\nI posted this Idea on the mailing list http://mail-archives.apache.org/mod_mbox/hadoop-user/201507.mbox/%3C55B25140.3060005%40trivago.com%3E but I didn\\'t really get many responses, so I thought I my try this way.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 1: \\n\\ncommit message 1: feat: add option to skip newlines for empty files in getmerge command\\n\\nAdded a new `-skip-empty-file` option to the `getmerge` command in CopyCommands. This prevents adding newline characters when merging directories that contain empty files, addressing the issue described in HADOOP-12657. Updated the command description, usage, and logic to support the new flag.\\n\\nGit diff 2:\\ndiff --git a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\nindex 091743ebd..a570d3d17 100644\\n--- a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n+++ b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n@@ -29,6 +29,7 @@ import org.apache.activemq.util.ByteSequence;\\n public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n \\n     public static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\n+    private static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\n \\n     static {\\n         Constructor constructor = null;\\n@@ -243,7 +244,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n             int rc = 0;\\n             bs.writeBoolean(true);\\n             rc += tightMarshalString1(o.getClass().getName(), bs);\\n-            rc += tightMarshalString1(o.getMessage(), bs);\\n+            rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 rc += 2;\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n@@ -264,7 +265,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n                                           BooleanStream bs) throws IOException {\\n         if (bs.readBoolean()) {\\n             tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n-            tightMarshalString2(o.getMessage(), dataOut, bs);\\n+            tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -550,7 +551,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         dataOut.writeBoolean(o != null);\\n         if (o != null) {\\n             looseMarshalString(o.getClass().getName(), dataOut);\\n-            looseMarshalString(o.getMessage(), dataOut);\\n+            looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -641,4 +642,10 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         }\\n         return rc;\\n     }\\n+    \\n+    protected String cutMessageIfNeeded(final String message) {\\n+        return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE)?\\n+            message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n+            \\n+    }\\n }\\n\\n\\nAdditional context 2:\\nTicket ID: AMQ-6894\\nIssue Summary: Excessive number of connections by failover transport with priorityBackup\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nMy clients connect to AMQ with this connection string:\\r\\n\\r\\n(tcp://amq1:61616,tcp://amq2:61616)?randomize=false&priorityBackup=true\\r\\n\\r\\n\\xa0It works - for some time. But sooner or later my AMQ server becomes unresponsive because the host it runs on runs out of resources (threads).\\r\\n\\r\\nSuddenly AMQ Server log explodes with the messages like:\\r\\n\\r\\n{code}\\r\\n2018-01-26 09:26:16,909 | WARN\\xa0 | Failed to register MBean org.apache.activemq :type=Broker,brokerName=activemq-vm-primary,connector=clientConnectors,connect\\r\\n\\r\\norName=default,connectionViewType=clientId,connectionName=ID_ca8f70e115d0-3708\\r\\n\\r\\n7-1516883370639-0_22 | org.apache.activemq.broker.jmx.ManagedTransportConnecti\\r\\n\\r\\non | ActiveMQ Transport: tcp:///172.10.7.56:55548@61616\\r\\n\\r\\n2018-01-26 09:26:21,375 | WARN\\xa0 | Ignoring ack received before dispatch; result of failover with an outstanding ack. Acked messages will be replayed if present on this broker. Ignored ack: MessageAck \\\\{commandId = 157, responseRequired = false, ackType = 2, consumerId = ID:ca8f70e115d0-37087-1516883370639-1:22:10:1, firstMessageId = ID:a95345a9c0df-33771-1516883685728-1:17:5:1:23, lastMessageId = ID:a95345a9c0df-33771-1516883685728-1:17:5:1:23, destination = queue://MY_QUEUE_OUT, transactionId = null, messageCount = 1, poisonCause = null} | org.apache.activemq.broker.region.PrefetchSubscription | ActiveMQ Transport: tcp:///172.16.6.56:55464@61616\\r\\n\\r\\n2018-01-26 09:26:39,211 | WARN\\xa0 | Transport Connection to: tcp://172.10.6.56:55860 failed: java.net.SocketException: Connection reset | org.apache.activemq.broker.TransportConnection.Transport | ActiveMQ InactivityMonitor Worker\\r\\n\\r\\n2018-01-26 09:26:47,175 | WARN\\xa0 | Transport Connection to: tcp://172.10.6.56:57012 failed: java.net.SocketException: Broken pipe (Write failed) | org.apache.activemq.broker.TransportConnection.Transport | ActiveMQ InactivityMonitor Worker\\r\\n{code}\\r\\n\\r\\nAfter short period of time AMQ server comes out of resources with \"java.lang.OutOfMemoryError: unable to create new native thread\" error. The AMQ service process in this case has a huge number of threads (some thousands)\\r\\n\\r\\n\\xa0\\r\\n\\r\\nThe client side log contains a lot of reconnection attempts messages like:\\r\\n\\r\\n{code}\\r\\n2018-01-26 00:10:31,387 WARN\\xa0\\xa0\\xa0 [\\\\{{bundle.name,org.apache.activemq.activemq-osgi}{bundle.version,5.14.1}\\\\{bundle.id,181}}]\\xa0\\xa0\\xa0\\xa0 [null]\\xa0 org.apache.activemq.transport.failover.FailoverTransport\\xa0 \\xa0\\xa0\\xa0\\xa0Failed to connect to [tcp://activemq-vm-primary:61616, tcp://activemq-vm-secondary:61616] after: 810 attempt(s) continuing to retry.\\r\\n{code}\\r\\n\\r\\nIt seems that client creates a huge number of connections by failover retry and after some time kills the server.\\r\\n\\r\\nIssue looks very similar to described in https://issues.apache.org/jira/browse/AMQ-6603, however server isn\\'t configured with access control settings.\\r\\n\\r\\nI found the description of similar problem into [http://activemq.2283324.n4.nabble.com/ActiveMQ-5-2-OutOfMemoryError-unable-to-create-new-native-thread-td2366585.html],\\xa0 but without concrete suggestion.\\r\\n\\r\\n\\xa0\\r\\n\\r\\nPart of server log is attached\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 2: \\n\\nCommit message 2: fix: limit exception message size to prevent resource exhaustion\\n\\nIntroduced a `MAX_EXCEPTION_MESSAGE_SIZE` constant (1024 characters) and added logic to truncate overly long exception messages in `BaseDataStreamMarshaller`. This prevents excessive memory and resource usage due to unbounded exception message sizes, addressing the issue in AMQ-6894.\\n\\nGit diff 3:\\ndiff --git a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\nindex ca38c0c319..fbaeaebcb8 100644\\n--- a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n+++ b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n@@ -19,20 +19,13 @@ package org.apache.cassandra.hints;\\n \\n import java.util.concurrent.atomic.AtomicBoolean;\\n \\n-import org.apache.cassandra.gms.ApplicationState;\\n-import org.apache.cassandra.gms.Gossiper;\\n-import org.apache.cassandra.schema.Schema;\\n-\\n-import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\n-\\n /**\\n  * A simple dispatch trigger that\\'s being run every 10 seconds.\\n  *\\n  * Goes through all hint stores and schedules for dispatch all the hints for hosts that are:\\n  * 1. Not currently scheduled for dispatch, and\\n  * 2. Either have some hint files, or an active hint writer, and\\n- * 3. Are live, and\\n- * 4. Have matching schema versions\\n+ * 3. Are live\\n  *\\n  * What does triggering a hints store for dispatch mean?\\n  * - If there are existing hint files, it means submitting them for dispatch;\\n@@ -65,7 +58,6 @@ final class HintsDispatchTrigger implements Runnable\\n                .filter(store -> !isScheduled(store))\\n                .filter(HintsStore::isLive)\\n                .filter(store -> store.isWriting() || store.hasFiles())\\n-               .filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address())))\\n                .forEach(this::schedule);\\n     }\\n \\n\\n\\nAdditional context 3:\\nTicket ID: CASSANDRA-20188\\nIssue Summary: Allow hint delivery during schema mismatch\\nIssue Type: Bug\\nPriority: Normal\\n\\nDescription:\\nIn CASSANDRA-2083 we made hints require schema agreement to avoid a flood of errors in case the table the hints were destined for did not yet exist.  This, however, has other undesirable effects, such as making keeping upgrades in a mixed mode over a longer period of time less tenable.  We should still try to deliver hints and back off if the destination table doesn\\'t exist.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 3: \\n\\nCommit message 3: fix: allow hint delivery during schema mismatch\\n\\nRemoved schema version checks in `HintsDispatchTrigger` to enable hint delivery even during schema mismatches. This change ensures smoother operations in mixed-mode upgrades by allowing hint dispatch while backing off if the destination table does not exist, addressing issue CASSANDRA-20188.\\n\\nGit diff 4:\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\nAdditional context 4:\\nTicket ID: DRILL-8381\\nIssue Summary: Add support for filtered aggregate calls\\nIssue Type: New Feature\\nPriority: Major\\n\\nDescription:\\nCurrently, Drill ignores filters for filtered aggregate calls and returns incorrect results.\\n\\nHere is the example query for which Drill will return incorrect results:\\n\\n{code:sql}\\n\\nSELECT count(n_name) FILTER(WHERE n_regionkey = 1) AS nations_count_in_1_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 2) AS nations_count_in_2_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 3) AS nations_count_in_3_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 4) AS nations_count_in_4_region,\\n\\ncount(n_name) FILTER(WHERE n_regionkey = 0) AS nations_count_in_0_region\\n\\nFROM cp.`tpch/nation.parquet`\\n\\n{code}\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 25                        | 25                        | 25                        | 25                        | 25                        |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nBut the correct result is\\n\\n{noformat}\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| nations_count_in_1_region | nations_count_in_2_region | nations_count_in_3_region | nations_count_in_4_region | nations_count_in_0_region |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n| 5                         | 5                         | 5                         | 5                         | 5                         |\\n\\n+---------------------------+---------------------------+---------------------------+---------------------------+---------------------------+\\n\\n{noformat}\\n\\nSide note:\\n\\nThe query above could be rewritten using PIVOT:\\n\\n{code:sql}\\n\\nSELECT `1` nations_count_in_1_region, `2` nations_count_in_2_region, `3` nations_count_in_3_region, `4` nations_count_in_4_region, `0` nations_count_in_0_region\\n\\nFROM (SELECT n_name, n_regionkey FROM cp.`tpch/nation.parquet`) \\n\\nPIVOT(count(n_name) FOR n_regionkey IN (0, 1, 2, 3, 4))\\n\\n{code}\\n\\nAnd will return correct results when this issue is fixed and Calcite is updated to 1.33.0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: DRILL-8400\\nIssue Summary: Fix pruning partitions with pushed transitive predicates\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nSee {{TestHivePartitionPruning.prunePartitionsBasedOnTransitivePredicates()}} test for details.\\n\\n\\n\\nThe issue occurs for queries like these:\\n\\n{code:sql}\\n\\nSELECT * FROM hive.partition_pruning_test t1 \\n\\nJOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \\n\\nWHERE t2.`e` IS NOT NULL AND t1.`d` = 1\\n\\n{code}\\n\\n\\n\\nThe expected behavior is to create additional filters based on the existing filters and join conditions. We have a {{TRANSITIVE_CLOSURE}} planning phase, which is responsible for such query transformations, but Drill pushes down filters from the WHERE condition before that phase, so the optimization is not performed.\\n\\n\\n\\nIdeally, we should move rules from the {{TRANSITIVE_CLOSURE}} phase to the {{LOGICAL}} phase so that the planner will choose the most optimal plan, but it wouldn\\'t help until CALCITE-1048 is fixed (it is required to pull predicates when three has {{RelSubset}} nodes).\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit type 4: refactor\\n\\nCommit message 4:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and additional context provided. If the context is relevant, include it in the commit body. Use IDs, names, or titles to reference relevant contexts for brevity. Including multiple contexts is allowed.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff 1:\\ndiff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\nindex c4e42c94b93..e2fad7560e3 100644\\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n@@ -53,24 +53,29 @@ public static void registerCommands(CommandFactory factory) {\\n   /** merge multiple files together */\\n   public static class Merge extends FsCommand {\\n     public static final String NAME = \"getmerge\";    \\n-    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n+    public static final String USAGE = \"[-nl] [-skip-empty-file] \"\\n+        + \"<src> <localdst>\";\\n     public static final String DESCRIPTION =\\n-      \"Get all the files in the directories that \" +\\n-      \"match the source file pattern and merge and sort them to only \" +\\n-      \"one file on local fs. <src> is kept.\\\\n\" +\\n-      \"-nl: Add a newline character at the end of each file.\";\\n+        \"Get all the files in the directories that \"\\n+        + \"match the source file pattern and merge and sort them to only \"\\n+        + \"one file on local fs. <src> is kept.\\\\n\"\\n+        + \"-nl: Add a newline character at the end of each file.\\\\n\"\\n+        + \"-skip-empty-file: Do not add new line character for empty file.\";\\n \\n     protected PathData dst = null;\\n     protected String delimiter = null;\\n+    private boolean skipEmptyFileDelimiter;\\n     protected List<PathData> srcs = null;\\n \\n     @Override\\n     protected void processOptions(LinkedList<String> args) throws IOException {\\n       try {\\n-        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n+        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\",\\n+            \"skip-empty-file\");\\n         cf.parse(args);\\n \\n         delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n+        skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n \\n         dst = new PathData(new URI(args.removeLast()), getConf());\\n         if (dst.exists && dst.stat.isDirectory()) {\\n@@ -92,21 +97,26 @@ protected void processArguments(LinkedList<PathData> items)\\n       FSDataOutputStream out = dst.fs.create(dst.path);\\n       try {\\n         for (PathData src : srcs) {\\n-          FSDataInputStream in = src.fs.open(src.path);\\n-          try {\\n-            IOUtils.copyBytes(in, out, getConf(), false);\\n-            if (delimiter != null) {\\n-              out.write(delimiter.getBytes(\"UTF-8\"));\\n+          if (src.stat.getLen() != 0) {\\n+            try (FSDataInputStream in = src.fs.open(src.path)) {\\n+              IOUtils.copyBytes(in, out, getConf(), false);\\n+              writeDelimiter(out);\\n             }\\n-          } finally {\\n-            in.close();\\n+          } else if (!skipEmptyFileDelimiter) {\\n+            writeDelimiter(out);\\n           }\\n         }\\n       } finally {\\n         out.close();\\n-      }      \\n+      }\\n     }\\n- \\n+\\n+    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n+      if (delimiter != null) {\\n+        out.write(delimiter.getBytes(\"UTF-8\"));\\n+      }\\n+    }\\n+\\n     @Override\\n     protected void processNonexistentPath(PathData item) throws IOException {\\n       exitCode = 1; // flag that a path is bad\\n\\n\\nAdditional context 1:\\nTicket ID: HADOOP-12657\\nIssue Summary: Add a option to skip newline on empty files with getMerge -nl\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nHello everyone,\\n\\nI recently was in the need of using the new line option -nl with getMerge because the files I needed to merge simply didn\\'t had one. I was merging all the files from one directory and unfortunately this directory also included empty files, which effectively led to multiple newlines append after some files. I needed to remove them manually afterwards.\\n\\nIn this situation it is maybe good to have another argument that allows skipping empty files.\\nThing one could try to implement this feature:\\n\\nThe call for IOUtils.copyBytes(in, out, getConf(), false); doesn\\'t\\nreturn the number of bytes copied which would be convenient as one could\\nskip append the new line when 0 bytes where copied or one would check the file size before.\\n\\nI posted this Idea on the mailing list http://mail-archives.apache.org/mod_mbox/hadoop-user/201507.mbox/%3C55B25140.3060005%40trivago.com%3E but I didn\\'t really get many responses, so I thought I my try this way.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 1: \\n\\ncommit message 1: feat: add option to skip newlines for empty files in getmerge command\\n\\nAdded a new `-skip-empty-file` option to the `getmerge` command in CopyCommands. This prevents adding newline characters when merging directories that contain empty files, addressing the issue described in HADOOP-12657. Updated the command description, usage, and logic to support the new flag.\\n\\nGit diff 2:\\ndiff --git a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\nindex 091743ebd..a570d3d17 100644\\n--- a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n+++ b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n@@ -29,6 +29,7 @@ import org.apache.activemq.util.ByteSequence;\\n public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n \\n     public static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\n+    private static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\n \\n     static {\\n         Constructor constructor = null;\\n@@ -243,7 +244,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n             int rc = 0;\\n             bs.writeBoolean(true);\\n             rc += tightMarshalString1(o.getClass().getName(), bs);\\n-            rc += tightMarshalString1(o.getMessage(), bs);\\n+            rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 rc += 2;\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n@@ -264,7 +265,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n                                           BooleanStream bs) throws IOException {\\n         if (bs.readBoolean()) {\\n             tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n-            tightMarshalString2(o.getMessage(), dataOut, bs);\\n+            tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -550,7 +551,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         dataOut.writeBoolean(o != null);\\n         if (o != null) {\\n             looseMarshalString(o.getClass().getName(), dataOut);\\n-            looseMarshalString(o.getMessage(), dataOut);\\n+            looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -641,4 +642,10 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         }\\n         return rc;\\n     }\\n+    \\n+    protected String cutMessageIfNeeded(final String message) {\\n+        return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE)?\\n+            message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n+            \\n+    }\\n }\\n\\n\\nAdditional context 2:\\nTicket ID: AMQ-6894\\nIssue Summary: Excessive number of connections by failover transport with priorityBackup\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nMy clients connect to AMQ with this connection string:\\r\\n\\r\\n(tcp://amq1:61616,tcp://amq2:61616)?randomize=false&priorityBackup=true\\r\\n\\r\\n\\xa0It works - for some time. But sooner or later my AMQ server becomes unresponsive because the host it runs on runs out of resources (threads).\\r\\n\\r\\nSuddenly AMQ Server log explodes with the messages like:\\r\\n\\r\\n{code}\\r\\n2018-01-26 09:26:16,909 | WARN\\xa0 | Failed to register MBean org.apache.activemq :type=Broker,brokerName=activemq-vm-primary,connector=clientConnectors,connect\\r\\n\\r\\norName=default,connectionViewType=clientId,connectionName=ID_ca8f70e115d0-3708\\r\\n\\r\\n7-1516883370639-0_22 | org.apache.activemq.broker.jmx.ManagedTransportConnecti\\r\\n\\r\\non | ActiveMQ Transport: tcp:///172.10.7.56:55548@61616\\r\\n\\r\\n2018-01-26 09:26:21,375 | WARN\\xa0 | Ignoring ack received before dispatch; result of failover with an outstanding ack. Acked messages will be replayed if present on this broker. Ignored ack: MessageAck \\\\{commandId = 157, responseRequired = false, ackType = 2, consumerId = ID:ca8f70e115d0-37087-1516883370639-1:22:10:1, firstMessageId = ID:a95345a9c0df-33771-1516883685728-1:17:5:1:23, lastMessageId = ID:a95345a9c0df-33771-1516883685728-1:17:5:1:23, destination = queue://MY_QUEUE_OUT, transactionId = null, messageCount = 1, poisonCause = null} | org.apache.activemq.broker.region.PrefetchSubscription | ActiveMQ Transport: tcp:///172.16.6.56:55464@61616\\r\\n\\r\\n2018-01-26 09:26:39,211 | WARN\\xa0 | Transport Connection to: tcp://172.10.6.56:55860 failed: java.net.SocketException: Connection reset | org.apache.activemq.broker.TransportConnection.Transport | ActiveMQ InactivityMonitor Worker\\r\\n\\r\\n2018-01-26 09:26:47,175 | WARN\\xa0 | Transport Connection to: tcp://172.10.6.56:57012 failed: java.net.SocketException: Broken pipe (Write failed) | org.apache.activemq.broker.TransportConnection.Transport | ActiveMQ InactivityMonitor Worker\\r\\n{code}\\r\\n\\r\\nAfter short period of time AMQ server comes out of resources with \"java.lang.OutOfMemoryError: unable to create new native thread\" error. The AMQ service process in this case has a huge number of threads (some thousands)\\r\\n\\r\\n\\xa0\\r\\n\\r\\nThe client side log contains a lot of reconnection attempts messages like:\\r\\n\\r\\n{code}\\r\\n2018-01-26 00:10:31,387 WARN\\xa0\\xa0\\xa0 [\\\\{{bundle.name,org.apache.activemq.activemq-osgi}{bundle.version,5.14.1}\\\\{bundle.id,181}}]\\xa0\\xa0\\xa0\\xa0 [null]\\xa0 org.apache.activemq.transport.failover.FailoverTransport\\xa0 \\xa0\\xa0\\xa0\\xa0Failed to connect to [tcp://activemq-vm-primary:61616, tcp://activemq-vm-secondary:61616] after: 810 attempt(s) continuing to retry.\\r\\n{code}\\r\\n\\r\\nIt seems that client creates a huge number of connections by failover retry and after some time kills the server.\\r\\n\\r\\nIssue looks very similar to described in https://issues.apache.org/jira/browse/AMQ-6603, however server isn\\'t configured with access control settings.\\r\\n\\r\\nI found the description of similar problem into [http://activemq.2283324.n4.nabble.com/ActiveMQ-5-2-OutOfMemoryError-unable-to-create-new-native-thread-td2366585.html],\\xa0 but without concrete suggestion.\\r\\n\\r\\n\\xa0\\r\\n\\r\\nPart of server log is attached\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 2: \\n\\nCommit message 2: fix: limit exception message size to prevent resource exhaustion\\n\\nIntroduced a `MAX_EXCEPTION_MESSAGE_SIZE` constant (1024 characters) and added logic to truncate overly long exception messages in `BaseDataStreamMarshaller`. This prevents excessive memory and resource usage due to unbounded exception message sizes, addressing the issue in AMQ-6894.\\n\\nGit diff 3:\\ndiff --git a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\nindex ca38c0c319..fbaeaebcb8 100644\\n--- a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n+++ b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n@@ -19,20 +19,13 @@ package org.apache.cassandra.hints;\\n \\n import java.util.concurrent.atomic.AtomicBoolean;\\n \\n-import org.apache.cassandra.gms.ApplicationState;\\n-import org.apache.cassandra.gms.Gossiper;\\n-import org.apache.cassandra.schema.Schema;\\n-\\n-import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\n-\\n /**\\n  * A simple dispatch trigger that\\'s being run every 10 seconds.\\n  *\\n  * Goes through all hint stores and schedules for dispatch all the hints for hosts that are:\\n  * 1. Not currently scheduled for dispatch, and\\n  * 2. Either have some hint files, or an active hint writer, and\\n- * 3. Are live, and\\n- * 4. Have matching schema versions\\n+ * 3. Are live\\n  *\\n  * What does triggering a hints store for dispatch mean?\\n  * - If there are existing hint files, it means submitting them for dispatch;\\n@@ -65,7 +58,6 @@ final class HintsDispatchTrigger implements Runnable\\n                .filter(store -> !isScheduled(store))\\n                .filter(HintsStore::isLive)\\n                .filter(store -> store.isWriting() || store.hasFiles())\\n-               .filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address())))\\n                .forEach(this::schedule);\\n     }\\n \\n\\n\\nAdditional context 3:\\nTicket ID: CASSANDRA-20188\\nIssue Summary: Allow hint delivery during schema mismatch\\nIssue Type: Bug\\nPriority: Normal\\n\\nDescription:\\nIn CASSANDRA-2083 we made hints require schema agreement to avoid a flood of errors in case the table the hints were destined for did not yet exist.  This, however, has other undesirable effects, such as making keeping upgrades in a mixed mode over a longer period of time less tenable.  We should still try to deliver hints and back off if the destination table doesn\\'t exist.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 3: \\n\\nCommit message 3: fix: allow hint delivery during schema mismatch\\n\\nRemoved schema version checks in `HintsDispatchTrigger` to enable hint delivery even during schema mismatches. This change ensures smoother operations in mixed-mode upgrades by allowing hint dispatch while backing off if the destination table does not exist, addressing issue CASSANDRA-20188.\\n\\nGit diff 4:\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\nAdditional context 4:\\nTicket ID: ZOOKEEPER-3991\\nIssue Summary: QuorumCnxManager Listener port bind retry does not retry DNS lookup\\nIssue Type: Bug\\nPriority: Minor\\n\\nDescription:\\nWe run Zookeeper in a container environment where DNS is not stable. As recommended by the documentation, we set _electionPortBindRetry_ to 0 (keeps retrying forever).\\n\\n\\n\\nOn some instances, we get the following exception in an infinite loop, even though the address already became resolve-able:\\n\\n\\n\\nÂ\\xa0\\n\\n{noformat}\\n\\nzk-2_1  | 2020-11-03 10:57:08,407 [myid:3] - ERROR [ListenerHandler-zk-2.test:3888:QuorumCnxManager$Listener$ListenerHandler@1093] - Exception while listening\\n\\nzk-2_1  | java.net.SocketException: Unresolved address\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.net.ServerSocket.bind(Unknown Source)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.createNewServerSocket(QuorumCnxManager.java:1140)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.acceptConnections(QuorumCnxManager.java:1064)\\n\\nzk-2_1  | \\tat org.apache.zookeeper.server.quorum.QuorumCnxManager$Listener$ListenerHandler.run(QuorumCnxManager.java:1033)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.FutureTask.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\\n\\nzk-2_1  | \\tat java.base/java.lang.Thread.run(Unknown Source){noformat}\\n\\nZookeeper does not actually retry the DNS resolution, it just keeps using the old failed result.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\nThis happens because the InetSocketAddress is created once and the DNS lookup happens when it is created.\\n\\n\\n\\nThis issue has come up previously in https://issues.apache.org/jira/browse/ZOOKEEPER-1506 but it appears to still happen here.\\n\\n\\n\\nI have attached a repro.tar.gz to help reproduce this issue. Steps:\\n\\n * Untar repro.tar.gz\\n\\n * docker-compose up\\n\\n * See the exception keeps happening for zk-2, not for the others\\n\\n * Open db.test and uncomment the zk-2 line, increment the serial and save\\n\\n * Wait a few seconds for the DNS to refresh\\n\\n * Verify that you can resolve zk-2.test now (dig @172.16.60.2 zk-2.test) but the error keeps appearing\\n\\n\\n\\nI have also attached a patch that resolves this. The patch will retry DNS resolution if the address is still unresolved every time it tries to create the server socket.\\n\\n\\n\\nÂ\\xa0\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\nTicket ID: ZOOKEEPER-3160\\nIssue Summary: Custom User SSLContext\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nThe Zookeeper libraries currently allow you to set up your SSL Context via system properties such as \"zookeeper.ssl.keyStore.location\" in the X509Util. This covers most simple use cases, where users have software keystores on their harddrive.\\n\\n\\n\\nThere are, however, a few additional scenarios that this doesn\\'t cover. Two possible ones would be:\\n\\n # The user has a hardware keystore, loaded in using PKCS11 or something similar.\\n\\n # The user has no access to the software keystore, but can retrieve an already-constructed SSLContext from their container.\\n\\n\\n\\nFor this, I would propose that the X509Util be extended to allow a user to set a property such as \"zookeeper.ssl.client.context\" to provide a class which supplies a custom SSL context. This gives a lot more flexibility to the ZK client, and allows the user to construct the SSLContext in whatever way they please (which also future proofs the implementation somewhat).\\n\\n\\n\\nI\\'ve already completed this feature, and will put in a PR soon for it.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit type 4: feat\\n\\nCommit message 4:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and additional context provided. If the context is relevant, include it in the commit body. Use IDs, names, or titles to reference relevant contexts for brevity. Including multiple contexts is allowed.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff 1:\\ndiff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\nindex c4e42c94b93..e2fad7560e3 100644\\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n@@ -53,24 +53,29 @@ public static void registerCommands(CommandFactory factory) {\\n   /** merge multiple files together */\\n   public static class Merge extends FsCommand {\\n     public static final String NAME = \"getmerge\";    \\n-    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n+    public static final String USAGE = \"[-nl] [-skip-empty-file] \"\\n+        + \"<src> <localdst>\";\\n     public static final String DESCRIPTION =\\n-      \"Get all the files in the directories that \" +\\n-      \"match the source file pattern and merge and sort them to only \" +\\n-      \"one file on local fs. <src> is kept.\\\\n\" +\\n-      \"-nl: Add a newline character at the end of each file.\";\\n+        \"Get all the files in the directories that \"\\n+        + \"match the source file pattern and merge and sort them to only \"\\n+        + \"one file on local fs. <src> is kept.\\\\n\"\\n+        + \"-nl: Add a newline character at the end of each file.\\\\n\"\\n+        + \"-skip-empty-file: Do not add new line character for empty file.\";\\n \\n     protected PathData dst = null;\\n     protected String delimiter = null;\\n+    private boolean skipEmptyFileDelimiter;\\n     protected List<PathData> srcs = null;\\n \\n     @Override\\n     protected void processOptions(LinkedList<String> args) throws IOException {\\n       try {\\n-        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n+        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\",\\n+            \"skip-empty-file\");\\n         cf.parse(args);\\n \\n         delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n+        skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n \\n         dst = new PathData(new URI(args.removeLast()), getConf());\\n         if (dst.exists && dst.stat.isDirectory()) {\\n@@ -92,21 +97,26 @@ protected void processArguments(LinkedList<PathData> items)\\n       FSDataOutputStream out = dst.fs.create(dst.path);\\n       try {\\n         for (PathData src : srcs) {\\n-          FSDataInputStream in = src.fs.open(src.path);\\n-          try {\\n-            IOUtils.copyBytes(in, out, getConf(), false);\\n-            if (delimiter != null) {\\n-              out.write(delimiter.getBytes(\"UTF-8\"));\\n+          if (src.stat.getLen() != 0) {\\n+            try (FSDataInputStream in = src.fs.open(src.path)) {\\n+              IOUtils.copyBytes(in, out, getConf(), false);\\n+              writeDelimiter(out);\\n             }\\n-          } finally {\\n-            in.close();\\n+          } else if (!skipEmptyFileDelimiter) {\\n+            writeDelimiter(out);\\n           }\\n         }\\n       } finally {\\n         out.close();\\n-      }      \\n+      }\\n     }\\n- \\n+\\n+    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n+      if (delimiter != null) {\\n+        out.write(delimiter.getBytes(\"UTF-8\"));\\n+      }\\n+    }\\n+\\n     @Override\\n     protected void processNonexistentPath(PathData item) throws IOException {\\n       exitCode = 1; // flag that a path is bad\\n\\n\\nAdditional context 1:\\nTicket ID: HADOOP-12657\\nIssue Summary: Add a option to skip newline on empty files with getMerge -nl\\nIssue Type: New Feature\\nPriority: Minor\\n\\nDescription:\\nHello everyone,\\n\\nI recently was in the need of using the new line option -nl with getMerge because the files I needed to merge simply didn\\'t had one. I was merging all the files from one directory and unfortunately this directory also included empty files, which effectively led to multiple newlines append after some files. I needed to remove them manually afterwards.\\n\\nIn this situation it is maybe good to have another argument that allows skipping empty files.\\nThing one could try to implement this feature:\\n\\nThe call for IOUtils.copyBytes(in, out, getConf(), false); doesn\\'t\\nreturn the number of bytes copied which would be convenient as one could\\nskip append the new line when 0 bytes where copied or one would check the file size before.\\n\\nI posted this Idea on the mailing list http://mail-archives.apache.org/mod_mbox/hadoop-user/201507.mbox/%3C55B25140.3060005%40trivago.com%3E but I didn\\'t really get many responses, so I thought I my try this way.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 1: \\n\\ncommit message 1: feat: add option to skip newlines for empty files in getmerge command\\n\\nAdded a new `-skip-empty-file` option to the `getmerge` command in CopyCommands. This prevents adding newline characters when merging directories that contain empty files, addressing the issue described in HADOOP-12657. Updated the command description, usage, and logic to support the new flag.\\n\\nGit diff 2:\\ndiff --git a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\nindex 091743ebd..a570d3d17 100644\\n--- a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n+++ b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n@@ -29,6 +29,7 @@ import org.apache.activemq.util.ByteSequence;\\n public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n \\n     public static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\n+    private static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\n \\n     static {\\n         Constructor constructor = null;\\n@@ -243,7 +244,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n             int rc = 0;\\n             bs.writeBoolean(true);\\n             rc += tightMarshalString1(o.getClass().getName(), bs);\\n-            rc += tightMarshalString1(o.getMessage(), bs);\\n+            rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 rc += 2;\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n@@ -264,7 +265,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n                                           BooleanStream bs) throws IOException {\\n         if (bs.readBoolean()) {\\n             tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n-            tightMarshalString2(o.getMessage(), dataOut, bs);\\n+            tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -550,7 +551,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         dataOut.writeBoolean(o != null);\\n         if (o != null) {\\n             looseMarshalString(o.getClass().getName(), dataOut);\\n-            looseMarshalString(o.getMessage(), dataOut);\\n+            looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -641,4 +642,10 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         }\\n         return rc;\\n     }\\n+    \\n+    protected String cutMessageIfNeeded(final String message) {\\n+        return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE)?\\n+            message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n+            \\n+    }\\n }\\n\\n\\nAdditional context 2:\\nTicket ID: AMQ-6894\\nIssue Summary: Excessive number of connections by failover transport with priorityBackup\\nIssue Type: Bug\\nPriority: Major\\n\\nDescription:\\nMy clients connect to AMQ with this connection string:\\r\\n\\r\\n(tcp://amq1:61616,tcp://amq2:61616)?randomize=false&priorityBackup=true\\r\\n\\r\\n\\xa0It works - for some time. But sooner or later my AMQ server becomes unresponsive because the host it runs on runs out of resources (threads).\\r\\n\\r\\nSuddenly AMQ Server log explodes with the messages like:\\r\\n\\r\\n{code}\\r\\n2018-01-26 09:26:16,909 | WARN\\xa0 | Failed to register MBean org.apache.activemq :type=Broker,brokerName=activemq-vm-primary,connector=clientConnectors,connect\\r\\n\\r\\norName=default,connectionViewType=clientId,connectionName=ID_ca8f70e115d0-3708\\r\\n\\r\\n7-1516883370639-0_22 | org.apache.activemq.broker.jmx.ManagedTransportConnecti\\r\\n\\r\\non | ActiveMQ Transport: tcp:///172.10.7.56:55548@61616\\r\\n\\r\\n2018-01-26 09:26:21,375 | WARN\\xa0 | Ignoring ack received before dispatch; result of failover with an outstanding ack. Acked messages will be replayed if present on this broker. Ignored ack: MessageAck \\\\{commandId = 157, responseRequired = false, ackType = 2, consumerId = ID:ca8f70e115d0-37087-1516883370639-1:22:10:1, firstMessageId = ID:a95345a9c0df-33771-1516883685728-1:17:5:1:23, lastMessageId = ID:a95345a9c0df-33771-1516883685728-1:17:5:1:23, destination = queue://MY_QUEUE_OUT, transactionId = null, messageCount = 1, poisonCause = null} | org.apache.activemq.broker.region.PrefetchSubscription | ActiveMQ Transport: tcp:///172.16.6.56:55464@61616\\r\\n\\r\\n2018-01-26 09:26:39,211 | WARN\\xa0 | Transport Connection to: tcp://172.10.6.56:55860 failed: java.net.SocketException: Connection reset | org.apache.activemq.broker.TransportConnection.Transport | ActiveMQ InactivityMonitor Worker\\r\\n\\r\\n2018-01-26 09:26:47,175 | WARN\\xa0 | Transport Connection to: tcp://172.10.6.56:57012 failed: java.net.SocketException: Broken pipe (Write failed) | org.apache.activemq.broker.TransportConnection.Transport | ActiveMQ InactivityMonitor Worker\\r\\n{code}\\r\\n\\r\\nAfter short period of time AMQ server comes out of resources with \"java.lang.OutOfMemoryError: unable to create new native thread\" error. The AMQ service process in this case has a huge number of threads (some thousands)\\r\\n\\r\\n\\xa0\\r\\n\\r\\nThe client side log contains a lot of reconnection attempts messages like:\\r\\n\\r\\n{code}\\r\\n2018-01-26 00:10:31,387 WARN\\xa0\\xa0\\xa0 [\\\\{{bundle.name,org.apache.activemq.activemq-osgi}{bundle.version,5.14.1}\\\\{bundle.id,181}}]\\xa0\\xa0\\xa0\\xa0 [null]\\xa0 org.apache.activemq.transport.failover.FailoverTransport\\xa0 \\xa0\\xa0\\xa0\\xa0Failed to connect to [tcp://activemq-vm-primary:61616, tcp://activemq-vm-secondary:61616] after: 810 attempt(s) continuing to retry.\\r\\n{code}\\r\\n\\r\\nIt seems that client creates a huge number of connections by failover retry and after some time kills the server.\\r\\n\\r\\nIssue looks very similar to described in https://issues.apache.org/jira/browse/AMQ-6603, however server isn\\'t configured with access control settings.\\r\\n\\r\\nI found the description of similar problem into [http://activemq.2283324.n4.nabble.com/ActiveMQ-5-2-OutOfMemoryError-unable-to-create-new-native-thread-td2366585.html],\\xa0 but without concrete suggestion.\\r\\n\\r\\n\\xa0\\r\\n\\r\\nPart of server log is attached\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 2: \\n\\nCommit message 2: fix: limit exception message size to prevent resource exhaustion\\n\\nIntroduced a `MAX_EXCEPTION_MESSAGE_SIZE` constant (1024 characters) and added logic to truncate overly long exception messages in `BaseDataStreamMarshaller`. This prevents excessive memory and resource usage due to unbounded exception message sizes, addressing the issue in AMQ-6894.\\n\\nGit diff 3:\\ndiff --git a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\nindex ca38c0c319..fbaeaebcb8 100644\\n--- a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n+++ b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n@@ -19,20 +19,13 @@ package org.apache.cassandra.hints;\\n \\n import java.util.concurrent.atomic.AtomicBoolean;\\n \\n-import org.apache.cassandra.gms.ApplicationState;\\n-import org.apache.cassandra.gms.Gossiper;\\n-import org.apache.cassandra.schema.Schema;\\n-\\n-import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\n-\\n /**\\n  * A simple dispatch trigger that\\'s being run every 10 seconds.\\n  *\\n  * Goes through all hint stores and schedules for dispatch all the hints for hosts that are:\\n  * 1. Not currently scheduled for dispatch, and\\n  * 2. Either have some hint files, or an active hint writer, and\\n- * 3. Are live, and\\n- * 4. Have matching schema versions\\n+ * 3. Are live\\n  *\\n  * What does triggering a hints store for dispatch mean?\\n  * - If there are existing hint files, it means submitting them for dispatch;\\n@@ -65,7 +58,6 @@ final class HintsDispatchTrigger implements Runnable\\n                .filter(store -> !isScheduled(store))\\n                .filter(HintsStore::isLive)\\n                .filter(store -> store.isWriting() || store.hasFiles())\\n-               .filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address())))\\n                .forEach(this::schedule);\\n     }\\n \\n\\n\\nAdditional context 3:\\nTicket ID: CASSANDRA-20188\\nIssue Summary: Allow hint delivery during schema mismatch\\nIssue Type: Bug\\nPriority: Normal\\n\\nDescription:\\nIn CASSANDRA-2083 we made hints require schema agreement to avoid a flood of errors in case the table the hints were destined for did not yet exist.  This, however, has other undesirable effects, such as making keeping upgrades in a mixed mode over a longer period of time less tenable.  We should still try to deliver hints and back off if the destination table doesn\\'t exist.\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit Type 3: \\n\\nCommit message 3: fix: allow hint delivery during schema mismatch\\n\\nRemoved schema version checks in `HintsDispatchTrigger` to enable hint delivery even during schema mismatches. This change ensures smoother operations in mixed-mode upgrades by allowing hint dispatch while backing off if the destination table does not exist, addressing issue CASSANDRA-20188.\\n\\nGit diff 4:\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\nAdditional context 4:\\nTicket ID: OPENNLP-1620\\nIssue Summary: It should be possible to remove the allocated ThreadLocal\\nIssue Type: Improvement\\nPriority: Major\\n\\nDescription:\\nIt should be possible to remove the allocated thread locals, if needed by the user as it is tied to the lifetime of the thread using it.\\n\\n\\n\\nÂ\\xa0\\n\\n\\n\\n!image-2024-10-08-11-55-15-901.png!\\n\\n--- RETRIEVED DOCUMENT SPLIT END ---\\n\\n\\n\\nCommit type 4: refactor\\n\\nCommit message 4:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019D590>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED640> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019EC60>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED640> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019C230>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019E8F0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED640> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFE99900>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019ECB0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1098'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9969'), (b'x-ratelimit-remaining-tokens', b'173820'), (b'x-ratelimit-reset-requests', b'4m27.167s'), (b'x-ratelimit-reset-tokens', b'7.853s'), (b'x-request-id', b'req_2bdd455e737a8f8cac33e7241ed7f81c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=t1x0mxCGVBWfvT_Gl2oPR2ylKqlLj8gU4.A_hHu1RBI-1737949484-1.0.1.1-hkDh42zU7yWn7HkWJZoMzne7hh2ogGPZ4kKvWhuk5jupMSulUJjmfGYBIjzeI2zgw7DlSQnhdrT7TfChE2YoQw; path=/; expires=Mon, 27-Jan-25 04:14:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=39CP0e2sZ9Ouh6jLixr_5R_XTkknDqM0gKJpKEHTi8Q-1737949484634-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beed184e91b4-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1098'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9969'), ('x-ratelimit-remaining-tokens', '173820'), ('x-ratelimit-reset-requests', '4m27.167s'), ('x-ratelimit-reset-tokens', '7.853s'), ('x-request-id', 'req_2bdd455e737a8f8cac33e7241ed7f81c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=t1x0mxCGVBWfvT_Gl2oPR2ylKqlLj8gU4.A_hHu1RBI-1737949484-1.0.1.1-hkDh42zU7yWn7HkWJZoMzne7hh2ogGPZ4kKvWhuk5jupMSulUJjmfGYBIjzeI2zgw7DlSQnhdrT7TfChE2YoQw; path=/; expires=Mon, 27-Jan-25 04:14:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=39CP0e2sZ9Ouh6jLixr_5R_XTkknDqM0gKJpKEHTi8Q-1737949484634-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085beed184e91b4-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_2bdd455e737a8f8cac33e7241ed7f81c\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1023'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9968'), (b'x-ratelimit-remaining-tokens', b'169828'), (b'x-ratelimit-reset-requests', b'4m35.422s'), (b'x-ratelimit-reset-tokens', b'9.051s'), (b'x-request-id', b'req_8cb156cfd2ea1e0609fb16fc77fa964a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jrzUbIgDIeV83uh90gyIlbnKnu7a.GpsuaNAY7_U6d0-1737949484-1.0.1.1-rd8kZ0Ja6CmZNJFDMXTMynqeNVakEFLCkuToKJPnHj7Hw9CGAt3g0ME1XL5rhU1HiQLjcza4lE6o7JCmGI2a4w; path=/; expires=Mon, 27-Jan-25 04:14:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=ysSfUF6t0CLhiyESzm5.ibLMfiGU7bc7aFgTqq98Zjs-1737949484930-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beec6ec8a042-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:44 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1023'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9968'), ('x-ratelimit-remaining-tokens', '169828'), ('x-ratelimit-reset-requests', '4m35.422s'), ('x-ratelimit-reset-tokens', '9.051s'), ('x-request-id', 'req_8cb156cfd2ea1e0609fb16fc77fa964a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=jrzUbIgDIeV83uh90gyIlbnKnu7a.GpsuaNAY7_U6d0-1737949484-1.0.1.1-rd8kZ0Ja6CmZNJFDMXTMynqeNVakEFLCkuToKJPnHj7Hw9CGAt3g0ME1XL5rhU1HiQLjcza4lE6o7JCmGI2a4w; path=/; expires=Mon, 27-Jan-25 04:14:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=ysSfUF6t0CLhiyESzm5.ibLMfiGU7bc7aFgTqq98Zjs-1737949484930-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085beec6ec8a042-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_8cb156cfd2ea1e0609fb16fc77fa964a\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1018'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9970'), (b'x-ratelimit-remaining-tokens', b'179977'), (b'x-ratelimit-reset-requests', b'4m18.625s'), (b'x-ratelimit-reset-tokens', b'6.006s'), (b'x-request-id', b'req_38fa8e758a31e76ee9a59388ea45a945'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=uMwIc41h9qva84m7AEkMCKI1rdYiBm0lo7RaFAzTsUQ-1737949485-1.0.1.1-hJaNLHmN5pRWZVohIO33GCaQFTtUqt46TksiODO5_0LWm7RtsdPAfmxO1p2SUEPEPiz2t0OkzUlKSALz3MXlIg; path=/; expires=Mon, 27-Jan-25 04:14:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=DLjDwPYjxxbm37ukO4lG.kfn9V4IpBvVOVY2sWiIzsk-1737949485037-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beec5de3fd03-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:45 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1018'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9970'), ('x-ratelimit-remaining-tokens', '179977'), ('x-ratelimit-reset-requests', '4m18.625s'), ('x-ratelimit-reset-tokens', '6.006s'), ('x-request-id', 'req_38fa8e758a31e76ee9a59388ea45a945'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=uMwIc41h9qva84m7AEkMCKI1rdYiBm0lo7RaFAzTsUQ-1737949485-1.0.1.1-hJaNLHmN5pRWZVohIO33GCaQFTtUqt46TksiODO5_0LWm7RtsdPAfmxO1p2SUEPEPiz2t0OkzUlKSALz3MXlIg; path=/; expires=Mon, 27-Jan-25 04:14:45 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=DLjDwPYjxxbm37ukO4lG.kfn9V4IpBvVOVY2sWiIzsk-1737949485037-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085beec5de3fd03-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_38fa8e758a31e76ee9a59388ea45a945\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Classify the Git diff into one of the following six software maintenance activities: feat, fix, perf, test, refactor, or chore. Return the activity that best matches the code changes. Refer to the definitions below for each activity.\\n\\nfeat: introducing new features into the system.\\nfix: fixing existing bugs or issues in the system.\\nperf: improving the performance of the system.\\ntest: adding, modifying, or deleting test cases.\\nrefactor: changes made to the internal structure of software to make it easier to understand and cheaper to modify without changing its observable behavior, including code styling.\\nchore: regular maintenance tasks, such as updating dependencies or build tasks.\\n\\nAvoid adding any additional comments or annotations to the classification.\\n\\n> Git diff: diff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\n> Software maintenance activity (feat / fix / perf / test / refactor / chore):\\n', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.0}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019EA80>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED010> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFE9AFD0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED010> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEB019C230>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFE9BC00>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'189'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9967'), (b'x-ratelimit-remaining-tokens', b'174590'), (b'x-ratelimit-reset-requests', b'4m42.567s'), (b'x-ratelimit-reset-tokens', b'7.622s'), (b'x-request-id', b'req_285597e20ef1cfbb2b999b861a769ff1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085befa098e3dd5-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '189', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9967', 'x-ratelimit-remaining-tokens': '174590', 'x-ratelimit-reset-requests': '4m42.567s', 'x-ratelimit-reset-tokens': '7.622s', 'x-request-id': 'req_285597e20ef1cfbb2b999b861a769ff1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085befa098e3dd5-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_285597e20ef1cfbb2b999b861a769ff1\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'189'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9966'), (b'x-ratelimit-remaining-tokens', b'172702'), (b'x-ratelimit-reset-requests', b'4m51.137s'), (b'x-ratelimit-reset-tokens', b'8.189s'), (b'x-request-id', b'req_bca2a2c69bd98bbfcbeb175f9374ca59'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085befa5af5ce51-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '189', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9966', 'x-ratelimit-remaining-tokens': '172702', 'x-ratelimit-reset-requests': '4m51.137s', 'x-ratelimit-reset-tokens': '8.189s', 'x-request-id': 'req_bca2a2c69bd98bbfcbeb175f9374ca59', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085befa5af5ce51-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_bca2a2c69bd98bbfcbeb175f9374ca59\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'225'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9965'), (b'x-ratelimit-remaining-tokens', b'171038'), (b'x-ratelimit-reset-requests', b'4m59.747s'), (b'x-ratelimit-reset-tokens', b'8.688s'), (b'x-request-id', b'req_5fc70a83d6ddafa13d09a10d968eb85a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085befa9adefd06-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Mon, 27 Jan 2025 03:44:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-yxw5duua92nmh24amrdiwkpm', 'openai-processing-ms': '225', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9965', 'x-ratelimit-remaining-tokens': '171038', 'x-ratelimit-reset-requests': '4m59.747s', 'x-ratelimit-reset-tokens': '8.688s', 'x-request-id': 'req_5fc70a83d6ddafa13d09a10d968eb85a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9085befa9adefd06-SIN', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_5fc70a83d6ddafa13d09a10d968eb85a\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and relevant source code provided. The relevant source code should be used to provide additional context for the changes made in the Git diff.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff 1:\\ndiff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\nindex c4e42c94b93..e2fad7560e3 100644\\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n@@ -53,24 +53,29 @@ public static void registerCommands(CommandFactory factory) {\\n   /** merge multiple files together */\\n   public static class Merge extends FsCommand {\\n     public static final String NAME = \"getmerge\";    \\n-    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n+    public static final String USAGE = \"[-nl] [-skip-empty-file] \"\\n+        + \"<src> <localdst>\";\\n     public static final String DESCRIPTION =\\n-      \"Get all the files in the directories that \" +\\n-      \"match the source file pattern and merge and sort them to only \" +\\n-      \"one file on local fs. <src> is kept.\\\\n\" +\\n-      \"-nl: Add a newline character at the end of each file.\";\\n+        \"Get all the files in the directories that \"\\n+        + \"match the source file pattern and merge and sort them to only \"\\n+        + \"one file on local fs. <src> is kept.\\\\n\"\\n+        + \"-nl: Add a newline character at the end of each file.\\\\n\"\\n+        + \"-skip-empty-file: Do not add new line character for empty file.\";\\n \\n     protected PathData dst = null;\\n     protected String delimiter = null;\\n+    private boolean skipEmptyFileDelimiter;\\n     protected List<PathData> srcs = null;\\n \\n     @Override\\n     protected void processOptions(LinkedList<String> args) throws IOException {\\n       try {\\n-        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n+        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\",\\n+            \"skip-empty-file\");\\n         cf.parse(args);\\n \\n         delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n+        skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n \\n         dst = new PathData(new URI(args.removeLast()), getConf());\\n         if (dst.exists && dst.stat.isDirectory()) {\\n@@ -92,21 +97,26 @@ protected void processArguments(LinkedList<PathData> items)\\n       FSDataOutputStream out = dst.fs.create(dst.path);\\n       try {\\n         for (PathData src : srcs) {\\n-          FSDataInputStream in = src.fs.open(src.path);\\n-          try {\\n-            IOUtils.copyBytes(in, out, getConf(), false);\\n-            if (delimiter != null) {\\n-              out.write(delimiter.getBytes(\"UTF-8\"));\\n+          if (src.stat.getLen() != 0) {\\n+            try (FSDataInputStream in = src.fs.open(src.path)) {\\n+              IOUtils.copyBytes(in, out, getConf(), false);\\n+              writeDelimiter(out);\\n             }\\n-          } finally {\\n-            in.close();\\n+          } else if (!skipEmptyFileDelimiter) {\\n+            writeDelimiter(out);\\n           }\\n         }\\n       } finally {\\n         out.close();\\n-      }      \\n+      }\\n     }\\n- \\n+\\n+    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n+      if (delimiter != null) {\\n+        out.write(delimiter.getBytes(\"UTF-8\"));\\n+      }\\n+    }\\n+\\n     @Override\\n     protected void processNonexistentPath(PathData item) throws IOException {\\n       exitCode = 1; // flag that a path is bad\\n\\n\\nRelevant source code 1:\\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java (Before)\\nclass CopyCommands {\\n/**\\n * merge multiple files together\\n */\\npublic static class Merge extends FsCommand {\\n\\n    public static final String NAME = \"getmerge\";\\n\\n    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n\\n    public static final String DESCRIPTION = \"Get all the files in the directories that \" + \"match the source file pattern and merge and sort them to only \" + \"one file on local fs. <src> is kept.\\\\n\" + \"-nl: Add a newline character at the end of each file.\";\\n\\n    protected PathData dst = null;\\n\\n    protected String delimiter = null;\\n\\n    protected List<PathData> srcs = null;\\n\\n    @Override\\n    protected void processOptions(LinkedList<String> args) throws IOException {\\n        try {\\n            CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n            cf.parse(args);\\n            delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n            dst = new PathData(new URI(args.removeLast()), getConf());\\n            if (dst.exists && dst.stat.isDirectory()) {\\n                throw new PathIsDirectoryException(dst.toString());\\n            }\\n            srcs = new LinkedList<PathData>();\\n        } catch (URISyntaxException e) {\\n            throw new IOException(\"unexpected URISyntaxException\", e);\\n        }\\n    }\\n\\n    @Override\\n    protected void processArguments(LinkedList<PathData> items) throws IOException {\\n        super.processArguments(items);\\n        if (exitCode != 0) {\\n            // check for error collecting paths\\n            return;\\n        }\\n        FSDataOutputStream out = dst.fs.create(dst.path);\\n        try {\\n            for (PathData src : srcs) {\\n                FSDataInputStream in = src.fs.open(src.path);\\n                try {\\n                    IOUtils.copyBytes(in, out, getConf(), false);\\n                    if (delimiter != null) {\\n                        out.write(delimiter.getBytes(\"UTF-8\"));\\n                    }\\n                } finally {\\n                    in.close();\\n                }\\n            }\\n        } finally {\\n            out.close();\\n        }\\n    }\\n\\n    @Override\\n    protected void processNonexistentPath(PathData item) throws IOException {\\n        // flag that a path is bad\\n        exitCode = 1;\\n        super.processNonexistentPath(item);\\n    }\\n\\n    // this command is handled a bit differently than others.  the paths\\n    // are batched up instead of actually being processed.  this avoids\\n    // unnecessarily streaming into the merge file and then encountering\\n    // a path error that should abort the merge\\n    @Override\\n    protected void processPath(PathData src) throws IOException {\\n        // for directories, recurse one level to get its files, else skip it\\n        if (src.stat.isDirectory()) {\\n            if (getDepth() == 0) {\\n                recursePath(src);\\n            }\\n            // skip subdirs\\n        } else {\\n            srcs.add(src);\\n        }\\n    }\\n}\\n}\\n\\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java (After)\\nclass CopyCommands {\\n/**\\n * merge multiple files together\\n */\\npublic static class Merge extends FsCommand {\\n\\n    public static final String NAME = \"getmerge\";\\n\\n    public static final String USAGE = \"[-nl] [-skip-empty-file] \" + \"<src> <localdst>\";\\n\\n    public static final String DESCRIPTION = \"Get all the files in the directories that \" + \"match the source file pattern and merge and sort them to only \" + \"one file on local fs. <src> is kept.\\\\n\" + \"-nl: Add a newline character at the end of each file.\\\\n\" + \"-skip-empty-file: Do not add new line character for empty file.\";\\n\\n    protected PathData dst = null;\\n\\n    protected String delimiter = null;\\n\\n    private boolean skipEmptyFileDelimiter;\\n\\n    protected List<PathData> srcs = null;\\n\\n    @Override\\n    protected void processOptions(LinkedList<String> args) throws IOException {\\n        try {\\n            CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\", \"skip-empty-file\");\\n            cf.parse(args);\\n            delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n            skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n            dst = new PathData(new URI(args.removeLast()), getConf());\\n            if (dst.exists && dst.stat.isDirectory()) {\\n                throw new PathIsDirectoryException(dst.toString());\\n            }\\n            srcs = new LinkedList<PathData>();\\n        } catch (URISyntaxException e) {\\n            throw new IOException(\"unexpected URISyntaxException\", e);\\n        }\\n    }\\n\\n    @Override\\n    protected void processArguments(LinkedList<PathData> items) throws IOException {\\n        super.processArguments(items);\\n        if (exitCode != 0) {\\n            // check for error collecting paths\\n            return;\\n        }\\n        FSDataOutputStream out = dst.fs.create(dst.path);\\n        try {\\n            for (PathData src : srcs) {\\n                if (src.stat.getLen() != 0) {\\n                    try (FSDataInputStream in = src.fs.open(src.path)) {\\n                        IOUtils.copyBytes(in, out, getConf(), false);\\n                        writeDelimiter(out);\\n                    }\\n                } else if (!skipEmptyFileDelimiter) {\\n                    writeDelimiter(out);\\n                }\\n            }\\n        } finally {\\n            out.close();\\n        }\\n    }\\n\\n    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n        if (delimiter != null) {\\n            out.write(delimiter.getBytes(\"UTF-8\"));\\n        }\\n    }\\n\\n    @Override\\n    protected void processNonexistentPath(PathData item) throws IOException {\\n        // flag that a path is bad\\n        exitCode = 1;\\n        super.processNonexistentPath(item);\\n    }\\n\\n    // this command is handled a bit differently than others.  the paths\\n    // are batched up instead of actually being processed.  this avoids\\n    // unnecessarily streaming into the merge file and then encountering\\n    // a path error that should abort the merge\\n    @Override\\n    protected void processPath(PathData src) throws IOException {\\n        // for directories, recurse one level to get its files, else skip it\\n        if (src.stat.isDirectory()) {\\n            if (getDepth() == 0) {\\n                recursePath(src);\\n            }\\n            // skip subdirs\\n        } else {\\n            srcs.add(src);\\n        }\\n    }\\n}\\n}\\n\\n\\nCommit Type 1: \\n\\ncommit message 1: feat: add option to skip newlines for empty files in getmerge command\\n\\nAdded a new `-skip-empty-file` option to the `getmerge` command in CopyCommands. This prevents adding newline characters when merging directories that contain empty files, addressing the issue described in HADOOP-12657. Updated the command description, usage, and logic to support the new flag.\\n\\nGit diff 2:\\ndiff --git a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\nindex 091743ebd..a570d3d17 100644\\n--- a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n+++ b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n@@ -29,6 +29,7 @@ import org.apache.activemq.util.ByteSequence;\\n public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n \\n     public static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\n+    private static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\n \\n     static {\\n         Constructor constructor = null;\\n@@ -243,7 +244,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n             int rc = 0;\\n             bs.writeBoolean(true);\\n             rc += tightMarshalString1(o.getClass().getName(), bs);\\n-            rc += tightMarshalString1(o.getMessage(), bs);\\n+            rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 rc += 2;\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n@@ -264,7 +265,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n                                           BooleanStream bs) throws IOException {\\n         if (bs.readBoolean()) {\\n             tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n-            tightMarshalString2(o.getMessage(), dataOut, bs);\\n+            tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -550,7 +551,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         dataOut.writeBoolean(o != null);\\n         if (o != null) {\\n             looseMarshalString(o.getClass().getName(), dataOut);\\n-            looseMarshalString(o.getMessage(), dataOut);\\n+            looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -641,4 +642,10 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         }\\n         return rc;\\n     }\\n+    \\n+    protected String cutMessageIfNeeded(final String message) {\\n+        return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE)?\\n+            message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n+            \\n+    }\\n }\\n\\n\\nRelevant source code 2:\\nactivemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java (Before)\\npublic  abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\npublic static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\nstatic {\\n    Constructor constructor = null;\\n    try {\\n        constructor = StackTraceElement.class.getConstructor(new Class[] { String.class, String.class, String.class, int.class });\\n    } catch (Throwable e) {\\n    }\\n    STACK_TRACE_ELEMENT_CONSTRUCTOR = constructor;\\n}\\nprotected int tightMarshalThrowable1(OpenWireFormat wireFormat, Throwable o, BooleanStream bs) throws IOException {\\n    if (o == null) {\\n        bs.writeBoolean(false);\\n        return 0;\\n    } else {\\n        int rc = 0;\\n        bs.writeBoolean(true);\\n        rc += tightMarshalString1(o.getClass().getName(), bs);\\n        rc += tightMarshalString1(o.getMessage(), bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            rc += 2;\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                rc += tightMarshalString1(element.getClassName(), bs);\\n                rc += tightMarshalString1(element.getMethodName(), bs);\\n                rc += tightMarshalString1(element.getFileName(), bs);\\n                rc += 4;\\n            }\\n            rc += tightMarshalThrowable1(wireFormat, o.getCause(), bs);\\n        }\\n        return rc;\\n    }\\n}\\nprotected void tightMarshalThrowable2(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut, BooleanStream bs) throws IOException {\\n    if (bs.readBoolean()) {\\n        tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n        tightMarshalString2(o.getMessage(), dataOut, bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                tightMarshalString2(element.getClassName(), dataOut, bs);\\n                tightMarshalString2(element.getMethodName(), dataOut, bs);\\n                tightMarshalString2(element.getFileName(), dataOut, bs);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            tightMarshalThrowable2(wireFormat, o.getCause(), dataOut, bs);\\n        }\\n    }\\n}\\nprotected void looseMarshalThrowable(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut) throws IOException {\\n    dataOut.writeBoolean(o != null);\\n    if (o != null) {\\n        looseMarshalString(o.getClass().getName(), dataOut);\\n        looseMarshalString(o.getMessage(), dataOut);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                looseMarshalString(element.getClassName(), dataOut);\\n                looseMarshalString(element.getMethodName(), dataOut);\\n                looseMarshalString(element.getFileName(), dataOut);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            looseMarshalThrowable(wireFormat, o.getCause(), dataOut);\\n        }\\n    }\\n}\\nprotected ByteSequence looseUnmarshalByteSequence(DataInput dataIn) throws IOException {\\n    ByteSequence rc = null;\\n    if (dataIn.readBoolean()) {\\n        int size = dataIn.readInt();\\n        byte[] t = new byte[size];\\n        dataIn.readFully(t);\\n        rc = new ByteSequence(t, 0, size);\\n    }\\n    return rc;\\n}\\n}\\n\\nactivemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java (After)\\npublic  abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\npublic static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\nprivate static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\nstatic {\\n    Constructor constructor = null;\\n    try {\\n        constructor = StackTraceElement.class.getConstructor(new Class[] { String.class, String.class, String.class, int.class });\\n    } catch (Throwable e) {\\n    }\\n    STACK_TRACE_ELEMENT_CONSTRUCTOR = constructor;\\n}\\nprotected int tightMarshalThrowable1(OpenWireFormat wireFormat, Throwable o, BooleanStream bs) throws IOException {\\n    if (o == null) {\\n        bs.writeBoolean(false);\\n        return 0;\\n    } else {\\n        int rc = 0;\\n        bs.writeBoolean(true);\\n        rc += tightMarshalString1(o.getClass().getName(), bs);\\n        rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            rc += 2;\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                rc += tightMarshalString1(element.getClassName(), bs);\\n                rc += tightMarshalString1(element.getMethodName(), bs);\\n                rc += tightMarshalString1(element.getFileName(), bs);\\n                rc += 4;\\n            }\\n            rc += tightMarshalThrowable1(wireFormat, o.getCause(), bs);\\n        }\\n        return rc;\\n    }\\n}\\nprotected void tightMarshalThrowable2(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut, BooleanStream bs) throws IOException {\\n    if (bs.readBoolean()) {\\n        tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n        tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                tightMarshalString2(element.getClassName(), dataOut, bs);\\n                tightMarshalString2(element.getMethodName(), dataOut, bs);\\n                tightMarshalString2(element.getFileName(), dataOut, bs);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            tightMarshalThrowable2(wireFormat, o.getCause(), dataOut, bs);\\n        }\\n    }\\n}\\nprotected void looseMarshalThrowable(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut) throws IOException {\\n    dataOut.writeBoolean(o != null);\\n    if (o != null) {\\n        looseMarshalString(o.getClass().getName(), dataOut);\\n        looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                looseMarshalString(element.getClassName(), dataOut);\\n                looseMarshalString(element.getMethodName(), dataOut);\\n                looseMarshalString(element.getFileName(), dataOut);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            looseMarshalThrowable(wireFormat, o.getCause(), dataOut);\\n        }\\n    }\\n}\\nprotected ByteSequence looseUnmarshalByteSequence(DataInput dataIn) throws IOException {\\n    ByteSequence rc = null;\\n    if (dataIn.readBoolean()) {\\n        int size = dataIn.readInt();\\n        byte[] t = new byte[size];\\n        dataIn.readFully(t);\\n        rc = new ByteSequence(t, 0, size);\\n    }\\n    return rc;\\n}\\nprotected String cutMessageIfNeeded(final String message) {\\n    return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE) ? message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n}\\n}\\n\\n\\nCommit Type 2: \\n\\nCommit message 2: fix: limit exception message size to prevent resource exhaustion\\n\\nIntroduced a `MAX_EXCEPTION_MESSAGE_SIZE` constant (1024 characters) and added logic to truncate overly long exception messages in `BaseDataStreamMarshaller`. This prevents excessive memory and resource usage due to unbounded exception message sizes, addressing the issue in AMQ-6894.\\n\\nGit diff 3:\\ndiff --git a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\nindex ca38c0c319..fbaeaebcb8 100644\\n--- a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n+++ b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n@@ -19,20 +19,13 @@ package org.apache.cassandra.hints;\\n \\n import java.util.concurrent.atomic.AtomicBoolean;\\n \\n-import org.apache.cassandra.gms.ApplicationState;\\n-import org.apache.cassandra.gms.Gossiper;\\n-import org.apache.cassandra.schema.Schema;\\n-\\n-import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\n-\\n /**\\n  * A simple dispatch trigger that\\'s being run every 10 seconds.\\n  *\\n  * Goes through all hint stores and schedules for dispatch all the hints for hosts that are:\\n  * 1. Not currently scheduled for dispatch, and\\n  * 2. Either have some hint files, or an active hint writer, and\\n- * 3. Are live, and\\n- * 4. Have matching schema versions\\n+ * 3. Are live\\n  *\\n  * What does triggering a hints store for dispatch mean?\\n  * - If there are existing hint files, it means submitting them for dispatch;\\n@@ -65,7 +58,6 @@ final class HintsDispatchTrigger implements Runnable\\n                .filter(store -> !isScheduled(store))\\n                .filter(HintsStore::isLive)\\n                .filter(store -> store.isWriting() || store.hasFiles())\\n-               .filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address())))\\n                .forEach(this::schedule);\\n     }\\n \\n\\n\\nRelevant source code 3:\\nsrc/java/org/apache/cassandra/hints/HintsDispatchTrigger.java (Before)\\nimport java.util.concurrent.atomic.AtomicBoolean;\\nimport org.apache.cassandra.gms.ApplicationState;\\nimport org.apache.cassandra.gms.Gossiper;\\nimport org.apache.cassandra.schema.Schema;\\nimport static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\nfinal class HintsDispatchTrigger implements Runnable {\\npublic void run() {\\n    if (isPaused.get())\\n        return;\\n    catalog.stores().filter(store -> !isScheduled(store)).filter(HintsStore::isLive).filter(store -> store.isWriting() || store.hasFiles()).filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address()))).forEach(this::schedule);\\n}\\n}\\n\\nsrc/java/org/apache/cassandra/hints/HintsDispatchTrigger.java (After)\\nimport java.util.concurrent.atomic.AtomicBoolean;\\nfinal class HintsDispatchTrigger implements Runnable {\\npublic void run() {\\n    if (isPaused.get())\\n        return;\\n    catalog.stores().filter(store -> !isScheduled(store)).filter(HintsStore::isLive).filter(store -> store.isWriting() || store.hasFiles()).forEach(this::schedule);\\n}\\n}\\n\\n\\nCommit Type 3: \\n\\nCommit message 3: fix: allow hint delivery during schema mismatch\\n\\nRemoved schema version checks in `HintsDispatchTrigger` to enable hint delivery even during schema mismatches. This change ensures smoother operations in mixed-mode upgrades by allowing hint dispatch while backing off if the destination table does not exist, addressing issue CASSANDRA-20188.\\n\\nGit diff 4:\\ndiff --git a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\nindex c021ebca1..1ce138c0e 100644\\n--- a/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n+++ b/contrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java\\n@@ -192,7 +192,7 @@ public class HiveStoragePlugin extends AbstractStoragePlugin {\\n   @Override\\n   public Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n     switch (phase) {\\n-      case LOGICAL:\\n+      case PARTITION_PRUNING:\\n         final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n         ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n         ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\ndiff --git a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\nindex 62a2c136a..608aaf8d1 100644\\n--- a/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n+++ b/contrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java\\n@@ -28,7 +28,6 @@ import org.apache.drill.exec.planner.physical.PlannerSettings;\\n import org.apache.drill.exec.rpc.user.QueryDataBatch;\\n import org.junit.AfterClass;\\n import org.junit.BeforeClass;\\n-import org.junit.Ignore;\\n import org.junit.Test;\\n import org.junit.experimental.categories.Category;\\n \\n@@ -163,11 +162,10 @@ public class TestHivePartitionPruning extends HiveTestBase {\\n   }\\n \\n   @Test // DRILL-6173\\n-  @Ignore(\"DRILL-8400\")\\n   public void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n-    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" +\\n+    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" +\\n             \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" +\\n-            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n+            \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n \\n     int actualRowCount = testSql(query);\\n     int expectedRowCount = 450;\\n\\n\\nRelevant source code 4:\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (Before)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case LOGICAL:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/main/java/org/apache/drill/exec/store/hive/HiveStoragePlugin.java (After)\\npublic class HiveStoragePlugin extends AbstractStoragePlugin {\\n@Override\\npublic Set<StoragePluginOptimizerRule> getOptimizerRules(OptimizerRulesContext optimizerContext, PlannerPhase phase) {\\n    switch(phase) {\\n        case PARTITION_PRUNING:\\n            final String defaultPartitionValue = hiveConf.get(ConfVars.DEFAULTPARTITIONNAME.varname);\\n            ImmutableSet.Builder<StoragePluginOptimizerRule> ruleBuilder = ImmutableSet.builder();\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnProject(optimizerContext, defaultPartitionValue));\\n            ruleBuilder.add(HivePushPartitionFilterIntoScan.getFilterOnScan(optimizerContext, defaultPartitionValue));\\n            return ruleBuilder.build();\\n        case PHYSICAL:\\n            {\\n                ruleBuilder = ImmutableSet.builder();\\n                OptionManager options = optimizerContext.getPlannerSettings().getOptions();\\n                // TODO: Remove implicit using of convert_fromTIMESTAMP_IMPALA function\\n                // once \"store.parquet.reader.int96_as_timestamp\" will be true by default\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_SCAN_WITH_NATIVE_READERS) || options.getBoolean(ExecConstants.HIVE_OPTIMIZE_PARQUET_SCAN_WITH_NATIVE_READER)) {\\n                    ruleBuilder.add(ConvertHiveParquetScanToDrillParquetScan.INSTANCE);\\n                }\\n                if (options.getBoolean(ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER)) {\\n                    try {\\n                        Class<?> hiveToDrillMapRDBJsonRuleClass = Class.forName(\"org.apache.drill.exec.planner.sql.logical.ConvertHiveMapRDBJsonScanToDrillMapRDBJsonScan\");\\n                        ruleBuilder.add((StoragePluginOptimizerRule) hiveToDrillMapRDBJsonRuleClass.getField(\"INSTANCE\").get(null));\\n                    } catch (ReflectiveOperationException e) {\\n                        logger.warn(\"Current Drill build is not designed for working with Hive MapR-DB tables. \" + \"Please disable {} option\", ExecConstants.HIVE_OPTIMIZE_MAPRDB_JSON_SCAN_WITH_NATIVE_READER);\\n                    }\\n                }\\n                return ruleBuilder.build();\\n            }\\n        default:\\n            return ImmutableSet.of();\\n    }\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (Before)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Ignore;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\n@Ignore(\"DRILL-8400\")\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = String.format(\"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\");\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\ncontrib/storage-hive/core/src/test/java/org/apache/drill/exec/TestHivePartitionPruning.java (After)\\nimport org.apache.drill.exec.rpc.user.QueryDataBatch;\\nimport org.junit.AfterClass;\\nimport org.junit.BeforeClass;\\nimport org.junit.Test;\\nimport org.junit.experimental.categories.Category;\\npublic class TestHivePartitionPruning extends HiveTestBase {\\n// DRILL-5032\\n@Test\\npublic void testPartitionColumnsCaching() throws Exception {\\n    final String query = \"EXPLAIN PLAN FOR SELECT * FROM hive.partition_with_few_schemas\";\\n    List<QueryDataBatch> queryDataBatches = testSqlWithResults(query);\\n    String resultString = getResultString(queryDataBatches, \"|\");\\n    // different for both partitions column strings from physical plan\\n    String columnString = \"\\\\\"name\\\\\" : \\\\\"a\\\\\"\";\\n    String secondColumnString = \"\\\\\"name\\\\\" : \\\\\"a1\\\\\"\";\\n    int columnIndex = resultString.indexOf(columnString);\\n    assertTrue(columnIndex >= 0);\\n    columnIndex = resultString.indexOf(columnString, columnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, columnIndex);\\n    int secondColumnIndex = resultString.indexOf(secondColumnString);\\n    assertTrue(secondColumnIndex >= 0);\\n    secondColumnIndex = resultString.indexOf(secondColumnString, secondColumnIndex + 1);\\n    // checks that column added to physical plan only one time\\n    assertEquals(-1, secondColumnIndex);\\n}\\n// DRILL-6173\\n@Test\\npublic void prunePartitionsBasedOnTransitivePredicates() throws Exception {\\n    String query = \"SELECT * FROM hive.partition_pruning_test t1 \" + \"JOIN hive.partition_with_few_schemas t2 ON t1.`d` = t2.`d` AND t1.`e` = t2.`e` \" + \"WHERE t2.`e` IS NOT NULL AND t1.`d` = 1\";\\n    int actualRowCount = testSql(query);\\n    int expectedRowCount = 450;\\n    assertEquals(\"Expected and actual row count should match\", expectedRowCount, actualRowCount);\\n    final String[] expectedPlan = { \"partition_with_few_schemas.*numPartitions=6\", \"partition_pruning_test.*numPartitions=6\" };\\n    testPlanMatchingPatterns(query, expectedPlan);\\n}\\n}\\n\\n\\nCommit type 4: refactor\\n\\nCommit message 4:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and relevant source code provided. The relevant source code should be used to provide additional context for the changes made in the Git diff.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff 1:\\ndiff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\nindex c4e42c94b93..e2fad7560e3 100644\\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n@@ -53,24 +53,29 @@ public static void registerCommands(CommandFactory factory) {\\n   /** merge multiple files together */\\n   public static class Merge extends FsCommand {\\n     public static final String NAME = \"getmerge\";    \\n-    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n+    public static final String USAGE = \"[-nl] [-skip-empty-file] \"\\n+        + \"<src> <localdst>\";\\n     public static final String DESCRIPTION =\\n-      \"Get all the files in the directories that \" +\\n-      \"match the source file pattern and merge and sort them to only \" +\\n-      \"one file on local fs. <src> is kept.\\\\n\" +\\n-      \"-nl: Add a newline character at the end of each file.\";\\n+        \"Get all the files in the directories that \"\\n+        + \"match the source file pattern and merge and sort them to only \"\\n+        + \"one file on local fs. <src> is kept.\\\\n\"\\n+        + \"-nl: Add a newline character at the end of each file.\\\\n\"\\n+        + \"-skip-empty-file: Do not add new line character for empty file.\";\\n \\n     protected PathData dst = null;\\n     protected String delimiter = null;\\n+    private boolean skipEmptyFileDelimiter;\\n     protected List<PathData> srcs = null;\\n \\n     @Override\\n     protected void processOptions(LinkedList<String> args) throws IOException {\\n       try {\\n-        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n+        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\",\\n+            \"skip-empty-file\");\\n         cf.parse(args);\\n \\n         delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n+        skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n \\n         dst = new PathData(new URI(args.removeLast()), getConf());\\n         if (dst.exists && dst.stat.isDirectory()) {\\n@@ -92,21 +97,26 @@ protected void processArguments(LinkedList<PathData> items)\\n       FSDataOutputStream out = dst.fs.create(dst.path);\\n       try {\\n         for (PathData src : srcs) {\\n-          FSDataInputStream in = src.fs.open(src.path);\\n-          try {\\n-            IOUtils.copyBytes(in, out, getConf(), false);\\n-            if (delimiter != null) {\\n-              out.write(delimiter.getBytes(\"UTF-8\"));\\n+          if (src.stat.getLen() != 0) {\\n+            try (FSDataInputStream in = src.fs.open(src.path)) {\\n+              IOUtils.copyBytes(in, out, getConf(), false);\\n+              writeDelimiter(out);\\n             }\\n-          } finally {\\n-            in.close();\\n+          } else if (!skipEmptyFileDelimiter) {\\n+            writeDelimiter(out);\\n           }\\n         }\\n       } finally {\\n         out.close();\\n-      }      \\n+      }\\n     }\\n- \\n+\\n+    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n+      if (delimiter != null) {\\n+        out.write(delimiter.getBytes(\"UTF-8\"));\\n+      }\\n+    }\\n+\\n     @Override\\n     protected void processNonexistentPath(PathData item) throws IOException {\\n       exitCode = 1; // flag that a path is bad\\n\\n\\nRelevant source code 1:\\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java (Before)\\nclass CopyCommands {\\n/**\\n * merge multiple files together\\n */\\npublic static class Merge extends FsCommand {\\n\\n    public static final String NAME = \"getmerge\";\\n\\n    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n\\n    public static final String DESCRIPTION = \"Get all the files in the directories that \" + \"match the source file pattern and merge and sort them to only \" + \"one file on local fs. <src> is kept.\\\\n\" + \"-nl: Add a newline character at the end of each file.\";\\n\\n    protected PathData dst = null;\\n\\n    protected String delimiter = null;\\n\\n    protected List<PathData> srcs = null;\\n\\n    @Override\\n    protected void processOptions(LinkedList<String> args) throws IOException {\\n        try {\\n            CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n            cf.parse(args);\\n            delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n            dst = new PathData(new URI(args.removeLast()), getConf());\\n            if (dst.exists && dst.stat.isDirectory()) {\\n                throw new PathIsDirectoryException(dst.toString());\\n            }\\n            srcs = new LinkedList<PathData>();\\n        } catch (URISyntaxException e) {\\n            throw new IOException(\"unexpected URISyntaxException\", e);\\n        }\\n    }\\n\\n    @Override\\n    protected void processArguments(LinkedList<PathData> items) throws IOException {\\n        super.processArguments(items);\\n        if (exitCode != 0) {\\n            // check for error collecting paths\\n            return;\\n        }\\n        FSDataOutputStream out = dst.fs.create(dst.path);\\n        try {\\n            for (PathData src : srcs) {\\n                FSDataInputStream in = src.fs.open(src.path);\\n                try {\\n                    IOUtils.copyBytes(in, out, getConf(), false);\\n                    if (delimiter != null) {\\n                        out.write(delimiter.getBytes(\"UTF-8\"));\\n                    }\\n                } finally {\\n                    in.close();\\n                }\\n            }\\n        } finally {\\n            out.close();\\n        }\\n    }\\n\\n    @Override\\n    protected void processNonexistentPath(PathData item) throws IOException {\\n        // flag that a path is bad\\n        exitCode = 1;\\n        super.processNonexistentPath(item);\\n    }\\n\\n    // this command is handled a bit differently than others.  the paths\\n    // are batched up instead of actually being processed.  this avoids\\n    // unnecessarily streaming into the merge file and then encountering\\n    // a path error that should abort the merge\\n    @Override\\n    protected void processPath(PathData src) throws IOException {\\n        // for directories, recurse one level to get its files, else skip it\\n        if (src.stat.isDirectory()) {\\n            if (getDepth() == 0) {\\n                recursePath(src);\\n            }\\n            // skip subdirs\\n        } else {\\n            srcs.add(src);\\n        }\\n    }\\n}\\n}\\n\\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java (After)\\nclass CopyCommands {\\n/**\\n * merge multiple files together\\n */\\npublic static class Merge extends FsCommand {\\n\\n    public static final String NAME = \"getmerge\";\\n\\n    public static final String USAGE = \"[-nl] [-skip-empty-file] \" + \"<src> <localdst>\";\\n\\n    public static final String DESCRIPTION = \"Get all the files in the directories that \" + \"match the source file pattern and merge and sort them to only \" + \"one file on local fs. <src> is kept.\\\\n\" + \"-nl: Add a newline character at the end of each file.\\\\n\" + \"-skip-empty-file: Do not add new line character for empty file.\";\\n\\n    protected PathData dst = null;\\n\\n    protected String delimiter = null;\\n\\n    private boolean skipEmptyFileDelimiter;\\n\\n    protected List<PathData> srcs = null;\\n\\n    @Override\\n    protected void processOptions(LinkedList<String> args) throws IOException {\\n        try {\\n            CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\", \"skip-empty-file\");\\n            cf.parse(args);\\n            delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n            skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n            dst = new PathData(new URI(args.removeLast()), getConf());\\n            if (dst.exists && dst.stat.isDirectory()) {\\n                throw new PathIsDirectoryException(dst.toString());\\n            }\\n            srcs = new LinkedList<PathData>();\\n        } catch (URISyntaxException e) {\\n            throw new IOException(\"unexpected URISyntaxException\", e);\\n        }\\n    }\\n\\n    @Override\\n    protected void processArguments(LinkedList<PathData> items) throws IOException {\\n        super.processArguments(items);\\n        if (exitCode != 0) {\\n            // check for error collecting paths\\n            return;\\n        }\\n        FSDataOutputStream out = dst.fs.create(dst.path);\\n        try {\\n            for (PathData src : srcs) {\\n                if (src.stat.getLen() != 0) {\\n                    try (FSDataInputStream in = src.fs.open(src.path)) {\\n                        IOUtils.copyBytes(in, out, getConf(), false);\\n                        writeDelimiter(out);\\n                    }\\n                } else if (!skipEmptyFileDelimiter) {\\n                    writeDelimiter(out);\\n                }\\n            }\\n        } finally {\\n            out.close();\\n        }\\n    }\\n\\n    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n        if (delimiter != null) {\\n            out.write(delimiter.getBytes(\"UTF-8\"));\\n        }\\n    }\\n\\n    @Override\\n    protected void processNonexistentPath(PathData item) throws IOException {\\n        // flag that a path is bad\\n        exitCode = 1;\\n        super.processNonexistentPath(item);\\n    }\\n\\n    // this command is handled a bit differently than others.  the paths\\n    // are batched up instead of actually being processed.  this avoids\\n    // unnecessarily streaming into the merge file and then encountering\\n    // a path error that should abort the merge\\n    @Override\\n    protected void processPath(PathData src) throws IOException {\\n        // for directories, recurse one level to get its files, else skip it\\n        if (src.stat.isDirectory()) {\\n            if (getDepth() == 0) {\\n                recursePath(src);\\n            }\\n            // skip subdirs\\n        } else {\\n            srcs.add(src);\\n        }\\n    }\\n}\\n}\\n\\n\\nCommit Type 1: \\n\\ncommit message 1: feat: add option to skip newlines for empty files in getmerge command\\n\\nAdded a new `-skip-empty-file` option to the `getmerge` command in CopyCommands. This prevents adding newline characters when merging directories that contain empty files, addressing the issue described in HADOOP-12657. Updated the command description, usage, and logic to support the new flag.\\n\\nGit diff 2:\\ndiff --git a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\nindex 091743ebd..a570d3d17 100644\\n--- a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n+++ b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n@@ -29,6 +29,7 @@ import org.apache.activemq.util.ByteSequence;\\n public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n \\n     public static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\n+    private static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\n \\n     static {\\n         Constructor constructor = null;\\n@@ -243,7 +244,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n             int rc = 0;\\n             bs.writeBoolean(true);\\n             rc += tightMarshalString1(o.getClass().getName(), bs);\\n-            rc += tightMarshalString1(o.getMessage(), bs);\\n+            rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 rc += 2;\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n@@ -264,7 +265,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n                                           BooleanStream bs) throws IOException {\\n         if (bs.readBoolean()) {\\n             tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n-            tightMarshalString2(o.getMessage(), dataOut, bs);\\n+            tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -550,7 +551,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         dataOut.writeBoolean(o != null);\\n         if (o != null) {\\n             looseMarshalString(o.getClass().getName(), dataOut);\\n-            looseMarshalString(o.getMessage(), dataOut);\\n+            looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -641,4 +642,10 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         }\\n         return rc;\\n     }\\n+    \\n+    protected String cutMessageIfNeeded(final String message) {\\n+        return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE)?\\n+            message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n+            \\n+    }\\n }\\n\\n\\nRelevant source code 2:\\nactivemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java (Before)\\npublic  abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\npublic static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\nstatic {\\n    Constructor constructor = null;\\n    try {\\n        constructor = StackTraceElement.class.getConstructor(new Class[] { String.class, String.class, String.class, int.class });\\n    } catch (Throwable e) {\\n    }\\n    STACK_TRACE_ELEMENT_CONSTRUCTOR = constructor;\\n}\\nprotected int tightMarshalThrowable1(OpenWireFormat wireFormat, Throwable o, BooleanStream bs) throws IOException {\\n    if (o == null) {\\n        bs.writeBoolean(false);\\n        return 0;\\n    } else {\\n        int rc = 0;\\n        bs.writeBoolean(true);\\n        rc += tightMarshalString1(o.getClass().getName(), bs);\\n        rc += tightMarshalString1(o.getMessage(), bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            rc += 2;\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                rc += tightMarshalString1(element.getClassName(), bs);\\n                rc += tightMarshalString1(element.getMethodName(), bs);\\n                rc += tightMarshalString1(element.getFileName(), bs);\\n                rc += 4;\\n            }\\n            rc += tightMarshalThrowable1(wireFormat, o.getCause(), bs);\\n        }\\n        return rc;\\n    }\\n}\\nprotected void tightMarshalThrowable2(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut, BooleanStream bs) throws IOException {\\n    if (bs.readBoolean()) {\\n        tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n        tightMarshalString2(o.getMessage(), dataOut, bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                tightMarshalString2(element.getClassName(), dataOut, bs);\\n                tightMarshalString2(element.getMethodName(), dataOut, bs);\\n                tightMarshalString2(element.getFileName(), dataOut, bs);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            tightMarshalThrowable2(wireFormat, o.getCause(), dataOut, bs);\\n        }\\n    }\\n}\\nprotected void looseMarshalThrowable(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut) throws IOException {\\n    dataOut.writeBoolean(o != null);\\n    if (o != null) {\\n        looseMarshalString(o.getClass().getName(), dataOut);\\n        looseMarshalString(o.getMessage(), dataOut);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                looseMarshalString(element.getClassName(), dataOut);\\n                looseMarshalString(element.getMethodName(), dataOut);\\n                looseMarshalString(element.getFileName(), dataOut);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            looseMarshalThrowable(wireFormat, o.getCause(), dataOut);\\n        }\\n    }\\n}\\nprotected ByteSequence looseUnmarshalByteSequence(DataInput dataIn) throws IOException {\\n    ByteSequence rc = null;\\n    if (dataIn.readBoolean()) {\\n        int size = dataIn.readInt();\\n        byte[] t = new byte[size];\\n        dataIn.readFully(t);\\n        rc = new ByteSequence(t, 0, size);\\n    }\\n    return rc;\\n}\\n}\\n\\nactivemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java (After)\\npublic  abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\npublic static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\nprivate static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\nstatic {\\n    Constructor constructor = null;\\n    try {\\n        constructor = StackTraceElement.class.getConstructor(new Class[] { String.class, String.class, String.class, int.class });\\n    } catch (Throwable e) {\\n    }\\n    STACK_TRACE_ELEMENT_CONSTRUCTOR = constructor;\\n}\\nprotected int tightMarshalThrowable1(OpenWireFormat wireFormat, Throwable o, BooleanStream bs) throws IOException {\\n    if (o == null) {\\n        bs.writeBoolean(false);\\n        return 0;\\n    } else {\\n        int rc = 0;\\n        bs.writeBoolean(true);\\n        rc += tightMarshalString1(o.getClass().getName(), bs);\\n        rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            rc += 2;\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                rc += tightMarshalString1(element.getClassName(), bs);\\n                rc += tightMarshalString1(element.getMethodName(), bs);\\n                rc += tightMarshalString1(element.getFileName(), bs);\\n                rc += 4;\\n            }\\n            rc += tightMarshalThrowable1(wireFormat, o.getCause(), bs);\\n        }\\n        return rc;\\n    }\\n}\\nprotected void tightMarshalThrowable2(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut, BooleanStream bs) throws IOException {\\n    if (bs.readBoolean()) {\\n        tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n        tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                tightMarshalString2(element.getClassName(), dataOut, bs);\\n                tightMarshalString2(element.getMethodName(), dataOut, bs);\\n                tightMarshalString2(element.getFileName(), dataOut, bs);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            tightMarshalThrowable2(wireFormat, o.getCause(), dataOut, bs);\\n        }\\n    }\\n}\\nprotected void looseMarshalThrowable(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut) throws IOException {\\n    dataOut.writeBoolean(o != null);\\n    if (o != null) {\\n        looseMarshalString(o.getClass().getName(), dataOut);\\n        looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                looseMarshalString(element.getClassName(), dataOut);\\n                looseMarshalString(element.getMethodName(), dataOut);\\n                looseMarshalString(element.getFileName(), dataOut);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            looseMarshalThrowable(wireFormat, o.getCause(), dataOut);\\n        }\\n    }\\n}\\nprotected ByteSequence looseUnmarshalByteSequence(DataInput dataIn) throws IOException {\\n    ByteSequence rc = null;\\n    if (dataIn.readBoolean()) {\\n        int size = dataIn.readInt();\\n        byte[] t = new byte[size];\\n        dataIn.readFully(t);\\n        rc = new ByteSequence(t, 0, size);\\n    }\\n    return rc;\\n}\\nprotected String cutMessageIfNeeded(final String message) {\\n    return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE) ? message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n}\\n}\\n\\n\\nCommit Type 2: \\n\\nCommit message 2: fix: limit exception message size to prevent resource exhaustion\\n\\nIntroduced a `MAX_EXCEPTION_MESSAGE_SIZE` constant (1024 characters) and added logic to truncate overly long exception messages in `BaseDataStreamMarshaller`. This prevents excessive memory and resource usage due to unbounded exception message sizes, addressing the issue in AMQ-6894.\\n\\nGit diff 3:\\ndiff --git a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\nindex ca38c0c319..fbaeaebcb8 100644\\n--- a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n+++ b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n@@ -19,20 +19,13 @@ package org.apache.cassandra.hints;\\n \\n import java.util.concurrent.atomic.AtomicBoolean;\\n \\n-import org.apache.cassandra.gms.ApplicationState;\\n-import org.apache.cassandra.gms.Gossiper;\\n-import org.apache.cassandra.schema.Schema;\\n-\\n-import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\n-\\n /**\\n  * A simple dispatch trigger that\\'s being run every 10 seconds.\\n  *\\n  * Goes through all hint stores and schedules for dispatch all the hints for hosts that are:\\n  * 1. Not currently scheduled for dispatch, and\\n  * 2. Either have some hint files, or an active hint writer, and\\n- * 3. Are live, and\\n- * 4. Have matching schema versions\\n+ * 3. Are live\\n  *\\n  * What does triggering a hints store for dispatch mean?\\n  * - If there are existing hint files, it means submitting them for dispatch;\\n@@ -65,7 +58,6 @@ final class HintsDispatchTrigger implements Runnable\\n                .filter(store -> !isScheduled(store))\\n                .filter(HintsStore::isLive)\\n                .filter(store -> store.isWriting() || store.hasFiles())\\n-               .filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address())))\\n                .forEach(this::schedule);\\n     }\\n \\n\\n\\nRelevant source code 3:\\nsrc/java/org/apache/cassandra/hints/HintsDispatchTrigger.java (Before)\\nimport java.util.concurrent.atomic.AtomicBoolean;\\nimport org.apache.cassandra.gms.ApplicationState;\\nimport org.apache.cassandra.gms.Gossiper;\\nimport org.apache.cassandra.schema.Schema;\\nimport static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\nfinal class HintsDispatchTrigger implements Runnable {\\npublic void run() {\\n    if (isPaused.get())\\n        return;\\n    catalog.stores().filter(store -> !isScheduled(store)).filter(HintsStore::isLive).filter(store -> store.isWriting() || store.hasFiles()).filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address()))).forEach(this::schedule);\\n}\\n}\\n\\nsrc/java/org/apache/cassandra/hints/HintsDispatchTrigger.java (After)\\nimport java.util.concurrent.atomic.AtomicBoolean;\\nfinal class HintsDispatchTrigger implements Runnable {\\npublic void run() {\\n    if (isPaused.get())\\n        return;\\n    catalog.stores().filter(store -> !isScheduled(store)).filter(HintsStore::isLive).filter(store -> store.isWriting() || store.hasFiles()).forEach(this::schedule);\\n}\\n}\\n\\n\\nCommit Type 3: \\n\\nCommit message 3: fix: allow hint delivery during schema mismatch\\n\\nRemoved schema version checks in `HintsDispatchTrigger` to enable hint delivery even during schema mismatches. This change ensures smoother operations in mixed-mode upgrades by allowing hint dispatch while backing off if the destination table does not exist, addressing issue CASSANDRA-20188.\\n\\nGit diff 4:\\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\nindex 3ca787fc3..f8b275a01 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java\\n@@ -17,10 +17,9 @@\\n  */\\n package org.apache.zookeeper.common;\\n \\n-\\n-import java.io.ByteArrayInputStream;\\n import java.io.Closeable;\\n import java.io.IOException;\\n+import java.lang.reflect.InvocationTargetException;\\n import java.net.Socket;\\n import java.nio.file.Path;\\n import java.nio.file.Paths;\\n@@ -33,15 +32,14 @@\\n import java.security.Security;\\n import java.security.cert.PKIXBuilderParameters;\\n import java.security.cert.X509CertSelector;\\n-import java.util.Arrays;\\n import java.util.Objects;\\n import java.util.concurrent.atomic.AtomicReference;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.CertPathTrustManagerParameters;\\n import javax.net.ssl.KeyManager;\\n import javax.net.ssl.KeyManagerFactory;\\n import javax.net.ssl.SSLContext;\\n-import javax.net.ssl.SSLParameters;\\n import javax.net.ssl.SSLServerSocket;\\n import javax.net.ssl.SSLSocket;\\n import javax.net.ssl.TrustManager;\\n@@ -137,6 +135,7 @@ public static ClientAuth fromPropertyValue(String prop) {\\n     private String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\n     private String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\n     private String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\n+    private String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\n     private String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\n     private String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\n     private String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\n@@ -202,6 +201,10 @@ public String getSslTruststoreTypeProperty() {\\n         return sslTruststoreTypeProperty;\\n     }\\n \\n+    public String getSslContextSupplierClassProperty() {\\n+        return sslContextSupplierClassProperty;\\n+    }\\n+\\n     public String getSslHostnameVerificationEnabledProperty() {\\n         return sslHostnameVerificationEnabledProperty;\\n     }\\n@@ -282,7 +285,28 @@ public int getSslHandshakeTimeoutMillis() {\\n         }\\n     }\\n \\n+    @SuppressWarnings(\"unchecked\")\\n     public SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n+        final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n+        if (supplierContextClassName != null) {\\n+            if (LOG.isDebugEnabled()) {\\n+                LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n+            }\\n+            try {\\n+                Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n+                Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n+                return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n+            } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException |\\n+                    InstantiationException | IllegalAccessException e) {\\n+                throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName +\\n+                        \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n+            }\\n+        } else {\\n+            return createSSLContextAndOptionsFromConfig(config);\\n+        }\\n+    }\\n+\\n+    public SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n         KeyManager[] keyManagers = null;\\n         TrustManager[] trustManagers = null;\\n \\ndiff --git a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\nindex 43bc2d8e9..76bdd2e20 100644\\n--- a/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n+++ b/zookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java\\n@@ -133,6 +133,8 @@ private void putSSLProperties(X509Util x509Util) {\\n                 System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n         properties.put(x509Util.getSslTruststoreTypeProperty(),\\n                 System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n+        properties.put(x509Util.getSslContextSupplierClassProperty(),\\n+                System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n         properties.put(x509Util.getSslHostnameVerificationEnabledProperty(),\\n                 System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n         properties.put(x509Util.getSslCrlEnabledProperty(),\\ndiff --git a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\nindex 2a6bb3246..1fecd808d 100644\\n--- a/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n+++ b/zookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java\\n@@ -22,6 +22,7 @@\\n import java.net.InetSocketAddress;\\n import java.net.ServerSocket;\\n import java.net.Socket;\\n+import java.security.NoSuchAlgorithmException;\\n import java.security.Security;\\n import java.util.Collection;\\n import java.util.concurrent.Callable;\\n@@ -30,6 +31,7 @@\\n import java.util.concurrent.Executors;\\n import java.util.concurrent.Future;\\n import java.util.concurrent.atomic.AtomicInteger;\\n+import java.util.function.Supplier;\\n \\n import javax.net.ssl.HandshakeCompletedEvent;\\n import javax.net.ssl.HandshakeCompletedListener;\\n@@ -403,6 +405,23 @@ public void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n         }\\n     }\\n \\n+    @Test(expected = X509Exception.SSLContextException.class)\\n+    public void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n+        clientX509Util.createSSLContext(zkConfig);\\n+    }\\n+\\n+    @Test\\n+    public void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n+        ZKConfig zkConfig = new ZKConfig();\\n+        ClientX509Util clientX509Util = new ClientX509Util();\\n+        zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n+        final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n+        Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n+    }\\n+\\n     private static void forceClose(Socket s) {\\n         if (s == null || s.isClosed()) {\\n             return;\\n@@ -528,4 +547,18 @@ private void setCustomCipherSuites() {\\n         x509Util.close(); // remember to close old instance before replacing it\\n         x509Util = new ClientX509Util();\\n     }\\n+\\n+    public static class SslContextSupplier implements Supplier<SSLContext> {\\n+\\n+        @Override\\n+        public SSLContext get() {\\n+            try {\\n+                return SSLContext.getDefault();\\n+            } catch (NoSuchAlgorithmException e) {\\n+                throw new RuntimeException(e);\\n+            }\\n+        }\\n+\\n+    }\\n+\\n }\\n\\n\\nRelevant source code 4:\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (Before)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.ByteArrayInputStream;\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Arrays;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLParameters;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/X509Util.java (After)\\npackage org.apache.zookeeper.common;\\n\\nimport java.io.Closeable;\\nimport java.io.IOException;\\nimport java.lang.reflect.InvocationTargetException;\\nimport java.net.Socket;\\nimport java.nio.file.Path;\\nimport java.nio.file.Paths;\\nimport java.security.Security;\\nimport java.security.cert.PKIXBuilderParameters;\\nimport java.security.cert.X509CertSelector;\\nimport java.util.Objects;\\nimport java.util.concurrent.atomic.AtomicReference;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.CertPathTrustManagerParameters;\\nimport javax.net.ssl.KeyManager;\\nimport javax.net.ssl.KeyManagerFactory;\\nimport javax.net.ssl.SSLContext;\\nimport javax.net.ssl.SSLServerSocket;\\nimport javax.net.ssl.SSLSocket;\\nimport javax.net.ssl.TrustManager;\\npublic  abstract class X509Util implements Closeable, AutoCloseable {\\nprivate String sslTruststoreLocationProperty = getConfigPrefix() + \"trustStore.location\";\\nprivate String sslTruststorePasswdProperty = getConfigPrefix() + \"trustStore.password\";\\nprivate String sslTruststoreTypeProperty = getConfigPrefix() + \"trustStore.type\";\\nprivate String sslContextSupplierClassProperty = getConfigPrefix() + \"context.supplier.class\";\\nprivate String sslHostnameVerificationEnabledProperty = getConfigPrefix() + \"hostnameVerification\";\\nprivate String sslCrlEnabledProperty = getConfigPrefix() + \"crl\";\\nprivate String sslOcspEnabledProperty = getConfigPrefix() + \"ocsp\";\\npublic String getSslTruststoreTypeProperty() {\\n    return sslTruststoreTypeProperty;\\n}\\npublic String getSslContextSupplierClassProperty() {\\n    return sslContextSupplierClassProperty;\\n}\\npublic String getSslHostnameVerificationEnabledProperty() {\\n    return sslHostnameVerificationEnabledProperty;\\n}\\n/**\\n * Returns the max amount of time, in milliseconds, that the first UnifiedServerSocket read() operation should\\n * block for when trying to detect the client mode (TLS or PLAINTEXT).\\n * Defaults to {@link X509Util#DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS}.\\n *\\n * @return the handshake detection timeout, in milliseconds.\\n */\\npublic int getSslHandshakeTimeoutMillis() {\\n    try {\\n        SSLContextAndOptions ctx = getDefaultSSLContextAndOptions();\\n        return ctx.getHandshakeDetectionTimeoutMillis();\\n    } catch (SSLContextException e) {\\n        LOG.error(\"Error creating SSL context and options\", e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    } catch (Exception e) {\\n        LOG.error(\"Error parsing config property \" + getSslHandshakeDetectionTimeoutMillisProperty(), e);\\n        return DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS;\\n    }\\n}\\n@SuppressWarnings(\"unchecked\")\\npublic SSLContextAndOptions createSSLContextAndOptions(ZKConfig config) throws SSLContextException {\\n    final String supplierContextClassName = config.getProperty(sslContextSupplierClassProperty);\\n    if (supplierContextClassName != null) {\\n        if (LOG.isDebugEnabled()) {\\n            LOG.debug(\"Loading SSLContext supplier from property \\'{}\\'\", sslContextSupplierClassProperty);\\n        }\\n        try {\\n            Class<?> sslContextClass = Class.forName(supplierContextClassName);\\n            Supplier<SSLContext> sslContextSupplier = (Supplier<SSLContext>) sslContextClass.getConstructor().newInstance();\\n            return new SSLContextAndOptions(this, config, sslContextSupplier.get());\\n        } catch (ClassNotFoundException | ClassCastException | NoSuchMethodException | InvocationTargetException | InstantiationException | IllegalAccessException e) {\\n            throw new SSLContextException(\"Could not retrieve the SSLContext from supplier source \\'\" + supplierContextClassName + \"\\' provided in the property \\'\" + sslContextSupplierClassProperty + \"\\'\", e);\\n        }\\n    } else {\\n        return createSSLContextAndOptionsFromConfig(config);\\n    }\\n}\\npublic SSLContextAndOptions createSSLContextAndOptionsFromConfig(ZKConfig config) throws SSLContextException {\\n    KeyManager[] keyManagers = null;\\n    TrustManager[] trustManagers = null;\\n    String keyStoreLocationProp = config.getProperty(sslKeystoreLocationProperty, \"\");\\n    String keyStorePasswordProp = config.getProperty(sslKeystorePasswdProperty, \"\");\\n    String keyStoreTypeProp = config.getProperty(sslKeystoreTypeProperty);\\n    // There are legal states in some use cases for null KeyManager or TrustManager.\\n    // But if a user wanna specify one, location is required. Password defaults to empty string if it is not\\n    // specified by the user.\\n    if (keyStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslKeystoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            keyManagers = new KeyManager[] { createKeyManager(keyStoreLocationProp, keyStorePasswordProp, keyStoreTypeProp) };\\n        } catch (KeyManagerException keyManagerException) {\\n            throw new SSLContextException(\"Failed to create KeyManager\", keyManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslKeystoreTypeProperty + \": \" + keyStoreTypeProp, e);\\n        }\\n    }\\n    String trustStoreLocationProp = config.getProperty(sslTruststoreLocationProperty, \"\");\\n    String trustStorePasswordProp = config.getProperty(sslTruststorePasswdProperty, \"\");\\n    String trustStoreTypeProp = config.getProperty(sslTruststoreTypeProperty);\\n    boolean sslCrlEnabled = config.getBoolean(this.sslCrlEnabledProperty);\\n    boolean sslOcspEnabled = config.getBoolean(this.sslOcspEnabledProperty);\\n    boolean sslServerHostnameVerificationEnabled = config.getBoolean(this.getSslHostnameVerificationEnabledProperty(), true);\\n    boolean sslClientHostnameVerificationEnabled = sslServerHostnameVerificationEnabled && shouldVerifyClientHostname();\\n    if (trustStoreLocationProp.isEmpty()) {\\n        LOG.warn(getSslTruststoreLocationProperty() + \" not specified\");\\n    } else {\\n        try {\\n            trustManagers = new TrustManager[] { createTrustManager(trustStoreLocationProp, trustStorePasswordProp, trustStoreTypeProp, sslCrlEnabled, sslOcspEnabled, sslServerHostnameVerificationEnabled, sslClientHostnameVerificationEnabled) };\\n        } catch (TrustManagerException trustManagerException) {\\n            throw new SSLContextException(\"Failed to create TrustManager\", trustManagerException);\\n        } catch (IllegalArgumentException e) {\\n            throw new SSLContextException(\"Bad value for \" + sslTruststoreTypeProperty + \": \" + trustStoreTypeProp, e);\\n        }\\n    }\\n    String protocol = config.getProperty(sslProtocolProperty, DEFAULT_PROTOCOL);\\n    try {\\n        SSLContext sslContext = SSLContext.getInstance(protocol);\\n        sslContext.init(keyManagers, trustManagers, null);\\n        return new SSLContextAndOptions(this, config, sslContext);\\n    } catch (NoSuchAlgorithmException | KeyManagementException sslContextInitException) {\\n        throw new SSLContextException(sslContextInitException);\\n    }\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (Before)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/main/java/org/apache/zookeeper/common/ZKConfig.java (After)\\npublic class ZKConfig {\\nprivate void putSSLProperties(X509Util x509Util) {\\n    properties.put(x509Util.getSslProtocolProperty(), System.getProperty(x509Util.getSslProtocolProperty()));\\n    properties.put(x509Util.getSslEnabledProtocolsProperty(), System.getProperty(x509Util.getSslEnabledProtocolsProperty()));\\n    properties.put(x509Util.getSslCipherSuitesProperty(), System.getProperty(x509Util.getSslCipherSuitesProperty()));\\n    properties.put(x509Util.getSslKeystoreLocationProperty(), System.getProperty(x509Util.getSslKeystoreLocationProperty()));\\n    properties.put(x509Util.getSslKeystorePasswdProperty(), System.getProperty(x509Util.getSslKeystorePasswdProperty()));\\n    properties.put(x509Util.getSslKeystoreTypeProperty(), System.getProperty(x509Util.getSslKeystoreTypeProperty()));\\n    properties.put(x509Util.getSslTruststoreLocationProperty(), System.getProperty(x509Util.getSslTruststoreLocationProperty()));\\n    properties.put(x509Util.getSslTruststorePasswdProperty(), System.getProperty(x509Util.getSslTruststorePasswdProperty()));\\n    properties.put(x509Util.getSslTruststoreTypeProperty(), System.getProperty(x509Util.getSslTruststoreTypeProperty()));\\n    properties.put(x509Util.getSslContextSupplierClassProperty(), System.getProperty(x509Util.getSslContextSupplierClassProperty()));\\n    properties.put(x509Util.getSslHostnameVerificationEnabledProperty(), System.getProperty(x509Util.getSslHostnameVerificationEnabledProperty()));\\n    properties.put(x509Util.getSslCrlEnabledProperty(), System.getProperty(x509Util.getSslCrlEnabledProperty()));\\n    properties.put(x509Util.getSslOcspEnabledProperty(), System.getProperty(x509Util.getSslOcspEnabledProperty()));\\n    properties.put(x509Util.getSslClientAuthProperty(), System.getProperty(x509Util.getSslClientAuthProperty()));\\n    properties.put(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), System.getProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty()));\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (Before)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\n}\\n\\nzookeeper-server/src/test/java/org/apache/zookeeper/common/X509UtilTest.java (After)\\nimport java.net.InetSocketAddress;\\nimport java.net.ServerSocket;\\nimport java.net.Socket;\\nimport java.security.NoSuchAlgorithmException;\\nimport java.security.Security;\\nimport java.util.Collection;\\nimport java.util.concurrent.Callable;\\nimport java.util.concurrent.Executors;\\nimport java.util.concurrent.Future;\\nimport java.util.concurrent.atomic.AtomicInteger;\\nimport java.util.function.Supplier;\\nimport javax.net.ssl.HandshakeCompletedEvent;\\nimport javax.net.ssl.HandshakeCompletedListener;\\npublic class X509UtilTest extends BaseX509ParameterizedTestCase {\\n@Test\\npublic void testGetSslHandshakeDetectionTimeoutMillisProperty() {\\n    Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, x509Util.getSslHandshakeTimeoutMillis());\\n    // Note: need to create a new ClientX509Util each time to pick up modified property value\\n    String newPropertyString = Integer.toString(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1);\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), newPropertyString);\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS + 1, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // 0 value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"0\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n    // Negative value not allowed, will return the default\\n    System.setProperty(x509Util.getSslHandshakeDetectionTimeoutMillisProperty(), \"-1\");\\n    try (X509Util tempX509Util = new ClientX509Util()) {\\n        Assert.assertEquals(X509Util.DEFAULT_HANDSHAKE_DETECTION_TIMEOUT_MILLIS, tempX509Util.getSslHandshakeTimeoutMillis());\\n    }\\n}\\n@Test(expected = X509Exception.SSLContextException.class)\\npublic void testCreateSSLContext_invalidCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), String.class.getCanonicalName());\\n    clientX509Util.createSSLContext(zkConfig);\\n}\\n@Test\\npublic void testCreateSSLContext_validCustomSSLContextClass() throws Exception {\\n    ZKConfig zkConfig = new ZKConfig();\\n    ClientX509Util clientX509Util = new ClientX509Util();\\n    zkConfig.setProperty(clientX509Util.getSslContextSupplierClassProperty(), SslContextSupplier.class.getName());\\n    final SSLContext sslContext = clientX509Util.createSSLContext(zkConfig);\\n    Assert.assertEquals(SSLContext.getDefault(), sslContext);\\n}\\nprivate static void forceClose(Socket s) {\\n    if (s == null || s.isClosed()) {\\n        return;\\n    }\\n    try {\\n        s.close();\\n    } catch (IOException e) {\\n    }\\n}\\n// Warning: this will reset the x509Util\\nprivate void setCustomCipherSuites() {\\n    System.setProperty(x509Util.getCipherSuitesProperty(), customCipherSuites[0] + \",\" + customCipherSuites[1]);\\n    // remember to close old instance before replacing it\\n    x509Util.close();\\n    x509Util = new ClientX509Util();\\n}\\npublic static class SslContextSupplier implements Supplier<SSLContext> {\\n\\n    @Override\\n    public SSLContext get() {\\n        try {\\n            return SSLContext.getDefault();\\n        } catch (NoSuchAlgorithmException e) {\\n            throw new RuntimeException(e);\\n        }\\n    }\\n}\\n}\\n\\n\\nCommit type 4: feat\\n\\nCommit message 4:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFEE0690>\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'content': 'Write a concise commit message based on the Git diff and relevant source code provided. The relevant source code should be used to provide additional context for the changes made in the Git diff.\\n\\nA good commit message explains what changes were made and why they were necessary. Wrap the body at one to three brief sentences.\\n\\nFollow this format for the commit message:\\n\\n{type}: {subject}\\n\\n{body}\\n\\nGit diff 1:\\ndiff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\nindex c4e42c94b93..e2fad7560e3 100644\\n--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java\\n@@ -53,24 +53,29 @@ public static void registerCommands(CommandFactory factory) {\\n   /** merge multiple files together */\\n   public static class Merge extends FsCommand {\\n     public static final String NAME = \"getmerge\";    \\n-    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n+    public static final String USAGE = \"[-nl] [-skip-empty-file] \"\\n+        + \"<src> <localdst>\";\\n     public static final String DESCRIPTION =\\n-      \"Get all the files in the directories that \" +\\n-      \"match the source file pattern and merge and sort them to only \" +\\n-      \"one file on local fs. <src> is kept.\\\\n\" +\\n-      \"-nl: Add a newline character at the end of each file.\";\\n+        \"Get all the files in the directories that \"\\n+        + \"match the source file pattern and merge and sort them to only \"\\n+        + \"one file on local fs. <src> is kept.\\\\n\"\\n+        + \"-nl: Add a newline character at the end of each file.\\\\n\"\\n+        + \"-skip-empty-file: Do not add new line character for empty file.\";\\n \\n     protected PathData dst = null;\\n     protected String delimiter = null;\\n+    private boolean skipEmptyFileDelimiter;\\n     protected List<PathData> srcs = null;\\n \\n     @Override\\n     protected void processOptions(LinkedList<String> args) throws IOException {\\n       try {\\n-        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n+        CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\",\\n+            \"skip-empty-file\");\\n         cf.parse(args);\\n \\n         delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n+        skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n \\n         dst = new PathData(new URI(args.removeLast()), getConf());\\n         if (dst.exists && dst.stat.isDirectory()) {\\n@@ -92,21 +97,26 @@ protected void processArguments(LinkedList<PathData> items)\\n       FSDataOutputStream out = dst.fs.create(dst.path);\\n       try {\\n         for (PathData src : srcs) {\\n-          FSDataInputStream in = src.fs.open(src.path);\\n-          try {\\n-            IOUtils.copyBytes(in, out, getConf(), false);\\n-            if (delimiter != null) {\\n-              out.write(delimiter.getBytes(\"UTF-8\"));\\n+          if (src.stat.getLen() != 0) {\\n+            try (FSDataInputStream in = src.fs.open(src.path)) {\\n+              IOUtils.copyBytes(in, out, getConf(), false);\\n+              writeDelimiter(out);\\n             }\\n-          } finally {\\n-            in.close();\\n+          } else if (!skipEmptyFileDelimiter) {\\n+            writeDelimiter(out);\\n           }\\n         }\\n       } finally {\\n         out.close();\\n-      }      \\n+      }\\n     }\\n- \\n+\\n+    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n+      if (delimiter != null) {\\n+        out.write(delimiter.getBytes(\"UTF-8\"));\\n+      }\\n+    }\\n+\\n     @Override\\n     protected void processNonexistentPath(PathData item) throws IOException {\\n       exitCode = 1; // flag that a path is bad\\n\\n\\nRelevant source code 1:\\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java (Before)\\nclass CopyCommands {\\n/**\\n * merge multiple files together\\n */\\npublic static class Merge extends FsCommand {\\n\\n    public static final String NAME = \"getmerge\";\\n\\n    public static final String USAGE = \"[-nl] <src> <localdst>\";\\n\\n    public static final String DESCRIPTION = \"Get all the files in the directories that \" + \"match the source file pattern and merge and sort them to only \" + \"one file on local fs. <src> is kept.\\\\n\" + \"-nl: Add a newline character at the end of each file.\";\\n\\n    protected PathData dst = null;\\n\\n    protected String delimiter = null;\\n\\n    protected List<PathData> srcs = null;\\n\\n    @Override\\n    protected void processOptions(LinkedList<String> args) throws IOException {\\n        try {\\n            CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\");\\n            cf.parse(args);\\n            delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n            dst = new PathData(new URI(args.removeLast()), getConf());\\n            if (dst.exists && dst.stat.isDirectory()) {\\n                throw new PathIsDirectoryException(dst.toString());\\n            }\\n            srcs = new LinkedList<PathData>();\\n        } catch (URISyntaxException e) {\\n            throw new IOException(\"unexpected URISyntaxException\", e);\\n        }\\n    }\\n\\n    @Override\\n    protected void processArguments(LinkedList<PathData> items) throws IOException {\\n        super.processArguments(items);\\n        if (exitCode != 0) {\\n            // check for error collecting paths\\n            return;\\n        }\\n        FSDataOutputStream out = dst.fs.create(dst.path);\\n        try {\\n            for (PathData src : srcs) {\\n                FSDataInputStream in = src.fs.open(src.path);\\n                try {\\n                    IOUtils.copyBytes(in, out, getConf(), false);\\n                    if (delimiter != null) {\\n                        out.write(delimiter.getBytes(\"UTF-8\"));\\n                    }\\n                } finally {\\n                    in.close();\\n                }\\n            }\\n        } finally {\\n            out.close();\\n        }\\n    }\\n\\n    @Override\\n    protected void processNonexistentPath(PathData item) throws IOException {\\n        // flag that a path is bad\\n        exitCode = 1;\\n        super.processNonexistentPath(item);\\n    }\\n\\n    // this command is handled a bit differently than others.  the paths\\n    // are batched up instead of actually being processed.  this avoids\\n    // unnecessarily streaming into the merge file and then encountering\\n    // a path error that should abort the merge\\n    @Override\\n    protected void processPath(PathData src) throws IOException {\\n        // for directories, recurse one level to get its files, else skip it\\n        if (src.stat.isDirectory()) {\\n            if (getDepth() == 0) {\\n                recursePath(src);\\n            }\\n            // skip subdirs\\n        } else {\\n            srcs.add(src);\\n        }\\n    }\\n}\\n}\\n\\nhadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/shell/CopyCommands.java (After)\\nclass CopyCommands {\\n/**\\n * merge multiple files together\\n */\\npublic static class Merge extends FsCommand {\\n\\n    public static final String NAME = \"getmerge\";\\n\\n    public static final String USAGE = \"[-nl] [-skip-empty-file] \" + \"<src> <localdst>\";\\n\\n    public static final String DESCRIPTION = \"Get all the files in the directories that \" + \"match the source file pattern and merge and sort them to only \" + \"one file on local fs. <src> is kept.\\\\n\" + \"-nl: Add a newline character at the end of each file.\\\\n\" + \"-skip-empty-file: Do not add new line character for empty file.\";\\n\\n    protected PathData dst = null;\\n\\n    protected String delimiter = null;\\n\\n    private boolean skipEmptyFileDelimiter;\\n\\n    protected List<PathData> srcs = null;\\n\\n    @Override\\n    protected void processOptions(LinkedList<String> args) throws IOException {\\n        try {\\n            CommandFormat cf = new CommandFormat(2, Integer.MAX_VALUE, \"nl\", \"skip-empty-file\");\\n            cf.parse(args);\\n            delimiter = cf.getOpt(\"nl\") ? \"\\\\n\" : null;\\n            skipEmptyFileDelimiter = cf.getOpt(\"skip-empty-file\");\\n            dst = new PathData(new URI(args.removeLast()), getConf());\\n            if (dst.exists && dst.stat.isDirectory()) {\\n                throw new PathIsDirectoryException(dst.toString());\\n            }\\n            srcs = new LinkedList<PathData>();\\n        } catch (URISyntaxException e) {\\n            throw new IOException(\"unexpected URISyntaxException\", e);\\n        }\\n    }\\n\\n    @Override\\n    protected void processArguments(LinkedList<PathData> items) throws IOException {\\n        super.processArguments(items);\\n        if (exitCode != 0) {\\n            // check for error collecting paths\\n            return;\\n        }\\n        FSDataOutputStream out = dst.fs.create(dst.path);\\n        try {\\n            for (PathData src : srcs) {\\n                if (src.stat.getLen() != 0) {\\n                    try (FSDataInputStream in = src.fs.open(src.path)) {\\n                        IOUtils.copyBytes(in, out, getConf(), false);\\n                        writeDelimiter(out);\\n                    }\\n                } else if (!skipEmptyFileDelimiter) {\\n                    writeDelimiter(out);\\n                }\\n            }\\n        } finally {\\n            out.close();\\n        }\\n    }\\n\\n    private void writeDelimiter(FSDataOutputStream out) throws IOException {\\n        if (delimiter != null) {\\n            out.write(delimiter.getBytes(\"UTF-8\"));\\n        }\\n    }\\n\\n    @Override\\n    protected void processNonexistentPath(PathData item) throws IOException {\\n        // flag that a path is bad\\n        exitCode = 1;\\n        super.processNonexistentPath(item);\\n    }\\n\\n    // this command is handled a bit differently than others.  the paths\\n    // are batched up instead of actually being processed.  this avoids\\n    // unnecessarily streaming into the merge file and then encountering\\n    // a path error that should abort the merge\\n    @Override\\n    protected void processPath(PathData src) throws IOException {\\n        // for directories, recurse one level to get its files, else skip it\\n        if (src.stat.isDirectory()) {\\n            if (getDepth() == 0) {\\n                recursePath(src);\\n            }\\n            // skip subdirs\\n        } else {\\n            srcs.add(src);\\n        }\\n    }\\n}\\n}\\n\\n\\nCommit Type 1: \\n\\ncommit message 1: feat: add option to skip newlines for empty files in getmerge command\\n\\nAdded a new `-skip-empty-file` option to the `getmerge` command in CopyCommands. This prevents adding newline characters when merging directories that contain empty files, addressing the issue described in HADOOP-12657. Updated the command description, usage, and logic to support the new flag.\\n\\nGit diff 2:\\ndiff --git a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\nindex 091743ebd..a570d3d17 100644\\n--- a/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n+++ b/activemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java\\n@@ -29,6 +29,7 @@ import org.apache.activemq.util.ByteSequence;\\n public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n \\n     public static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\n+    private static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\n \\n     static {\\n         Constructor constructor = null;\\n@@ -243,7 +244,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n             int rc = 0;\\n             bs.writeBoolean(true);\\n             rc += tightMarshalString1(o.getClass().getName(), bs);\\n-            rc += tightMarshalString1(o.getMessage(), bs);\\n+            rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 rc += 2;\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n@@ -264,7 +265,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n                                           BooleanStream bs) throws IOException {\\n         if (bs.readBoolean()) {\\n             tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n-            tightMarshalString2(o.getMessage(), dataOut, bs);\\n+            tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -550,7 +551,7 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         dataOut.writeBoolean(o != null);\\n         if (o != null) {\\n             looseMarshalString(o.getClass().getName(), dataOut);\\n-            looseMarshalString(o.getMessage(), dataOut);\\n+            looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n             if (wireFormat.isStackTraceEnabled()) {\\n                 StackTraceElement[] stackTrace = o.getStackTrace();\\n                 dataOut.writeShort(stackTrace.length);\\n@@ -641,4 +642,10 @@ public abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\n         }\\n         return rc;\\n     }\\n+    \\n+    protected String cutMessageIfNeeded(final String message) {\\n+        return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE)?\\n+            message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n+            \\n+    }\\n }\\n\\n\\nRelevant source code 2:\\nactivemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java (Before)\\npublic  abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\npublic static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\nstatic {\\n    Constructor constructor = null;\\n    try {\\n        constructor = StackTraceElement.class.getConstructor(new Class[] { String.class, String.class, String.class, int.class });\\n    } catch (Throwable e) {\\n    }\\n    STACK_TRACE_ELEMENT_CONSTRUCTOR = constructor;\\n}\\nprotected int tightMarshalThrowable1(OpenWireFormat wireFormat, Throwable o, BooleanStream bs) throws IOException {\\n    if (o == null) {\\n        bs.writeBoolean(false);\\n        return 0;\\n    } else {\\n        int rc = 0;\\n        bs.writeBoolean(true);\\n        rc += tightMarshalString1(o.getClass().getName(), bs);\\n        rc += tightMarshalString1(o.getMessage(), bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            rc += 2;\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                rc += tightMarshalString1(element.getClassName(), bs);\\n                rc += tightMarshalString1(element.getMethodName(), bs);\\n                rc += tightMarshalString1(element.getFileName(), bs);\\n                rc += 4;\\n            }\\n            rc += tightMarshalThrowable1(wireFormat, o.getCause(), bs);\\n        }\\n        return rc;\\n    }\\n}\\nprotected void tightMarshalThrowable2(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut, BooleanStream bs) throws IOException {\\n    if (bs.readBoolean()) {\\n        tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n        tightMarshalString2(o.getMessage(), dataOut, bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                tightMarshalString2(element.getClassName(), dataOut, bs);\\n                tightMarshalString2(element.getMethodName(), dataOut, bs);\\n                tightMarshalString2(element.getFileName(), dataOut, bs);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            tightMarshalThrowable2(wireFormat, o.getCause(), dataOut, bs);\\n        }\\n    }\\n}\\nprotected void looseMarshalThrowable(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut) throws IOException {\\n    dataOut.writeBoolean(o != null);\\n    if (o != null) {\\n        looseMarshalString(o.getClass().getName(), dataOut);\\n        looseMarshalString(o.getMessage(), dataOut);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                looseMarshalString(element.getClassName(), dataOut);\\n                looseMarshalString(element.getMethodName(), dataOut);\\n                looseMarshalString(element.getFileName(), dataOut);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            looseMarshalThrowable(wireFormat, o.getCause(), dataOut);\\n        }\\n    }\\n}\\nprotected ByteSequence looseUnmarshalByteSequence(DataInput dataIn) throws IOException {\\n    ByteSequence rc = null;\\n    if (dataIn.readBoolean()) {\\n        int size = dataIn.readInt();\\n        byte[] t = new byte[size];\\n        dataIn.readFully(t);\\n        rc = new ByteSequence(t, 0, size);\\n    }\\n    return rc;\\n}\\n}\\n\\nactivemq-client/src/main/java/org/apache/activemq/openwire/v10/BaseDataStreamMarshaller.java (After)\\npublic  abstract class BaseDataStreamMarshaller implements DataStreamMarshaller {\\npublic static final Constructor STACK_TRACE_ELEMENT_CONSTRUCTOR;\\nprivate static final int MAX_EXCEPTION_MESSAGE_SIZE = 1024;\\nstatic {\\n    Constructor constructor = null;\\n    try {\\n        constructor = StackTraceElement.class.getConstructor(new Class[] { String.class, String.class, String.class, int.class });\\n    } catch (Throwable e) {\\n    }\\n    STACK_TRACE_ELEMENT_CONSTRUCTOR = constructor;\\n}\\nprotected int tightMarshalThrowable1(OpenWireFormat wireFormat, Throwable o, BooleanStream bs) throws IOException {\\n    if (o == null) {\\n        bs.writeBoolean(false);\\n        return 0;\\n    } else {\\n        int rc = 0;\\n        bs.writeBoolean(true);\\n        rc += tightMarshalString1(o.getClass().getName(), bs);\\n        rc += tightMarshalString1(cutMessageIfNeeded(o.getMessage()), bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            rc += 2;\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                rc += tightMarshalString1(element.getClassName(), bs);\\n                rc += tightMarshalString1(element.getMethodName(), bs);\\n                rc += tightMarshalString1(element.getFileName(), bs);\\n                rc += 4;\\n            }\\n            rc += tightMarshalThrowable1(wireFormat, o.getCause(), bs);\\n        }\\n        return rc;\\n    }\\n}\\nprotected void tightMarshalThrowable2(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut, BooleanStream bs) throws IOException {\\n    if (bs.readBoolean()) {\\n        tightMarshalString2(o.getClass().getName(), dataOut, bs);\\n        tightMarshalString2(cutMessageIfNeeded(o.getMessage()), dataOut, bs);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                tightMarshalString2(element.getClassName(), dataOut, bs);\\n                tightMarshalString2(element.getMethodName(), dataOut, bs);\\n                tightMarshalString2(element.getFileName(), dataOut, bs);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            tightMarshalThrowable2(wireFormat, o.getCause(), dataOut, bs);\\n        }\\n    }\\n}\\nprotected void looseMarshalThrowable(OpenWireFormat wireFormat, Throwable o, DataOutput dataOut) throws IOException {\\n    dataOut.writeBoolean(o != null);\\n    if (o != null) {\\n        looseMarshalString(o.getClass().getName(), dataOut);\\n        looseMarshalString(cutMessageIfNeeded(o.getMessage()), dataOut);\\n        if (wireFormat.isStackTraceEnabled()) {\\n            StackTraceElement[] stackTrace = o.getStackTrace();\\n            dataOut.writeShort(stackTrace.length);\\n            for (int i = 0; i < stackTrace.length; i++) {\\n                StackTraceElement element = stackTrace[i];\\n                looseMarshalString(element.getClassName(), dataOut);\\n                looseMarshalString(element.getMethodName(), dataOut);\\n                looseMarshalString(element.getFileName(), dataOut);\\n                dataOut.writeInt(element.getLineNumber());\\n            }\\n            looseMarshalThrowable(wireFormat, o.getCause(), dataOut);\\n        }\\n    }\\n}\\nprotected ByteSequence looseUnmarshalByteSequence(DataInput dataIn) throws IOException {\\n    ByteSequence rc = null;\\n    if (dataIn.readBoolean()) {\\n        int size = dataIn.readInt();\\n        byte[] t = new byte[size];\\n        dataIn.readFully(t);\\n        rc = new ByteSequence(t, 0, size);\\n    }\\n    return rc;\\n}\\nprotected String cutMessageIfNeeded(final String message) {\\n    return (message.length() > MAX_EXCEPTION_MESSAGE_SIZE) ? message.substring(0, MAX_EXCEPTION_MESSAGE_SIZE - 3) + \"...\" : message;\\n}\\n}\\n\\n\\nCommit Type 2: \\n\\nCommit message 2: fix: limit exception message size to prevent resource exhaustion\\n\\nIntroduced a `MAX_EXCEPTION_MESSAGE_SIZE` constant (1024 characters) and added logic to truncate overly long exception messages in `BaseDataStreamMarshaller`. This prevents excessive memory and resource usage due to unbounded exception message sizes, addressing the issue in AMQ-6894.\\n\\nGit diff 3:\\ndiff --git a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\nindex ca38c0c319..fbaeaebcb8 100644\\n--- a/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n+++ b/src/java/org/apache/cassandra/hints/HintsDispatchTrigger.java\\n@@ -19,20 +19,13 @@ package org.apache.cassandra.hints;\\n \\n import java.util.concurrent.atomic.AtomicBoolean;\\n \\n-import org.apache.cassandra.gms.ApplicationState;\\n-import org.apache.cassandra.gms.Gossiper;\\n-import org.apache.cassandra.schema.Schema;\\n-\\n-import static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\n-\\n /**\\n  * A simple dispatch trigger that\\'s being run every 10 seconds.\\n  *\\n  * Goes through all hint stores and schedules for dispatch all the hints for hosts that are:\\n  * 1. Not currently scheduled for dispatch, and\\n  * 2. Either have some hint files, or an active hint writer, and\\n- * 3. Are live, and\\n- * 4. Have matching schema versions\\n+ * 3. Are live\\n  *\\n  * What does triggering a hints store for dispatch mean?\\n  * - If there are existing hint files, it means submitting them for dispatch;\\n@@ -65,7 +58,6 @@ final class HintsDispatchTrigger implements Runnable\\n                .filter(store -> !isScheduled(store))\\n                .filter(HintsStore::isLive)\\n                .filter(store -> store.isWriting() || store.hasFiles())\\n-               .filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address())))\\n                .forEach(this::schedule);\\n     }\\n \\n\\n\\nRelevant source code 3:\\nsrc/java/org/apache/cassandra/hints/HintsDispatchTrigger.java (Before)\\nimport java.util.concurrent.atomic.AtomicBoolean;\\nimport org.apache.cassandra.gms.ApplicationState;\\nimport org.apache.cassandra.gms.Gossiper;\\nimport org.apache.cassandra.schema.Schema;\\nimport static org.apache.cassandra.utils.FBUtilities.getBroadcastAddressAndPort;\\nfinal class HintsDispatchTrigger implements Runnable {\\npublic void run() {\\n    if (isPaused.get())\\n        return;\\n    catalog.stores().filter(store -> !isScheduled(store)).filter(HintsStore::isLive).filter(store -> store.isWriting() || store.hasFiles()).filter(store -> Schema.instance.isSameVersion(Gossiper.instance.getSchemaVersion(store.address()))).forEach(this::schedule);\\n}\\n}\\n\\nsrc/java/org/apache/cassandra/hints/HintsDispatchTrigger.java (After)\\nimport java.util.concurrent.atomic.AtomicBoolean;\\nfinal class HintsDispatchTrigger implements Runnable {\\npublic void run() {\\n    if (isPaused.get())\\n        return;\\n    catalog.stores().filter(store -> !isScheduled(store)).filter(HintsStore::isLive).filter(store -> store.isWriting() || store.hasFiles()).forEach(this::schedule);\\n}\\n}\\n\\n\\nCommit Type 3: \\n\\nCommit message 3: fix: allow hint delivery during schema mismatch\\n\\nRemoved schema version checks in `HintsDispatchTrigger` to enable hint delivery even during schema mismatches. This change ensures smoother operations in mixed-mode upgrades by allowing hint dispatch while backing off if the destination table does not exist, addressing issue CASSANDRA-20188.\\n\\nGit diff 4:\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\nindex 52419ddf..b567f1ea 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java\\n@@ -23,9 +23,18 @@ import opennlp.tools.util.Sequence;\\n /**\\n  * A thread-safe version of the POSTaggerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafePOSTaggerME implements POSTagger {\\n+public class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\n \\n   private final POSModel model;\\n \\n@@ -64,4 +73,9 @@ public class ThreadSafePOSTaggerME implements POSTagger {\\n   public Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n     return getTagger().topKSequences(sentence, additionaContext);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\nindex 99abc6fb..17ea14e8 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java\\n@@ -24,16 +24,21 @@ import opennlp.tools.util.Span;\\n  * A thread-safe version of SentenceDetectorME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n  * <p>\\n- * Note, however, that this implementation uses a ThreadLocal. Although the implementation is\\n- * lightweight as the model is not duplicated, if you have many long-running threads, you may run\\n- * into memory issues. Be careful when you use this in a JEE application, for example.\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n+public class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\n \\n   private final SentenceModel model;\\n \\n-  private final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal =\\n+  private final ThreadLocal<SentenceDetectorME> threadLocal =\\n       new ThreadLocal<>();\\n \\n   public ThreadSafeSentenceDetectorME(SentenceModel model) {\\n@@ -43,10 +48,10 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n \\n   // If a thread-local version exists, return it. Otherwise, create, then return.\\n   private SentenceDetectorME getSD() {\\n-    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n+    SentenceDetectorME sd = threadLocal.get();\\n     if (sd == null) {\\n       sd = new SentenceDetectorME(model);\\n-      sentenceDetectorThreadLocal.set(sd);\\n+      threadLocal.set(sd);\\n     }\\n     return sd;\\n   }\\n@@ -64,4 +69,9 @@ public class ThreadSafeSentenceDetectorME implements SentenceDetector {\\n   public Span[] sentPosDetect(CharSequence s) {\\n     return getSD().sentPosDetect(s);\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\ndiff --git a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\nindex b92dd5e0..3ebbd1e3 100644\\n--- a/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n+++ b/opennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java\\n@@ -23,13 +23,22 @@ import opennlp.tools.util.Span;\\n /**\\n  * A thread-safe version of TokenizerME. Using it is completely transparent. You can use it in\\n  * a single-threaded context as well, it only incurs a minimal overhead.\\n+ * <p>\\n+ * Note, however, that this implementation uses a {@link ThreadLocal}. Although the implementation is\\n+ * lightweight because the model is not duplicated, if you have many long-running threads,\\n+ * you may run into memory problems.\\n+ * </p>\\n+ * <p>\\n+ * Be careful when using this in a Jakarta EE application, for example.\\n+ * </p>\\n+ * The user is responsible for clearing the {@link ThreadLocal}.\\n  */\\n @ThreadSafe\\n-public class ThreadSafeTokenizerME implements Tokenizer {\\n+public class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\n \\n   private final TokenizerModel model;\\n \\n-  private final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\n+  private final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\n \\n   public ThreadSafeTokenizerME(TokenizerModel model) {\\n     super();\\n@@ -37,10 +46,10 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   }\\n \\n   private TokenizerME getTokenizer() {\\n-    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n+    TokenizerME tokenizer = threadLocal.get();\\n     if (tokenizer == null) {\\n       tokenizer = new TokenizerME(model);\\n-      tokenizerThreadLocal.set(tokenizer);\\n+      threadLocal.set(tokenizer);\\n     }\\n     return tokenizer;\\n   }\\n@@ -58,4 +67,9 @@ public class ThreadSafeTokenizerME implements Tokenizer {\\n   public double[] getProbabilities() {\\n     return getTokenizer().getTokenProbabilities();\\n   }\\n+\\n+  @Override\\n+  public void close() {\\n+    threadLocal.remove();\\n+  }\\n }\\n\\n\\nRelevant source code 4:\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (Before)\\npublic class ThreadSafePOSTaggerME implements POSTagger {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/postag/ThreadSafePOSTaggerME.java (After)\\npublic class ThreadSafePOSTaggerME implements POSTagger, AutoCloseable {\\nprivate final POSModel model;\\n@Override\\npublic Sequence[] topKSequences(String[] sentence, Object[] additionaContext) {\\n    return getTagger().topKSequences(sentence, additionaContext);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (Before)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> sentenceDetectorThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = sentenceDetectorThreadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        sentenceDetectorThreadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/sentdetect/ThreadSafeSentenceDetectorME.java (After)\\npublic class ThreadSafeSentenceDetectorME implements SentenceDetector, AutoCloseable {\\nprivate final SentenceModel model;\\nprivate final ThreadLocal<SentenceDetectorME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeSentenceDetectorME(SentenceModel model) {\\n    super();\\n    this.model = model;\\n}\\n// If a thread-local version exists, return it. Otherwise, create, then return.\\nprivate SentenceDetectorME getSD() {\\n    SentenceDetectorME sd = threadLocal.get();\\n    if (sd == null) {\\n        sd = new SentenceDetectorME(model);\\n        threadLocal.set(sd);\\n    }\\n    return sd;\\n}\\n@Override\\npublic Span[] sentPosDetect(CharSequence s) {\\n    return getSD().sentPosDetect(s);\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (Before)\\npublic class ThreadSafeTokenizerME implements Tokenizer {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> tokenizerThreadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = tokenizerThreadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        tokenizerThreadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n}\\n\\nopennlp-tools/src/main/java/opennlp/tools/tokenize/ThreadSafeTokenizerME.java (After)\\npublic class ThreadSafeTokenizerME implements Tokenizer, AutoCloseable {\\nprivate final TokenizerModel model;\\nprivate final ThreadLocal<TokenizerME> threadLocal = new ThreadLocal<>();\\npublic ThreadSafeTokenizerME(TokenizerModel model) {\\n    super();\\n    this.model = model;\\n}\\nprivate TokenizerME getTokenizer() {\\n    TokenizerME tokenizer = threadLocal.get();\\n    if (tokenizer == null) {\\n        tokenizer = new TokenizerME(model);\\n        threadLocal.set(tokenizer);\\n    }\\n    return tokenizer;\\n}\\npublic double[] getProbabilities() {\\n    return getTokenizer().getTokenProbabilities();\\n}\\n@Override\\npublic void close() {\\n    threadLocal.remove();\\n}\\n}\\n\\n\\nCommit type 4: refactor\\n\\nCommit message 4:', 'role': 'user'}], 'model': 'gpt-4o-mini', 'n': 1, 'stream': False, 'temperature': 0.7}}\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED2E0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFEE06E0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFE9A620>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED2E0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFE9B5C0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x000001AED48ED2E0> server_hostname='api.openai.com' timeout=None\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFE9A8F0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001AEFFEE16D0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1432'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9964'), (b'x-ratelimit-remaining-tokens', b'165422'), (b'x-ratelimit-reset-requests', b'5m7.484s'), (b'x-ratelimit-reset-tokens', b'10.373s'), (b'x-request-id', b'req_f083810ca8f14fc7360a499e8e2bcf5d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=XDIt2k10XqfZE5YPKrW6xypQE1Y3AR50sJZIzhZm9x8-1737949487-1.0.1.1-Si4HM33i02Li86_Znk2cmCjkFQ6ici96i6Il_kxfwUmcg8w8Uu.wXXjRR7siLc9vJ9XOupvYTAy7Bvh2ZAdPdA; path=/; expires=Mon, 27-Jan-25 04:14:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=chxnDWfWNl1WC8awCGbOUzGP6xt9pT8mAMw48k_DyhE-1737949487845-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085beff7a0b302c-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:47 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1432'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9964'), ('x-ratelimit-remaining-tokens', '165422'), ('x-ratelimit-reset-requests', '5m7.484s'), ('x-ratelimit-reset-tokens', '10.373s'), ('x-request-id', 'req_f083810ca8f14fc7360a499e8e2bcf5d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=XDIt2k10XqfZE5YPKrW6xypQE1Y3AR50sJZIzhZm9x8-1737949487-1.0.1.1-Si4HM33i02Li86_Znk2cmCjkFQ6ici96i6Il_kxfwUmcg8w8Uu.wXXjRR7siLc9vJ9XOupvYTAy7Bvh2ZAdPdA; path=/; expires=Mon, 27-Jan-25 04:14:47 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=chxnDWfWNl1WC8awCGbOUzGP6xt9pT8mAMw48k_DyhE-1737949487845-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085beff7a0b302c-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_f083810ca8f14fc7360a499e8e2bcf5d\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1279'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9963'), (b'x-ratelimit-remaining-tokens', b'152899'), (b'x-ratelimit-reset-requests', b'5m15.773s'), (b'x-ratelimit-reset-tokens', b'14.13s'), (b'x-request-id', b'req_da3078e55c229afb31b4ad4bcdbdbd5b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=fcfmc8XRZPsCT6VSFK3zrNKNV4LHaiB8hzRMps0Z3mw-1737949488-1.0.1.1-9pA_dTpkjJhP0b9CsnCsXOhtTVl6QDyO.nVNBvhktg4tkuw5fxl2erHV8GjGv7NiEKH3toM0zohH6shSpRubXQ; path=/; expires=Mon, 27-Jan-25 04:14:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=M1d16AkDSZelBoIXKh3dgb6rrX8YmszPgVCQt5xjQC8-1737949488037-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bf0088bdf93f-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:48 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1279'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9963'), ('x-ratelimit-remaining-tokens', '152899'), ('x-ratelimit-reset-requests', '5m15.773s'), ('x-ratelimit-reset-tokens', '14.13s'), ('x-request-id', 'req_da3078e55c229afb31b4ad4bcdbdbd5b'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=fcfmc8XRZPsCT6VSFK3zrNKNV4LHaiB8hzRMps0Z3mw-1737949488-1.0.1.1-9pA_dTpkjJhP0b9CsnCsXOhtTVl6QDyO.nVNBvhktg4tkuw5fxl2erHV8GjGv7NiEKH3toM0zohH6shSpRubXQ; path=/; expires=Mon, 27-Jan-25 04:14:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=M1d16AkDSZelBoIXKh3dgb6rrX8YmszPgVCQt5xjQC8-1737949488037-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bf0088bdf93f-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_da3078e55c229afb31b4ad4bcdbdbd5b\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Mon, 27 Jan 2025 03:44:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-yxw5duua92nmh24amrdiwkpm'), (b'openai-processing-ms', b'1389'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9962'), (b'x-ratelimit-remaining-tokens', b'145359'), (b'x-ratelimit-reset-requests', b'5m24.07s'), (b'x-ratelimit-reset-tokens', b'16.392s'), (b'x-request-id', b'req_feff6b26a6f214f3097c010ee56863ec'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=5grniTxCGQ_tTa4lA1Kp2mgDm20h5yjC58J7l9ODNzM-1737949488-1.0.1.1-XEtYjH1_IoL3z75906kDLeUFVs33Ph91pPRuQwWM05Al6PuEROiGjXcXXDRyVHJL.9vJVzLD6yaEbUPmmft6Qw; path=/; expires=Mon, 27-Jan-25 04:14:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=nSc75bdoDa8IFfyRIiHMJcj3XJbJLyI98nHnHMCkYWg-1737949488489-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9085bf00efbaa092-SIN'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Mon, 27 Jan 2025 03:44:48 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-yxw5duua92nmh24amrdiwkpm'), ('openai-processing-ms', '1389'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '200000'), ('x-ratelimit-remaining-requests', '9962'), ('x-ratelimit-remaining-tokens', '145359'), ('x-ratelimit-reset-requests', '5m24.07s'), ('x-ratelimit-reset-tokens', '16.392s'), ('x-request-id', 'req_feff6b26a6f214f3097c010ee56863ec'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=5grniTxCGQ_tTa4lA1Kp2mgDm20h5yjC58J7l9ODNzM-1737949488-1.0.1.1-XEtYjH1_IoL3z75906kDLeUFVs33Ph91pPRuQwWM05Al6PuEROiGjXcXXDRyVHJL.9vJVzLD6yaEbUPmmft6Qw; path=/; expires=Mon, 27-Jan-25 04:14:48 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=nSc75bdoDa8IFfyRIiHMJcj3XJbJLyI98nHnHMCkYWg-1737949488489-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '9085bf00efbaa092-SIN'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_feff6b26a6f214f3097c010ee56863ec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n",
      "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/multipart HTTP/11\" 202 33\n"
     ]
    }
   ],
   "source": [
    "INCLUDED_GENERATOR_INDEXES = [0, 1, 2, 3]\n",
    "\n",
    "filtered_generators = [GENERATORS[i] for i in INCLUDED_GENERATOR_INDEXES]\n",
    "evaluator.evaluate(filtered_generators, COMMITS, CONTEXT_DATA_PATH, CMG_OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
