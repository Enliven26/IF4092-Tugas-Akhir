{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", verbose=True, override=True)\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from typing import Any\n",
    "import jsonpickle\n",
    "import statistics\n",
    "\n",
    "from autocommit_evaluation.core.enums import EnvironmentKey\n",
    "from autocommit_evaluation.cmg.evaluators import CommitMessageGenerator\n",
    "from autocommit_evaluation.cmg import evaluator\n",
    "from autocommit_evaluation.core import (\n",
    "    main_few_shot_high_level_context_cmg_chain,\n",
    "    main_zero_shot_low_level_context_cmg_chain,\n",
    "    main_few_shot_low_level_context_cmg_chain,\n",
    "    main_zero_shot_high_level_context_cmg_chain,\n",
    "    main_high_level_context_chain\n",
    ")\n",
    "from autocommit.core.models import CommitDataModel\n",
    "from autocommit_evaluation.datapreparation import context_generator, example_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMIT_DATA_JSON_FILE_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"cmg\", \"commits.json\")\n",
    "EVALUATION_COMMIT_DATA_JSON_FILE_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"cmg\", \"commits.evaluation.json\")\n",
    "TEST_COMMIT_DATA_JSON_FILE_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"cmg\", \"commits.test.json\")\n",
    "EXAMPLE_DATA_JSON_FILE_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"cmg\", \"commits.example.json\")\n",
    "RESULT_DATA_JSON_FILE_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"result\", \"evaluation.json\")\n",
    "SCORE_DATA_JSON_FILE_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"result\", \"score.json\")\n",
    "\n",
    "CONTEXT_DATA_PATH = os.path.join(\"autocommit_evaluation\",\"data\", \"context\")\n",
    "\n",
    "DEFAULT_CONTEXT_GENERATION_OUTPUT_PATH = os.path.join(\n",
    "    \"autocommit_evaluation\", \"data\", \"context\"\n",
    ")\n",
    "DEFAULT_HIGH_LEVEL_CONTEXT_OUTPUT_PATH = os.path.join(\n",
    "    \"out\", \"result\", \"highlevelcontext\"\n",
    ")\n",
    "DEFAULT_CMG_OUTPUT_PATH = os.path.join(\"out\", \"result\", \"cmg\")\n",
    "DEFAULT_DIFF_CLASSIFICATION_OUTPUT_PATH = os.path.join(\n",
    "    \"out\", \"result\", \"diffclassification\"\n",
    ")\n",
    "DEFAULT_EXAMPLE_GENERATION_OUTPUT_PATH = os.path.join(\"out\", \"result\", \"example\")\n",
    "DEFAULT_CLEANING_RESULT_OUTPUT_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"result\", \"evaluation.cleaned.json\")\n",
    "DEFAULT_SCORE_SUMMARY_OUTPUT_PATH = os.path.join(\"autocommit_evaluation\", \"data\", \"result\", \"score.summary.json\")\n",
    "\n",
    "DIFF_CLASSIFIER_CHAINS = [\n",
    "    main_zero_shot_low_level_context_cmg_chain,\n",
    "    main_zero_shot_high_level_context_cmg_chain,\n",
    "]\n",
    "\n",
    "HIGH_LEVEL_CONTEXT_CHAINS = [\n",
    "    main_high_level_context_chain,\n",
    "]\n",
    "\n",
    "GENERATORS = [\n",
    "    CommitMessageGenerator(\n",
    "        \"Main Few-Shot Low-Level Context Generator\", main_few_shot_low_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"Main Zero-Shot High-Level Context Generator\", main_zero_shot_high_level_context_cmg_chain\n",
    "    ),\n",
    "    CommitMessageGenerator(\n",
    "        \"Main Few-Shot High-Level Context Generator\", main_few_shot_high_level_context_cmg_chain\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_GENERATION_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.CONTEXT_GENERATION_OUTPUT_PATH.value,\n",
    "        DEFAULT_CONTEXT_GENERATION_OUTPUT_PATH,\n",
    "    )\n",
    "\n",
    "HIGH_LEVEL_CONTEXT_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.HIGH_LEVEL_CONTEXT_OUTPUT_PATH.value,\n",
    "        DEFAULT_HIGH_LEVEL_CONTEXT_OUTPUT_PATH,\n",
    "    )\n",
    "\n",
    "CMG_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.CMG_OUTPUT_PATH.value, DEFAULT_CMG_OUTPUT_PATH\n",
    "    )\n",
    "\n",
    "DIFF_CLASSIFICATION_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.DIFF_CLASSIFICATION_OUTPUT_PATH.value,\n",
    "        DEFAULT_DIFF_CLASSIFICATION_OUTPUT_PATH,\n",
    "    )\n",
    "\n",
    "EXAMPLE_GENERATION_OUTPUT_PATH = os.getenv(\n",
    "        EnvironmentKey.EXAMPLE_GENERATION_OUTPUT_PATH.value,\n",
    "        DEFAULT_EXAMPLE_GENERATION_OUTPUT_PATH,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(path: str) -> list[CommitDataModel]:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            json_string = file.read()\n",
    "\n",
    "        return CommitDataModel.from_json(json_string)\n",
    "\n",
    "COMMITS = get_commits(COMMIT_DATA_JSON_FILE_PATH)\n",
    "EVALUATION_COMMITS = get_commits(EVALUATION_COMMIT_DATA_JSON_FILE_PATH)\n",
    "TEST_COMMITS = get_commits(TEST_COMMIT_DATA_JSON_FILE_PATH)\n",
    "EXAMPLE_COMMITS = get_commits(EXAMPLE_DATA_JSON_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_commits = COMMITS + EVALUATION_COMMITS + TEST_COMMITS + EXAMPLE_COMMITS\n",
    "# repo_name_filters = [\"camel\", \"kafka\"]\n",
    "\n",
    "# context_generator.generate_context(all_commits, CONTEXT_GENERATION_OUTPUT_PATH, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_generator.generate_examples(EXAMPLE_COMMITS, EXAMPLE_GENERATION_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Commit Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluator.evaluate(GENERATORS, COMMITS, CONTEXT_DATA_PATH, CMG_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMG Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_commit_subject_length(commit_message: str):\n",
    "#     return len(commit_message.split(\"\\n\")[0])\n",
    "\n",
    "# data = None\n",
    "\n",
    "# with open(RESULT_DATA_JSON_FILE_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "#     json_string = file.read()\n",
    "#     data = json.loads(json_string)\n",
    "\n",
    "# random_state = random.getstate()\n",
    "\n",
    "# for commit in data:\n",
    "\n",
    "#     commit[\"generation_results\"] = [\n",
    "#         result for result in commit[\"generation_results\"] if result[\"generator_id\"] != \"Main Zero-Shot Low-Level Context Generator\"\n",
    "#     ]\n",
    "    \n",
    "#     for result in commit[\"generation_results\"]:    \n",
    "#         commit_message = result.get(\"cleaned_commit_message\") or result[\"commit_message\"]\n",
    "#         result[\"commit_subject_length\"] = calculate_commit_subject_length(commit_message)\n",
    "\n",
    "#     seed_value = int(commit[\"evaluation_id\"][2:]) + 42\n",
    "#     random.seed(seed_value)\n",
    "#     random.shuffle(commit[\"generation_results\"])\n",
    "    \n",
    "# random.setstate(random_state)\n",
    "\n",
    "# with open(DEFAULT_CLEANING_RESULT_OUTPUT_PATH, \"w\", encoding=\"utf-8\") as file:\n",
    "#     json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning scores...\n",
      "Total invalid individual responses: 159\n",
      "Percentage of invalid individual responses: 57.19%\n",
      "Finished cleaning scores.\n",
      "\n",
      "Removing outliers...\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC001\n",
      "Samples: [[3, 3, 1, 3], [4, 4, 3, 3], [4, 3, 4, 2], [4, 4, 4, 3]]\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC001\n",
      "Samples: [[4, 4, 4, 4], [4, 4, 4, 4], [4, 4, 4, 4], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC001\n",
      "Samples: [[4, 4, 1, 4], [4, 4, 3, 3], [4, 4, 4, 4], [4, 2, 4, 4]]\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {1}\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC007\n",
      "Samples: [[3, 2, 3, 1], [2, 4, 3, 3], [4, 3, 4, 4], [2, 3, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {1}\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC007\n",
      "Samples: [[4, 4, 4, 2], [4, 4, 4, 4], [3, 2, 3, 1], [4, 4, 4, 2]]\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC007\n",
      "Samples: [[2, 4, 4, 4], [2, 4, 4, 4], [4, 3, 4, 3], [3, 4, 4, 4]]\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {0}\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC015\n",
      "Samples: [[3, 2, 3, 3], [3, 3, 3, 3], [3, 4, 4, 3], [4, 2, 3, 2]]\n",
      "Outlier indexes: {1}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC015\n",
      "Samples: [[4, 4, 4, 4], [4, 4, 4, 3], [4, 4, 3, 4], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC015\n",
      "Samples: [[4, 4, 4, 4], [3, 4, 4, 3], [4, 4, 4, 4], [2, 4, 3, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC016\n",
      "Samples: [[2, 1, 2, 3], [2, 2, 2, 3], [3, 4, 4, 3], [2, 1, 3, 1]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC016\n",
      "Samples: [[4, 4, 4, 4], [4, 4, 4, 4], [3, 3, 1, 2], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC016\n",
      "Samples: [[4, 4, 4, 2], [3, 3, 4, 2], [4, 4, 4, 4], [3, 3, 4, 4]]\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC020\n",
      "Samples: [[2, 3, 3, 3], [3, 3, 4, 3], [4, 4, 3, 4], [2, 4, 3, 3]]\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC020\n",
      "Samples: [[4, 4, 4, 4], [4, 4, 4, 3], [3, 2, 4, 2], [4, 3, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {1}\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC020\n",
      "Samples: [[4, 2, 4, 4], [4, 2, 4, 3], [4, 4, 4, 4], [4, 4, 4, 2]]\n",
      "Outlier indexes: {1}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC021\n",
      "Samples: [[1, 3, 3, 3], [2, 4, 3, 3], [3, 3, 4, 4], [4, 3, 4, 4]]\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {1}\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC021\n",
      "Samples: [[1, 4, 4, 4], [3, 4, 4, 4], [3, 3, 4, 4], [4, 4, 4, 4]]\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC021\n",
      "Samples: [[1, 4, 4, 2], [2, 4, 3, 3], [3, 3, 4, 2], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC024\n",
      "Samples: [[2, 1, 2, 2], [3, 2, 4, 3], [4, 3, 4, 2], [2, 1, 3, 3]]\n",
      "Outlier indexes: {1}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC024\n",
      "Samples: [[3, 3, 3, 2], [4, 2, 4, 3], [2, 2, 2, 1], [4, 2, 3, 2]]\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC024\n",
      "Samples: [[4, 1, 4, 4], [3, 2, 4, 3], [4, 4, 4, 3], [4, 2, 4, 3]]\n",
      "Outlier indexes: {1}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC025\n",
      "Samples: [[3, 3, 3, 3], [3, 4, 3, 4], [4, 4, 4, 3], [4, 3, 4, 3]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {3}\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC025\n",
      "Samples: [[4, 4, 4, 4], [4, 4, 4, 4], [4, 4, 4, 4], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC025\n",
      "Samples: [[4, 4, 4, 4], [3, 3, 2, 3], [4, 4, 4, 4], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC034\n",
      "Samples: [[3, 3, 3, 3], [4, 3, 3, 4], [3, 4, 4, 4], [4, 3, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {1}\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC034\n",
      "Samples: [[4, 4, 2, 4], [3, 3, 2, 3], [3, 4, 4, 4], [4, 3, 4, 4]]\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {1}\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC034\n",
      "Samples: [[4, 4, 4, 4], [4, 3, 3, 4], [4, 4, 4, 4], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC042\n",
      "Samples: [[2, 3, 3, 3], [2, 3, 3, 3], [3, 4, 4, 4], [2, 2, 4, 2]]\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: {2}\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC042\n",
      "Samples: [[4, 4, 4, 4], [4, 4, 4, 4], [4, 2, 3, 3], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC042\n",
      "Samples: [[4, 4, 4, 4], [4, 4, 3, 4], [4, 4, 4, 4], [4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {2}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: set()\n",
      "Generator ID: Main Few-Shot Low-Level Context Generator\n",
      "Evaluation ID: TC047\n",
      "Samples: [[3, 3, 2, 3, 1], [3, 4, 3, 2, 4], [2, 4, 3, 3, 3], [3, 4, 3, 3, 4]]\n",
      "Outlier indexes: {2, 4}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {0, 1}\n",
      "Outlier indexes: {1, 4}\n",
      "Generator ID: Main Zero-Shot High-Level Context Generator\n",
      "Evaluation ID: TC047\n",
      "Samples: [[3, 3, 3, 2, 1], [3, 4, 3, 3, 4], [1, 4, 4, 3, 3], [2, 4, 4, 1, 4]]\n",
      "Outlier indexes: {3, 4}\n",
      "Outlier indexes: {1, 4}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {0, 3}\n",
      "Generator ID: Main Few-Shot High-Level Context Generator\n",
      "Evaluation ID: TC047\n",
      "Samples: [[4, 4, 4, 4, 4], [3, 4, 4, 4, 4], [4, 4, 4, 4, 4], [3, 4, 4, 4, 4]]\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {0}\n",
      "Outlier indexes: set()\n",
      "Outlier indexes: {0}\n",
      "Total outlier individual responses: 30\n",
      "Percentage of outlier individual responses: 25.21%\n",
      "Finished cleaning scores.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Form Result Processing\n",
    "\n",
    "class CommitMessageScore:\n",
    "    def __init__(self):\n",
    "        self.rationality_score: int = 0\n",
    "        self.comprehensiveness_score: int = 0\n",
    "        self.conciseness_score: int = 0\n",
    "        self.correctness_score: int = 0\n",
    "\n",
    "class GeneratorScore:\n",
    "    def __init__(self):\n",
    "        self.generator_id: str = \"\"\n",
    "        self.scores: list[CommitMessageScore] = []\n",
    "\n",
    "class TestCaseScore:\n",
    "    def __init__(self):\n",
    "        self.evaluation_id: str = \"\"\n",
    "        self.scores: list[GeneratorScore] = []\n",
    "\n",
    "class ScoreSummary:\n",
    "    def __init__(self):\n",
    "        self.generator_id: str = \"\"\n",
    "        self.rationality_score: float = 0\n",
    "        self.comprehensiveness_score: float = 0\n",
    "        self.conciseness_score: float = 0\n",
    "        self.correctness_score: float = 0\n",
    "\n",
    "def json_to_object(name: str, data: Any) -> Any:\n",
    "    if isinstance(data, dict):\n",
    "        return type(name, (object,), {k: json_to_object(k, v) for k, v in data.items()})()\n",
    "    elif isinstance(data, list):\n",
    "        return [json_to_object(name, item) for item in data]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "def is_rationality_score_valid(\n",
    "        commit_message_score: CommitMessageScore, commit_message: str) -> bool:\n",
    "    jira_ticket_pattern = r'\\b[A-Z]+-\\d+\\b'\n",
    "\n",
    "    if commit_message_score.rationality_score == 3:\n",
    "        if re.search(jira_ticket_pattern, commit_message):\n",
    "            return False\n",
    "\n",
    "    elif commit_message_score.rationality_score == 4:\n",
    "        if not re.search(jira_ticket_pattern, commit_message):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def is_conciseness_score_valid(\n",
    "        commit_message_score: CommitMessageScore, commit_subject_length: int) -> bool:\n",
    "    if commit_message_score.conciseness_score != 1:\n",
    "        if (commit_subject_length > 100):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def is_correctness_score_valid(\n",
    "        commit_message_score: CommitMessageScore, \n",
    "        commit_message: str,\n",
    "        jira_url: str) -> bool:\n",
    "    \n",
    "    ground_truth_ticket_id = jira_url.split(\"/\")[-1]\n",
    "    ticket_ids = re.findall(r'\\b[A-Z]+-\\d+\\b', commit_message)\n",
    "\n",
    "    if commit_message_score.correctness_score == 4:\n",
    "        if (len(ticket_ids) > 1 \n",
    "            or (len(ticket_ids) == 1 and ticket_ids[0] != ground_truth_ticket_id)):\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def clean_scores(test_case_scores: list[TestCaseScore]) -> list[TestCaseScore]:\n",
    "    print(\"Cleaning scores...\")\n",
    "\n",
    "    data: list[Any] = None\n",
    "    cleaned_test_case_scores: list[TestCaseScore] = []\n",
    "    total_individual_responses = 0\n",
    "    total_invalid_individual_responses = 0\n",
    "\n",
    "    with open(DEFAULT_CLEANING_RESULT_OUTPUT_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "        json_string = file.read()\n",
    "        data = json.loads(json_string)\n",
    "\n",
    "    for test_case_score in test_case_scores:\n",
    "        commit = next((commit for commit in data if commit[\"evaluation_id\"] == test_case_score.evaluation_id), None)\n",
    "\n",
    "        if commit is None:\n",
    "            continue\n",
    "        \n",
    "        invalid_indexes = set()\n",
    "\n",
    "        total_individual_responses += len(test_case_score.scores[0].scores)\n",
    "\n",
    "        for generator_score in test_case_score.scores:\n",
    "            for idx, commit_message_score in enumerate(generator_score.scores):\n",
    "                commit_message = next((result for result in commit[\"generation_results\"] if result[\"generator_id\"] == generator_score.generator_id), None)\n",
    "\n",
    "                if commit_message is None:\n",
    "                    continue\n",
    "\n",
    "                is_rationality_valid = is_rationality_score_valid(\n",
    "                    commit_message_score, \n",
    "                    commit_message.get(\"cleaned_commit_message\") or commit_message[\"commit_message\"])\n",
    "                is_comprehensiveness_valid = True\n",
    "                is_conciseness_valid = is_conciseness_score_valid(\n",
    "                    commit_message_score, \n",
    "                    commit_message[\"commit_subject_length\"])\n",
    "                is_correctness_valid = is_correctness_score_valid(\n",
    "                    commit_message_score, \n",
    "                    commit_message.get(\"cleaned_commit_message\") or commit_message[\"commit_message\"],\n",
    "                    commit[\"jira_url\"])\n",
    "                \n",
    "                is_valid = is_rationality_valid and is_comprehensiveness_valid and is_conciseness_valid and is_correctness_valid\n",
    "                \n",
    "                if not is_valid:\n",
    "                    invalid_indexes.add(idx)\n",
    "\n",
    "        valid_test_case_score = TestCaseScore()\n",
    "        valid_test_case_score.evaluation_id = test_case_score.evaluation_id\n",
    "        valid_test_case_score.scores = []\n",
    "\n",
    "        for generator_score in test_case_score.scores:\n",
    "            valid_generator_score = GeneratorScore()\n",
    "            valid_generator_score.generator_id = generator_score.generator_id\n",
    "            valid_generator_score.scores = []\n",
    "\n",
    "            for idx, commit_message_score in enumerate(generator_score.scores):\n",
    "                if idx in invalid_indexes:\n",
    "                    continue\n",
    "\n",
    "                valid_generator_score.scores.append(commit_message_score)\n",
    "\n",
    "            valid_test_case_score.scores.append(valid_generator_score)\n",
    "\n",
    "        cleaned_test_case_scores.append(valid_test_case_score)\n",
    "        total_invalid_individual_responses += len(invalid_indexes)\n",
    "\n",
    "    print(f\"Total invalid individual responses: {total_invalid_individual_responses}\")\n",
    "    print(f\"Percentage of invalid individual responses: {total_invalid_individual_responses / total_individual_responses * 100:.2f}%\")\n",
    "\n",
    "    print(\"Finished cleaning scores.\\n\")\n",
    "    return cleaned_test_case_scores\n",
    "\n",
    "def get_outlier_indexes(samples: list[int]) -> set[int]:\n",
    "    median = statistics.median(samples)\n",
    "    mad = statistics.median([abs(x - median) for x in samples])\n",
    "    made = 1.483 * mad\n",
    "\n",
    "    lower_bound = median - 3 * made\n",
    "    upper_bound = median + 3 * made\n",
    "\n",
    "    return {\n",
    "        i for i, x in enumerate(samples)\n",
    "        if x < lower_bound or x > upper_bound\n",
    "    }\n",
    "\n",
    "def remove_outliers(test_case_scores: list[TestCaseScore]) -> list[TestCaseScore]:\n",
    "    print(\"Removing outliers...\")\n",
    "\n",
    "    cleaned_test_case_scores: list[TestCaseScore] = []\n",
    "    total_individual_responses = 0\n",
    "    total_outlier_individual_responses = 0\n",
    "\n",
    "    for test_case_score in test_case_scores:\n",
    "        outlier_indexes = set()\n",
    "\n",
    "        total_individual_responses += len(test_case_score.scores[0].scores)\n",
    "\n",
    "        for generator_score in test_case_score.scores:\n",
    "            if (len(generator_score.scores) >= 4):\n",
    "                samples_collection = [[] for _ in range(4)]\n",
    "\n",
    "                for commit_message_score in generator_score.scores:\n",
    "                    samples_collection[0].append(commit_message_score.rationality_score)\n",
    "                    samples_collection[1].append(commit_message_score.comprehensiveness_score)\n",
    "                    samples_collection[2].append(commit_message_score.conciseness_score)\n",
    "                    samples_collection[3].append(commit_message_score.correctness_score)\n",
    "\n",
    "                print(f\"Generator ID: {generator_score.generator_id}\")\n",
    "                print(f\"Evaluation ID: {test_case_score.evaluation_id}\")\n",
    "                print(f\"Samples: {samples_collection}\")\n",
    "                for samples in samples_collection:\n",
    "                    new_outlier_indexes = get_outlier_indexes(samples)\n",
    "                    print(f\"Outlier indexes: {new_outlier_indexes}\")\n",
    "                    outlier_indexes = outlier_indexes.union(new_outlier_indexes)\n",
    "\n",
    "        valid_test_case_score = TestCaseScore()\n",
    "        valid_test_case_score.evaluation_id = test_case_score.evaluation_id\n",
    "        valid_test_case_score.scores = []\n",
    "\n",
    "        for generator_score in test_case_score.scores:\n",
    "            valid_generator_score = GeneratorScore()\n",
    "            valid_generator_score.generator_id = generator_score.generator_id\n",
    "            valid_generator_score.scores = []\n",
    "\n",
    "            for idx, commit_message_score in enumerate(generator_score.scores):\n",
    "                if idx in outlier_indexes:\n",
    "                    continue\n",
    "\n",
    "                valid_generator_score.scores.append(commit_message_score)\n",
    "\n",
    "            valid_test_case_score.scores.append(valid_generator_score)\n",
    "\n",
    "        cleaned_test_case_scores.append(valid_test_case_score)\n",
    "        total_outlier_individual_responses += len(outlier_indexes)\n",
    "\n",
    "    print(f\"Total outlier individual responses: {total_outlier_individual_responses}\")\n",
    "    print(f\"Percentage of outlier individual responses: {total_outlier_individual_responses / total_individual_responses * 100:.2f}%\")\n",
    "\n",
    "    print(\"Finished cleaning scores.\\n\")\n",
    "    return cleaned_test_case_scores\n",
    "\n",
    "\n",
    "score_data = None\n",
    "\n",
    "with open(SCORE_DATA_JSON_FILE_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "    score_data = json.load(file)\n",
    "\n",
    "test_case_scores: list[TestCaseScore] = json_to_object(\"TestCaseScore\", score_data)\n",
    "test_case_scores = clean_scores(test_case_scores)\n",
    "test_case_scores = remove_outliers(test_case_scores)\n",
    "\n",
    "score_summaries: list[ScoreSummary] = []\n",
    "\n",
    "for test_case_score in test_case_scores:\n",
    "    for generatorScore in test_case_score.scores:\n",
    "        score_summary = next((score for score in score_summaries if score.generator_id == generatorScore.generator_id), None)\n",
    "\n",
    "        if score_summary is None:\n",
    "            score_summary = ScoreSummary()\n",
    "            score_summary.generator_id = generatorScore.generator_id\n",
    "            score_summaries.append(score_summary)\n",
    "\n",
    "        for commitMessageScore in generatorScore.scores:\n",
    "            score_summary.rationality_score += commitMessageScore.rationality_score\n",
    "            score_summary.comprehensiveness_score += commitMessageScore.comprehensiveness_score\n",
    "            score_summary.conciseness_score += commitMessageScore.conciseness_score\n",
    "            score_summary.correctness_score += commitMessageScore.correctness_score\n",
    "\n",
    "for score_summary in score_summaries:\n",
    "    score_count = sum([\n",
    "        sum([\n",
    "            len(generator_score.scores) \n",
    "            for generator_score \n",
    "            in test_case_score.scores\n",
    "            if generator_score.generator_id == score_summary.generator_id\n",
    "        ])\n",
    "        for test_case_score\n",
    "        in test_case_scores\n",
    "    ])\n",
    "    \n",
    "    score_summary.rationality_score /= score_count\n",
    "    score_summary.comprehensiveness_score /= score_count\n",
    "    score_summary.conciseness_score /= score_count\n",
    "    score_summary.correctness_score /= score_count\n",
    "\n",
    "json_string = jsonpickle.encode(score_summaries, unpicklable=False, indent=4)\n",
    "\n",
    "with open(DEFAULT_SCORE_SUMMARY_OUTPUT_PATH, \"w\") as file:\n",
    "    file.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
